<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>78758dc40d3d442998aa7fd4f0446bc5</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="introduction" class="cell markdown" id="nVPplLIzC5l3">
<h1>Introduction</h1>
</section>
<div class="cell markdown" id="TeA4AJ6QC8mW">
<p>Daily travel in the US is largely dominated by cars. Cars are a
necessary part of American life due to the current state of public
transportation. Very few places in America can boast adequate public
transportation, and 45% of Americas have no access to public
transportation (Source: <a
href="https://www.apta.com/news-publications/public-transportation-facts/">APTA</a>).
As a result, the American commute is primarily made via car, with 76% of
American commuters using a personal vehicle to get to their workplace
(Source: <a
href="https://www.weforum.org/agenda/2022/05/commute-america-sustainability-cars/">World
Economic Forum</a>). For these Americans, their livelihood is tied to
access to a car.</p>
<p>In recent years, the spike in prices of new cars and trucks has
caused many Americans to look towards buying used cars when the need for
a new car arises (Sources: <a
href="https://www.cbsnews.com/newyork/news/car-values-increasing-along-with-demand-for-used-vehicles-average-years-on-the-road/">CBS</a>,
<a
href="https://www.majorworld.com/why-are-more-people-buying-used-cars-in-2024/">Major
World</a>). In 2023, the average price of a new car had increased by
around $10,000 since 2020, largely because of inflation and
manufacturing delays related to the COVID-19 pandemic (Source: <a
href="https://www.consumerreports.org/cars/buying-a-car/people-spending-more-on-new-cars-but-prices-not-necessarily-rising-a3134608893/">Consumer
Reports</a>). Many manufacturers have also divested from their more
affordable models in favor of models that produce more profit (Source:
<a
href="https://www.consumerreports.org/cars/buying-a-car/people-spending-more-on-new-cars-but-prices-not-necessarily-rising-a3134608893/">Consumer
Reports</a>).</p>
<p>Used car prices have also risen to meet the growing demand, but these
vehicles are still seen by many as a more affordable and adequate
alternative to a new vehicle.</p>
<p>In our project, we hope to develop a price predictor for used cars
based on a combination of various features, including the location of
car (state), the year the car was built, the manufacturer, the number of
miled on the car (odometer), etc. This price predictor could be useful
for people looking to sell used cars to ensure (1) they are asking a
reasonable price for their car and (2) they are receiving resonable
offers for their car to avoid low-balling from buyers. It could also be
useful for people looking to buy a used car to ensure that they are not
taken advantage of by sellers hiking up the price of their car.</p>
</div>
<section id="imports" class="cell markdown" id="xx23m12dKMZ5">
<h2><strong>Imports</strong></h2>
<p>We will start by including some libraries for our analysis</p>
</section>
<div class="cell code" data-execution_count="2" id="nvg8zyM3vBwN">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime <span class="im">as</span> dt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dateutil <span class="im">import</span> parser</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score, accuracy_score</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, StandardScaler</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> regularizers</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/2383902976.py:2: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
</code></pre>
</div>
</div>
<section id="data-collection" class="cell markdown" id="tlyEMM23NvQw">
<h1><strong>Data Collection</strong></h1>
<p>The initial phase of our analysis involves data extraction. Our focus
will be on the collaboration between different regions, so it would be
beneficial to gather some general data on these regions, such as the
type of vehicles commonly found there. Although our current analysis
does not consider the state of the region, it might be intriguing to
incorporate this variable in future studies.</p>
<p>All the data was sourced from the following link which contains
information about various vehicles, their conditions, prices, and other
relevant details.</p>
<p>Data was downloaded from <a
href="https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data"
class="uri">https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data</a></p>
</section>
<div class="cell code" data-execution_count="3" id="lQWslMyUKLUs">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&#39;data.csv&#39;</span>, on_bad_lines<span class="op">=</span><span class="st">&#39;warn&#39;</span>)</span></code></pre></div>
</div>
<section id="data-cleaning" class="cell markdown" id="yObN2Tf3PmYr">
<h1><strong>Data Cleaning</strong></h1>
<p>Now that we have our dataframe we need to clean our dataset of
vehicle information. The primary focus is on correcting inconsistencies
in the column, replacing missing data, and removing unnecessary columns,
thereby preparing the data for further analysis or modeling.</p>
</section>
<div class="cell markdown" id="FJXEQShDY1GK">
<p>We'll begin by limiting our data to cars made in 2001 or later. This
was chosen because the average year in our dataset is 2011 and the
standard deviation is ~9.5 years. Rounding up to 10 years, one standard
deviation below the mean is 2001. Limiting our data to cars manufactured
after 2001 maintains 92.97% of our original data. We also exclude cars
produced in 2022 since we are interested in used cars.</p>
</div>
<div class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}"
id="7G3JBrKJZD_s" data-outputId="b07db10d-8cab-4389-a2fc-e8c9ac25c93b">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data.drop(columns<span class="op">=</span>[<span class="st">&#39;id&#39;</span>,<span class="st">&#39;VIN&#39;</span>, <span class="st">&#39;paint_color&#39;</span>, <span class="st">&#39;lat&#39;</span>, <span class="st">&#39;long&#39;</span>, <span class="st">&#39;size&#39;</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>odometer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4.268530e+05</td>
      <td>425675.000000</td>
      <td>4.224800e+05</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.520308e+04</td>
      <td>2011.235191</td>
      <td>9.804333e+04</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.218267e+07</td>
      <td>9.452120</td>
      <td>2.138815e+05</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000e+00</td>
      <td>1900.000000</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.900000e+03</td>
      <td>2008.000000</td>
      <td>3.770400e+04</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.395000e+04</td>
      <td>2013.000000</td>
      <td>8.554800e+04</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.648800e+04</td>
      <td>2017.000000</td>
      <td>1.335425e+05</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.736929e+09</td>
      <td>2022.000000</td>
      <td>1.000000e+07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown" id="FM6lJc-5QbY3">
<p>We now drop rows with missing data from our data frame. This still
leaves us with plenty of data to work with and avoids a false perception
of data.</p>
</div>
<div class="cell code" data-execution_count="5" id="8cStwmAwHZmG">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;year&#39;</span>]<span class="op">&gt;</span><span class="dv">2000</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;year&#39;</span>]<span class="op">&lt;</span><span class="dv">2022</span>]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.dropna()</span></code></pre></div>
</div>
<div class="cell markdown" id="hO2cbTu3a5QZ">
<p>Because the type of information given by region varies (some values
are cities, some are states, some are parts of states, some are large
geographic regions, etc.), we will not use region in our data analysis.
Instead, we will use state to determine the geographic location of the
vehicle. Here, we drop region and format state values to be uppercase,
as is the standard for state abbreviations.</p>
</div>
<div class="cell code" data-execution_count="6" id="-OsE27EUbSea">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropping region &amp; formatting state</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>data.drop(<span class="st">&#39;region&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;state&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;state&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.upper())</span></code></pre></div>
</div>
<div class="cell markdown" id="td5RbcDdcs4o">
<p>We now want ensure consistent formatting of year and posting
date.</p>
</div>
<div class="cell code" data-execution_count="7" id="Re360fsPblmo">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set format of year and posting_date</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> pd.to_datetime(data[<span class="st">&#39;year&#39;</span>], <span class="bu">format</span><span class="op">=</span><span class="st">&#39;%Y&#39;</span>).dt.strftime(<span class="st">&#39;%Y&#39;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;posting_date&#39;</span>] <span class="op">=</span>  pd.to_datetime(data[<span class="st">&#39;posting_date&#39;</span>], utc<span class="op">=</span><span class="va">True</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;mixed&#39;</span>).dt.strftime(<span class="st">&#39;%m-</span><span class="sc">%d</span><span class="st">-%Y&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="-dowxU3wfY-c">
<p>We next add a column for car age, which is calculated by subtracting
the model year from the year of posting (2021). If the model is 2022,
the car age is set to 0. If the age is unknown, it is also set to 0.</p>
</div>
<div class="cell code" data-execution_count="8" id="aTM7uthUfXwV">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate car age based on posting date and year</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>data.loc[:, <span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;posting_date&#39;</span>].<span class="bu">str</span>[<span class="op">-</span><span class="dv">4</span>:].astype(<span class="bu">float</span>) <span class="op">-</span> data[<span class="st">&#39;year&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Replacing cars with negative or no age to have age of 0</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;car_age&#39;</span>].replace(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;car_age&#39;</span>].replace(np.nan, <span class="fl">0.0</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Rearranging the columns for organization</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[[<span class="st">&#39;state&#39;</span>, <span class="st">&#39;price&#39;</span>, <span class="st">&#39;year&#39;</span>, <span class="st">&#39;car_age&#39;</span>, <span class="st">&#39;manufacturer&#39;</span>, <span class="st">&#39;model&#39;</span>, <span class="st">&#39;condition&#39;</span>, <span class="st">&#39;odometer&#39;</span>, <span class="st">&#39;title_status&#39;</span>, <span class="st">&#39;transmission&#39;</span>, <span class="st">&#39;posting_date&#39;</span>,<span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;fuel&#39;</span>, <span class="st">&#39;drive&#39;</span>, <span class="st">&#39;type&#39;</span>]]</span></code></pre></div>
</div>
<div class="cell markdown" id="zrqkkRHTfyLY">
<p>Now we will format the cylinder column to contain only an integer
representing the number of cylinders. Entries with an unknown number of
cylinders are set to have 0 cylinders.</p>
</div>
<div class="cell code" data-execution_count="9" id="yAEQTklwhGyx">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing &quot;cylinder&quot; from cylinder col entries (--&gt; type int)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># replace &#39;other&#39; and NaN with 0</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data[&#39;cylinders&#39;] = data[&#39;cylinders&#39;].replace(&#39;other&#39;, &#39;0 cylinders&#39;)</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;cylinders&#39;</span>] <span class="op">!=</span> <span class="st">&#39;other&#39;</span>]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>data.loc[:,<span class="st">&#39;cylinders&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;cylinders&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">int</span>(x.split(<span class="st">&#39; &#39;</span>)[<span class="dv">0</span>]))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;cylinders&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;cylinders&#39;</span>].astype(<span class="bu">int</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="DeWJS6mDn41K">
<p>We now move on to properly format the manufacturer column to
capitalize the brand names.</p>
</div>
<div class="cell code" data-execution_count="10" id="8-izoGWan5PM">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Format manufacturers</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace(a,b):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&quot;manufacturer&quot;</span>].replace(a,b,inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyphonated/Two Word Names</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;mercedes-benz&#39;</span>,<span class="st">&#39;Mercedes-Benz&#39;</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;alfa-romeo&#39;</span>,<span class="st">&#39;Alfa-Romeo&#39;</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;harley-davidson&#39;</span>,<span class="st">&#39;Harley-Davidson&#39;</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;aston-marin&#39;</span>,<span class="st">&#39;Aston-Martin&#39;</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;land rover&#39;</span>,<span class="st">&#39;Land Rover&#39;</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># All Caps</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;gmc&#39;</span>, <span class="st">&quot;GMC&quot;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;bmw&#39;</span>, <span class="st">&#39;BMW&#39;</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Based on car models, &#39;rover&#39; is &#39;land rover&#39;</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;rover&#39;</span>,<span class="st">&#39;Land Rover&#39;</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Capitalize every manufacturer that is not already formatted</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;manufacturer&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;manufacturer&quot;</span>].astype(<span class="bu">str</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.capitalize() <span class="cf">if</span> x <span class="kw">and</span> <span class="kw">not</span> x[<span class="dv">0</span>].isupper() <span class="cf">else</span> x)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/1322409721.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing &#39;df[col].method(value, inplace=True)&#39;, try using &#39;df.method({col: value}, inplace=True)&#39; or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data[&quot;manufacturer&quot;].replace(a,b,inplace=True)
</code></pre>
</div>
</div>
<div class="cell markdown" id="WEQLsT3ctbdF">
<p>Next, we'll ensure that the dtype of year is an integer.</p>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="8ICdCCqvtosH" data-outputId="f28b310a-2876-4beb-b548-756b2792c97d">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data.dtypes</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">
<pre><code>state            object
price             int64
year             object
car_age         float64
manufacturer     object
model            object
condition        object
odometer        float64
title_status     object
transmission     object
posting_date     object
cylinders         int64
fuel             object
drive            object
type             object
dtype: object</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="12" id="cmrJSmtqtb20">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_type_chnge(ch):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  data[ch] <span class="op">=</span> pd.to_numeric(data[ch], errors<span class="op">=</span><span class="st">&#39;coerce&#39;</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  data[ch].fillna(<span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  data[ch] <span class="op">=</span> data[ch].astype(<span class="bu">int</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>chn<span class="op">=</span> [<span class="st">&#39;year&#39;</span>]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> chn:</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  data_type_chnge(i)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/3714771194.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing &#39;df[col].method(value, inplace=True)&#39;, try using &#39;df.method({col: value}, inplace=True)&#39; or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data[ch].fillna(0, inplace=True)
</code></pre>
</div>
</div>
<div class="cell markdown" id="2tz1-L5dZpCu">
<p>We noticed a handful of outliers with prices that are beyond
reasonable. We drop these outliers here.</p>
</div>
<div class="cell code" data-execution_count="13" id="QNWO7oUWZoOo">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>data[data[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> <span class="dv">1000000</span>] <span class="co"># Outliers</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;price&#39;</span>] <span class="op">&lt;</span> <span class="dv">1000000</span>] <span class="co"># Drop the outliers</span></span></code></pre></div>
</div>
<div class="cell markdown" id="HSx-90V2TnYW">
<p>After cleaning, we are left with 115,497 data observations. Our
dataframe is the following format:</p>
</div>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:366}"
id="jlP2d1hhh_Ay" data-outputId="a5bbc956-ad4c-445b-b8c4-38597e5129ae">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Dimensions: </span><span class="sc">{}</span><span class="st"> x </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(data.shape[<span class="dv">0</span>], data.shape[<span class="dv">1</span>]))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>data.head(<span class="dv">5</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Dimensions: 115497 x 15
</code></pre>
</div>
<div class="output execute_result" data-execution_count="14">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>price</th>
      <th>year</th>
      <th>car_age</th>
      <th>manufacturer</th>
      <th>model</th>
      <th>condition</th>
      <th>odometer</th>
      <th>title_status</th>
      <th>transmission</th>
      <th>posting_date</th>
      <th>cylinders</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>15000</td>
      <td>2013</td>
      <td>8.0</td>
      <td>Ford</td>
      <td>f-150 xlt</td>
      <td>excellent</td>
      <td>128000.0</td>
      <td>clean</td>
      <td>automatic</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>rwd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>5</th>
      <td>AL</td>
      <td>27990</td>
      <td>2012</td>
      <td>9.0</td>
      <td>GMC</td>
      <td>sierra 2500 hd extended cab</td>
      <td>good</td>
      <td>68696.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>8</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>6</th>
      <td>AL</td>
      <td>34590</td>
      <td>2016</td>
      <td>5.0</td>
      <td>Chevrolet</td>
      <td>silverado 1500 double</td>
      <td>good</td>
      <td>29499.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>7</th>
      <td>AL</td>
      <td>35000</td>
      <td>2019</td>
      <td>2.0</td>
      <td>Toyota</td>
      <td>tacoma</td>
      <td>excellent</td>
      <td>43000.0</td>
      <td>clean</td>
      <td>automatic</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>8</th>
      <td>AL</td>
      <td>29990</td>
      <td>2016</td>
      <td>5.0</td>
      <td>Chevrolet</td>
      <td>colorado extended cab</td>
      <td>good</td>
      <td>17302.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Now that we have finished data collection, let's visualize the
data.</p>
</div>
<section id="data-visualization" class="cell markdown"
id="IkRltsCS3Iq8">
<h1><strong>Data Visualization</strong></h1>
</section>
<div class="cell markdown" id="ItueCAfAeRVv">
<p>We'll start by visualizing a point of curiosity -- which car
manufacturers were posted for sale the most in 2021.</p>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:518}"
id="D3BLxMq5a_ud" data-outputId="c8b70ad5-63ff-4778-d01e-23aacddd1e83">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>manufacturer_counts <span class="op">=</span> data[<span class="st">&#39;manufacturer&#39;</span>].value_counts()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.02</span> <span class="op">*</span> manufacturer_counts.<span class="bu">sum</span>()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>other_count <span class="op">=</span> manufacturer_counts[manufacturer_counts <span class="op">&lt;</span> threshold].<span class="bu">sum</span>()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>manufacturer_counts <span class="op">=</span> manufacturer_counts[manufacturer_counts <span class="op">&gt;=</span> threshold]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>manufacturer_counts[<span class="st">&#39;Other&#39;</span>] <span class="op">=</span> other_count</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> sns.color_palette(<span class="st">&#39;tab20&#39;</span>, <span class="bu">len</span>(manufacturer_counts))</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>wedges, texts, autotexts <span class="op">=</span> ax.pie(manufacturer_counts, labels<span class="op">=</span>manufacturer_counts.index, autopct<span class="op">=</span><span class="st">&#39;</span><span class="sc">%1.1f%%</span><span class="st">&#39;</span>, startangle<span class="op">=</span><span class="dv">90</span>, colors<span class="op">=</span>colors, explode<span class="op">=</span>[<span class="fl">0.1</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">&#39;Other&#39;</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> manufacturer_counts.index])</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    text.set_fontsize(<span class="dv">10</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> autotext <span class="kw">in</span> autotexts:</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    autotext.set_fontsize(<span class="dv">8</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    autotext.set_color(<span class="st">&#39;white&#39;</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">&#39;equal&#39;</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Proportion of Vehicles by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>plt.legend(wedges, manufacturer_counts.index, title<span class="op">=</span><span class="st">&quot;Manufacturers&quot;</span>, loc<span class="op">=</span><span class="st">&quot;center left&quot;</span>, bbox_to_anchor<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>))</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/7855efd6021ad50f9c4ccd74cd671f194eee9ece.png" /></p>
</div>
</div>
<div class="cell markdown" id="ln8W7CFZeikD">
<p>It appears that Ford, Chevy, Toyota, Honda, and Nissan were the top
five most available manufacturers.</p>
</div>
<div class="cell markdown" id="2NaKsJnEew4m">
<p>We now move on to visualizations that will tell us about how price
relates to variables of interest for our machine learning models.</p>
</div>
<div class="cell markdown" id="ZpkdlYNxuvrj">
<p>We're interested in seeing the average price of a car at each
possible age.</p>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:583}"
id="h5SCUuZOu1cs" data-outputId="9f8b4fa0-77d7-4d3c-de39-e7c2f9a45124">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average price of a car for each age group</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;car_age&quot;</span>).describe()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>avg_prices <span class="op">=</span> avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>avg_prices.index, y<span class="op">=</span>avg_prices, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, edgecolor<span class="op">=</span><span class="st">&#39;w&#39;</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Age (years)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by Age&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/c5e4bd811ec103d9eea9824856891e4aba6984fe.png" /></p>
</div>
</div>
<div class="cell markdown" id="-JbIJPCNxRYd">
<p>It seems that as car age increases, average price decreases.</p>
<p>Let's look at average price by manufacturer.</p>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:398}"
id="rdLXtfuUUVMA" data-outputId="9069dbb7-2945-44f8-f496-9dfec6bc7c4f">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the price statistics of a car for each manufacturer</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;manufacturer&quot;</span>).describe()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>avg_prices <span class="op">=</span> avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>avg_prices.index, y<span class="op">=</span>avg_prices, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, edgecolor<span class="op">=</span><span class="st">&#39;w&#39;</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/b3e8d8aab884150690d8e843d1f4b5d7ec4a8336.png" /></p>
</div>
</div>
<div class="cell markdown" id="Lno2FXC2agYu">
<p>It appears that each manufacturer has a distinct set of prices. Let's
create a violin plot for each manufacturer.</p>
</div>
<div class="cell markdown" id="X6VY7ARRqso8">
<p>A violin plot will give us an idea of how the data is distributed for
each manufacturer. For more detailed information on using and making
violin plots, see this helpful <a
href="https://www.atlassian.com/data/charts/violin-plot-complete-guide">guide
to violin plots</a>.</p>
</div>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:323}"
id="sV44aeVitDiP" data-outputId="f10b1381-b92f-4437-e996-75912d37bb55">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filtering to handle kernel density estimation used in seaborn</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>filtered_data <span class="op">=</span> data[(data[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> <span class="dv">100</span>) <span class="op">|</span> ((data[<span class="st">&#39;manufacturer&#39;</span>] <span class="op">!=</span> <span class="st">&#39;Ferrari&#39;</span>) <span class="op">&amp;</span> (data[<span class="st">&#39;manufacturer&#39;</span>] <span class="op">!=</span> <span class="st">&#39;Tesla&#39;</span>))]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a violin plot for prices by manufacturer</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>))</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">&quot;husl&quot;</span>, <span class="bu">len</span>(filtered_data[<span class="st">&#39;manufacturer&#39;</span>].unique()))</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>sns.violinplot(data<span class="op">=</span>filtered_data, x<span class="op">=</span><span class="st">&#39;manufacturer&#39;</span>, y<span class="op">=</span><span class="st">&#39;price&#39;</span>, hue<span class="op">=</span><span class="st">&#39;manufacturer&#39;</span>, palette<span class="op">=</span>palette, dodge<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Price of a Used Car by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/4bc4a56cb7e1039a94ec2f8bec56d3e3adb573b7.png" /></p>
</div>
</div>
<div class="cell markdown" id="18DxsuTsmT-P">
<p>It appears that manufacturers have different distributions of prices,
although some manufacturers (e.g. Volkswagen and Mazda) have similar
distributions.</p>
</div>
<div class="cell markdown" id="7xeMus3DfwAw">
<p>Let's now look at price by state.</p>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:228}"
id="NRY-lZYygCzv" data-outputId="49c05fc4-6baa-451a-bc0b-a58f2cd1acba">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the price statistics of a car for each state</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;state&quot;</span>).describe()</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot average price for each state</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(avgs.index, avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>])</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;State&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by State&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/0ffc7aa29058162fad006a60510e708ec5c15f7c.png" /></p>
</div>
</div>
<div class="cell markdown" id="0_zKBEBZgKNp">
<p>It seems that Alaska has the most expensive cars on average, while
New Jersey has the least expensive.</p>
</div>
<div class="cell code" data-execution_count="20"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:269}"
id="31O1gUqMgWjc" data-outputId="97d4f691-1be6-479e-c3a7-166d490bc465">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a violin plot for prices by state</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">&quot;husl&quot;</span>, <span class="bu">len</span>(data[<span class="st">&#39;state&#39;</span>].unique()))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>sns.violinplot(data<span class="op">=</span>data, x<span class="op">=</span><span class="st">&#39;state&#39;</span>, y<span class="op">=</span><span class="st">&#39;price&#39;</span>, hue<span class="op">=</span><span class="st">&#39;state&#39;</span>, palette<span class="op">=</span>palette, dodge<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;State&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Price of a Used Car by State&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/2ef597a29031d896b94ab5944208f705b43a95bf.png" /></p>
</div>
</div>
<div class="cell markdown" id="uebFMZtGginJ">
<p>This shows us that the bulk of the data for each state has a price of
under 50,000 USD, but each state has varying levels of variation in the
upper extreme of &gt; 50,000 USD.</p>
</div>
<section id="correlation----numeric-data" class="cell markdown"
id="FAQnIF5ugvV0">
<h3>Correlation -- Numeric Data</h3>
</section>
<div class="cell markdown" id="t8oNoaYrx55v">
<p>We are interested in correlation between numeric variables. We will
now visualize correlation between numeric data.</p>
</div>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="aLiHHPvFWUvK" data-outputId="3a04e29c-4154-4a55-9578-2025ff9087fa">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric data</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>num_data <span class="op">=</span> data.select_dtypes(include<span class="op">=</span>[np.number])</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pairwise correlation between columns</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> pd.DataFrame(num_data).corr()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>mat</span></code></pre></div>
<div class="output execute_result" data-execution_count="21">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>car_age</th>
      <th>odometer</th>
      <th>cylinders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>price</th>
      <td>1.000000</td>
      <td>0.555635</td>
      <td>-0.555635</td>
      <td>-0.221816</td>
      <td>0.364257</td>
    </tr>
    <tr>
      <th>year</th>
      <td>0.555635</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>-0.249332</td>
      <td>-0.063077</td>
    </tr>
    <tr>
      <th>car_age</th>
      <td>-0.555635</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>0.249332</td>
      <td>0.063077</td>
    </tr>
    <tr>
      <th>odometer</th>
      <td>-0.221816</td>
      <td>-0.249332</td>
      <td>0.249332</td>
      <td>1.000000</td>
      <td>0.016222</td>
    </tr>
    <tr>
      <th>cylinders</th>
      <td>0.364257</td>
      <td>-0.063077</td>
      <td>0.063077</td>
      <td>0.016222</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:606}"
id="2HQ4vdEtWarM" data-outputId="758d191d-fe60-4bfa-baee-d9e4a8fe687b">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(mat, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&quot;.1f&quot;</span>, cmap<span class="op">=</span><span class="st">&#39;coolwarm&#39;</span>, cbar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Heatmap Representation&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/da83681bf3d34936c1c7df05f943fa5e63b0c904.png" /></p>
</div>
</div>
<div class="cell markdown" id="faLdC8Scg61k">
<p>The price row shows us that price has some correlation with each of
these variables. These variables are also correlated with eachother to
varying degrees.</p>
</div>
<section id="ml" class="cell markdown" id="OyzOXibVvi8T">
<h1><strong>ML</strong></h1>
</section>
<div class="cell markdown" id="gduuIXKqjP--">
<p>We would like to train a model to predict a used car's price given
the car's year, odometer, number of cylinders, manufacturer, state,
condition, fuel-type, drive-type, and vehicle-type. Below, we fit a
linear model using OLS and Lasso Regression, a KNN model, a Random
Forest Model, and a Neural Network.</p>
</div>
<div class="cell code" data-execution_count="23" id="a8Il-0TwvqI_">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear &amp; Lasso Reg (Emily), Random forest (Aarambh), KNN (Ammar), SVM (Lucia)</span></span></code></pre></div>
</div>
<div class="cell markdown" id="8YGaNKRQfSXa">
<p>We'll begin by organizing the data for our model and standardizing
numeric values.</p>
</div>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="Fi8eCcuVMY-B" data-outputId="20a66a9c-cc93-4f6d-8a6c-669449be1236">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>num_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="24">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>car_age</th>
      <th>odometer</th>
      <th>cylinders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>15000</td>
      <td>2013</td>
      <td>8.0</td>
      <td>128000.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>27990</td>
      <td>2012</td>
      <td>9.0</td>
      <td>68696.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>34590</td>
      <td>2016</td>
      <td>5.0</td>
      <td>29499.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>7</th>
      <td>35000</td>
      <td>2019</td>
      <td>2.0</td>
      <td>43000.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>29990</td>
      <td>2016</td>
      <td>5.0</td>
      <td>17302.0</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="25" id="GDAL9YLtKZRj">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> data[[<span class="st">&#39;price&#39;</span>, <span class="st">&#39;year&#39;</span>, <span class="st">&#39;odometer&#39;</span>, <span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;manufacturer&#39;</span>, <span class="st">&#39;state&#39;</span>, <span class="st">&#39;condition&#39;</span>, <span class="st">&#39;fuel&#39;</span>, <span class="st">&#39;drive&#39;</span>, <span class="st">&#39;type&#39;</span>]]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize numeric data</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> train_df.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;int64&#39;</span>, <span class="st">&#39;float64&#39;</span>]).columns</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>train_df.loc[:, numeric_cols] <span class="op">=</span> scaler.fit_transform(train_df[numeric_cols])</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/536243984.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value &#39;[-0.08079239  0.87543971  1.36128511 ...  1.28767217  0.55154277
  0.94905265]&#39; has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  train_df.loc[:, numeric_cols] = scaler.fit_transform(train_df[numeric_cols])
/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/536243984.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value &#39;[0.23581872 0.03391689 0.84152419 ... 1.24532784 1.44722966 1.24532784]&#39; has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  train_df.loc[:, numeric_cols] = scaler.fit_transform(train_df[numeric_cols])
/var/folders/t1/800705wd5xv08rr8sp9xzmdr0000gn/T/ipykernel_987/536243984.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value &#39;[0.04082714 1.30095853 0.04082714 ... 0.04082714 0.04082714 0.04082714]&#39; has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  train_df.loc[:, numeric_cols] = scaler.fit_transform(train_df[numeric_cols])
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:226}"
id="aFwUlRwy1B7I" data-outputId="b552670f-3b0f-49a4-93c6-be8b6cec6604">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create df to hold model data</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> train_df</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>model_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="26">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>-0.080792</td>
      <td>0.235819</td>
      <td>0.133530</td>
      <td>0.040827</td>
      <td>Ford</td>
      <td>AL</td>
      <td>excellent</td>
      <td>gas</td>
      <td>rwd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.875440</td>
      <td>0.033917</td>
      <td>-0.230876</td>
      <td>1.300959</td>
      <td>GMC</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.361285</td>
      <td>0.841524</td>
      <td>-0.471730</td>
      <td>0.040827</td>
      <td>Chevrolet</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.391466</td>
      <td>1.447230</td>
      <td>-0.388770</td>
      <td>0.040827</td>
      <td>Toyota</td>
      <td>AL</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.022666</td>
      <td>0.841524</td>
      <td>-0.546677</td>
      <td>0.040827</td>
      <td>Chevrolet</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="27" id="Hm_AnQgo_whg">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to split data into test and training data</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split(X, y):</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 80-20 ratio of train to test</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">10</span>) <span class="co"># Set a random state so the split is reproducible</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> X_train, X_test, y_train, y_test</span></code></pre></div>
</div>
<section id="model-implementations" class="cell markdown"
id="_kgSj0BxKdWP">
<h1>Model Implementations</h1>
<p>Now that we've gathered, refined, and analyzed our data, it's time to
delve into constructing various models based off this data. We created
linear regression, lasso regression, KNN, and neural network models to
analyze the factors influencing the American used vehicle market. We'll
utilize our independent variables such as vehicle condition,
manufacturer, engine, and other factors, to develop these various models
aimed at uncovering their correlations with a used vehicle's market
value.</p>
</section>
<section id="linear-regression" class="cell markdown" id="pQZJZTFk1VHr">
<h2>Linear regression</h2>
</section>
<div class="cell markdown" id="oZceicVloHik">
<p>We start with a multi-variate linear regression model, trained using
OLS (Ordinary Least Squares). For more information on OLS and linear
regression, see this helpful guide to <a
href="https://builtin.com/data-science/ols-regression">understanding OLS
regression</a>.</p>
</div>
<div class="cell code" data-execution_count="28" id="SJKbqCLm1TW0">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model_data.drop(<span class="st">&#39;price&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model_data[<span class="st">&#39;price&#39;</span>]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="29" id="L9cHpKPR6vs6">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> X_train</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;price&#39;</span>] <span class="op">=</span> y_train</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:244}"
id="VvKU8lX16oo2" data-outputId="1b972de2-9bfd-44e5-b2a7-e3e43549f0d5">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="30">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>200584</th>
      <td>0.639622</td>
      <td>-0.360007</td>
      <td>1.300959</td>
      <td>Dodge</td>
      <td>MI</td>
      <td>excellent</td>
      <td>gas</td>
      <td>rwd</td>
      <td>coupe</td>
      <td>1.535380</td>
    </tr>
    <tr>
      <th>220065</th>
      <td>0.437721</td>
      <td>0.103919</td>
      <td>0.040827</td>
      <td>Jeep</td>
      <td>MO</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>SUV</td>
      <td>0.506860</td>
    </tr>
    <tr>
      <th>89817</th>
      <td>-1.783200</td>
      <td>1.276447</td>
      <td>0.040827</td>
      <td>Toyota</td>
      <td>DC</td>
      <td>good</td>
      <td>gas</td>
      <td>fwd</td>
      <td>mini-van</td>
      <td>-1.037761</td>
    </tr>
    <tr>
      <th>207496</th>
      <td>-0.773690</td>
      <td>-0.201498</td>
      <td>1.300959</td>
      <td>Chevrolet</td>
      <td>MI</td>
      <td>good</td>
      <td>gas</td>
      <td>rwd</td>
      <td>coupe</td>
      <td>0.802489</td>
    </tr>
    <tr>
      <th>135972</th>
      <td>1.043426</td>
      <td>-0.347896</td>
      <td>1.300959</td>
      <td>GMC</td>
      <td>ID</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
      <td>1.896451</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown" id="OSyNc9AcN0ta">
<p>Here, we train the model using training data.</p>
</div>
<div class="cell code" data-execution_count="31"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="32XS3wAQ2VJN" data-outputId="14162fb0-fd91-4a32-ee94-041e3f29a8c0">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.formula.ols(formula<span class="op">=</span><span class="st">&quot;price ~ year + odometer + cylinders + manufacturer + state + condition + fuel + drive + type&quot;</span>, data<span class="op">=</span>train)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="31">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.603</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.602</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1228.</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 17 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  
</tr>
<tr>
  <th>Time:</th>                 <td>15:03:37</td>     <th>  Log-Likelihood:    </th> <td> -88079.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 92397</td>      <th>  AIC:               </th> <td>1.764e+05</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 92282</td>      <th>  BIC:               </th> <td>1.775e+05</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>   114</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                       <td>    1.3165</td> <td>    0.032</td> <td>   40.733</td> <td> 0.000</td> <td>    1.253</td> <td>    1.380</td>
</tr>
<tr>
  <th>manufacturer[T.Alfa-Romeo]</th>      <td>    0.1905</td> <td>    0.125</td> <td>    1.524</td> <td> 0.127</td> <td>   -0.054</td> <td>    0.435</td>
</tr>
<tr>
  <th>manufacturer[T.Aston-martin]</th>    <td>    2.2805</td> <td>    0.315</td> <td>    7.235</td> <td> 0.000</td> <td>    1.663</td> <td>    2.898</td>
</tr>
<tr>
  <th>manufacturer[T.Audi]</th>            <td>   -0.0444</td> <td>    0.027</td> <td>   -1.624</td> <td> 0.104</td> <td>   -0.098</td> <td>    0.009</td>
</tr>
<tr>
  <th>manufacturer[T.BMW]</th>             <td>   -0.1404</td> <td>    0.023</td> <td>   -6.027</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.095</td>
</tr>
<tr>
  <th>manufacturer[T.Buick]</th>           <td>   -0.0885</td> <td>    0.026</td> <td>   -3.345</td> <td> 0.001</td> <td>   -0.140</td> <td>   -0.037</td>
</tr>
<tr>
  <th>manufacturer[T.Cadillac]</th>        <td>   -0.0367</td> <td>    0.026</td> <td>   -1.412</td> <td> 0.158</td> <td>   -0.088</td> <td>    0.014</td>
</tr>
<tr>
  <th>manufacturer[T.Chevrolet]</th>       <td>   -0.1901</td> <td>    0.020</td> <td>   -9.372</td> <td> 0.000</td> <td>   -0.230</td> <td>   -0.150</td>
</tr>
<tr>
  <th>manufacturer[T.Chrysler]</th>        <td>   -0.2976</td> <td>    0.025</td> <td>  -11.948</td> <td> 0.000</td> <td>   -0.346</td> <td>   -0.249</td>
</tr>
<tr>
  <th>manufacturer[T.Dodge]</th>           <td>   -0.3463</td> <td>    0.022</td> <td>  -15.442</td> <td> 0.000</td> <td>   -0.390</td> <td>   -0.302</td>
</tr>
<tr>
  <th>manufacturer[T.Ferrari]</th>         <td>    5.4557</td> <td>    0.150</td> <td>   36.429</td> <td> 0.000</td> <td>    5.162</td> <td>    5.749</td>
</tr>
<tr>
  <th>manufacturer[T.Fiat]</th>            <td>   -0.5809</td> <td>    0.058</td> <td>   -9.966</td> <td> 0.000</td> <td>   -0.695</td> <td>   -0.467</td>
</tr>
<tr>
  <th>manufacturer[T.Ford]</th>            <td>   -0.2195</td> <td>    0.020</td> <td>  -10.833</td> <td> 0.000</td> <td>   -0.259</td> <td>   -0.180</td>
</tr>
<tr>
  <th>manufacturer[T.GMC]</th>             <td>   -0.1329</td> <td>    0.022</td> <td>   -5.995</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.089</td>
</tr>
<tr>
  <th>manufacturer[T.Harley-Davidson]</th> <td>   -0.1294</td> <td>    0.142</td> <td>   -0.911</td> <td> 0.362</td> <td>   -0.408</td> <td>    0.149</td>
</tr>
<tr>
  <th>manufacturer[T.Honda]</th>           <td>   -0.0552</td> <td>    0.021</td> <td>   -2.602</td> <td> 0.009</td> <td>   -0.097</td> <td>   -0.014</td>
</tr>
<tr>
  <th>manufacturer[T.Hyundai]</th>         <td>   -0.2788</td> <td>    0.023</td> <td>  -11.914</td> <td> 0.000</td> <td>   -0.325</td> <td>   -0.233</td>
</tr>
<tr>
  <th>manufacturer[T.Infiniti]</th>        <td>   -0.1473</td> <td>    0.026</td> <td>   -5.620</td> <td> 0.000</td> <td>   -0.199</td> <td>   -0.096</td>
</tr>
<tr>
  <th>manufacturer[T.Jaguar]</th>          <td>    0.0919</td> <td>    0.043</td> <td>    2.114</td> <td> 0.034</td> <td>    0.007</td> <td>    0.177</td>
</tr>
<tr>
  <th>manufacturer[T.Jeep]</th>            <td>   -0.0333</td> <td>    0.022</td> <td>   -1.529</td> <td> 0.126</td> <td>   -0.076</td> <td>    0.009</td>
</tr>
<tr>
  <th>manufacturer[T.Kia]</th>             <td>   -0.3327</td> <td>    0.025</td> <td>  -13.577</td> <td> 0.000</td> <td>   -0.381</td> <td>   -0.285</td>
</tr>
<tr>
  <th>manufacturer[T.Land Rover]</th>      <td>    0.3149</td> <td>    0.039</td> <td>    8.052</td> <td> 0.000</td> <td>    0.238</td> <td>    0.392</td>
</tr>
<tr>
  <th>manufacturer[T.Lexus]</th>           <td>    0.1793</td> <td>    0.024</td> <td>    7.508</td> <td> 0.000</td> <td>    0.133</td> <td>    0.226</td>
</tr>
<tr>
  <th>manufacturer[T.Lincoln]</th>         <td>    0.0306</td> <td>    0.029</td> <td>    1.072</td> <td> 0.284</td> <td>   -0.025</td> <td>    0.087</td>
</tr>
<tr>
  <th>manufacturer[T.Mazda]</th>           <td>   -0.1721</td> <td>    0.027</td> <td>   -6.321</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.119</td>
</tr>
<tr>
  <th>manufacturer[T.Mercedes-Benz]</th>   <td>    0.0545</td> <td>    0.024</td> <td>    2.283</td> <td> 0.022</td> <td>    0.008</td> <td>    0.101</td>
</tr>
<tr>
  <th>manufacturer[T.Mercury]</th>         <td>   -0.1997</td> <td>    0.042</td> <td>   -4.761</td> <td> 0.000</td> <td>   -0.282</td> <td>   -0.118</td>
</tr>
<tr>
  <th>manufacturer[T.Mini]</th>            <td>   -0.1239</td> <td>    0.036</td> <td>   -3.439</td> <td> 0.001</td> <td>   -0.194</td> <td>   -0.053</td>
</tr>
<tr>
  <th>manufacturer[T.Mitsubishi]</th>      <td>   -0.2581</td> <td>    0.031</td> <td>   -8.302</td> <td> 0.000</td> <td>   -0.319</td> <td>   -0.197</td>
</tr>
<tr>
  <th>manufacturer[T.Nissan]</th>          <td>   -0.3071</td> <td>    0.021</td> <td>  -14.442</td> <td> 0.000</td> <td>   -0.349</td> <td>   -0.265</td>
</tr>
<tr>
  <th>manufacturer[T.Pontiac]</th>         <td>   -0.0804</td> <td>    0.033</td> <td>   -2.414</td> <td> 0.016</td> <td>   -0.146</td> <td>   -0.015</td>
</tr>
<tr>
  <th>manufacturer[T.Porsche]</th>         <td>    0.9402</td> <td>    0.048</td> <td>   19.737</td> <td> 0.000</td> <td>    0.847</td> <td>    1.034</td>
</tr>
<tr>
  <th>manufacturer[T.Ram]</th>             <td>   -0.1985</td> <td>    0.023</td> <td>   -8.693</td> <td> 0.000</td> <td>   -0.243</td> <td>   -0.154</td>
</tr>
<tr>
  <th>manufacturer[T.Saturn]</th>          <td>   -0.0355</td> <td>    0.039</td> <td>   -0.909</td> <td> 0.363</td> <td>   -0.112</td> <td>    0.041</td>
</tr>
<tr>
  <th>manufacturer[T.Subaru]</th>          <td>   -0.1418</td> <td>    0.024</td> <td>   -5.827</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.094</td>
</tr>
<tr>
  <th>manufacturer[T.Tesla]</th>           <td>    1.1418</td> <td>    0.285</td> <td>    4.002</td> <td> 0.000</td> <td>    0.583</td> <td>    1.701</td>
</tr>
<tr>
  <th>manufacturer[T.Toyota]</th>          <td>    0.0568</td> <td>    0.021</td> <td>    2.747</td> <td> 0.006</td> <td>    0.016</td> <td>    0.097</td>
</tr>
<tr>
  <th>manufacturer[T.Volkswagen]</th>      <td>   -0.2453</td> <td>    0.025</td> <td>   -9.956</td> <td> 0.000</td> <td>   -0.294</td> <td>   -0.197</td>
</tr>
<tr>
  <th>manufacturer[T.Volvo]</th>           <td>   -0.0790</td> <td>    0.032</td> <td>   -2.499</td> <td> 0.012</td> <td>   -0.141</td> <td>   -0.017</td>
</tr>
<tr>
  <th>state[T.AL]</th>                     <td>   -0.4199</td> <td>    0.031</td> <td>  -13.735</td> <td> 0.000</td> <td>   -0.480</td> <td>   -0.360</td>
</tr>
<tr>
  <th>state[T.AR]</th>                     <td>   -0.8555</td> <td>    0.032</td> <td>  -26.446</td> <td> 0.000</td> <td>   -0.919</td> <td>   -0.792</td>
</tr>
<tr>
  <th>state[T.AZ]</th>                     <td>   -0.4759</td> <td>    0.028</td> <td>  -17.007</td> <td> 0.000</td> <td>   -0.531</td> <td>   -0.421</td>
</tr>
<tr>
  <th>state[T.CA]</th>                     <td>   -0.4366</td> <td>    0.024</td> <td>  -17.849</td> <td> 0.000</td> <td>   -0.485</td> <td>   -0.389</td>
</tr>
<tr>
  <th>state[T.CO]</th>                     <td>   -0.4541</td> <td>    0.028</td> <td>  -16.163</td> <td> 0.000</td> <td>   -0.509</td> <td>   -0.399</td>
</tr>
<tr>
  <th>state[T.CT]</th>                     <td>   -0.5946</td> <td>    0.030</td> <td>  -20.119</td> <td> 0.000</td> <td>   -0.653</td> <td>   -0.537</td>
</tr>
<tr>
  <th>state[T.DC]</th>                     <td>   -0.4880</td> <td>    0.035</td> <td>  -13.949</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.419</td>
</tr>
<tr>
  <th>state[T.DE]</th>                     <td>   -0.3920</td> <td>    0.046</td> <td>   -8.442</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.301</td>
</tr>
<tr>
  <th>state[T.FL]</th>                     <td>   -0.6227</td> <td>    0.025</td> <td>  -25.011</td> <td> 0.000</td> <td>   -0.671</td> <td>   -0.574</td>
</tr>
<tr>
  <th>state[T.GA]</th>                     <td>   -0.4152</td> <td>    0.029</td> <td>  -14.176</td> <td> 0.000</td> <td>   -0.473</td> <td>   -0.358</td>
</tr>
<tr>
  <th>state[T.HI]</th>                     <td>   -0.3255</td> <td>    0.038</td> <td>   -8.610</td> <td> 0.000</td> <td>   -0.400</td> <td>   -0.251</td>
</tr>
<tr>
  <th>state[T.IA]</th>                     <td>   -0.4976</td> <td>    0.027</td> <td>  -18.672</td> <td> 0.000</td> <td>   -0.550</td> <td>   -0.445</td>
</tr>
<tr>
  <th>state[T.ID]</th>                     <td>   -0.4919</td> <td>    0.029</td> <td>  -16.752</td> <td> 0.000</td> <td>   -0.549</td> <td>   -0.434</td>
</tr>
<tr>
  <th>state[T.IL]</th>                     <td>   -0.5125</td> <td>    0.027</td> <td>  -18.739</td> <td> 0.000</td> <td>   -0.566</td> <td>   -0.459</td>
</tr>
<tr>
  <th>state[T.IN]</th>                     <td>   -0.4607</td> <td>    0.028</td> <td>  -16.336</td> <td> 0.000</td> <td>   -0.516</td> <td>   -0.405</td>
</tr>
<tr>
  <th>state[T.KS]</th>                     <td>   -0.6185</td> <td>    0.028</td> <td>  -21.719</td> <td> 0.000</td> <td>   -0.674</td> <td>   -0.563</td>
</tr>
<tr>
  <th>state[T.KY]</th>                     <td>   -0.4060</td> <td>    0.030</td> <td>  -13.543</td> <td> 0.000</td> <td>   -0.465</td> <td>   -0.347</td>
</tr>
<tr>
  <th>state[T.LA]</th>                     <td>   -0.8014</td> <td>    0.036</td> <td>  -22.124</td> <td> 0.000</td> <td>   -0.872</td> <td>   -0.730</td>
</tr>
<tr>
  <th>state[T.MA]</th>                     <td>   -0.5657</td> <td>    0.027</td> <td>  -20.909</td> <td> 0.000</td> <td>   -0.619</td> <td>   -0.513</td>
</tr>
<tr>
  <th>state[T.MD]</th>                     <td>   -0.4581</td> <td>    0.032</td> <td>  -14.321</td> <td> 0.000</td> <td>   -0.521</td> <td>   -0.395</td>
</tr>
<tr>
  <th>state[T.ME]</th>                     <td>   -0.6230</td> <td>    0.035</td> <td>  -18.020</td> <td> 0.000</td> <td>   -0.691</td> <td>   -0.555</td>
</tr>
<tr>
  <th>state[T.MI]</th>                     <td>   -0.4778</td> <td>    0.026</td> <td>  -18.467</td> <td> 0.000</td> <td>   -0.528</td> <td>   -0.427</td>
</tr>
<tr>
  <th>state[T.MN]</th>                     <td>   -0.5215</td> <td>    0.027</td> <td>  -19.081</td> <td> 0.000</td> <td>   -0.575</td> <td>   -0.468</td>
</tr>
<tr>
  <th>state[T.MO]</th>                     <td>   -0.5754</td> <td>    0.031</td> <td>  -18.845</td> <td> 0.000</td> <td>   -0.635</td> <td>   -0.516</td>
</tr>
<tr>
  <th>state[T.MS]</th>                     <td>   -0.4788</td> <td>    0.046</td> <td>  -10.510</td> <td> 0.000</td> <td>   -0.568</td> <td>   -0.390</td>
</tr>
<tr>
  <th>state[T.MT]</th>                     <td>   -0.4202</td> <td>    0.032</td> <td>  -13.111</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.357</td>
</tr>
<tr>
  <th>state[T.NC]</th>                     <td>   -0.4641</td> <td>    0.026</td> <td>  -17.879</td> <td> 0.000</td> <td>   -0.515</td> <td>   -0.413</td>
</tr>
<tr>
  <th>state[T.ND]</th>                     <td>   -0.5496</td> <td>    0.053</td> <td>  -10.452</td> <td> 0.000</td> <td>   -0.653</td> <td>   -0.447</td>
</tr>
<tr>
  <th>state[T.NE]</th>                     <td>   -0.4110</td> <td>    0.046</td> <td>   -8.954</td> <td> 0.000</td> <td>   -0.501</td> <td>   -0.321</td>
</tr>
<tr>
  <th>state[T.NH]</th>                     <td>   -0.5309</td> <td>    0.035</td> <td>  -15.330</td> <td> 0.000</td> <td>   -0.599</td> <td>   -0.463</td>
</tr>
<tr>
  <th>state[T.NJ]</th>                     <td>   -0.5108</td> <td>    0.027</td> <td>  -18.776</td> <td> 0.000</td> <td>   -0.564</td> <td>   -0.457</td>
</tr>
<tr>
  <th>state[T.NM]</th>                     <td>   -0.4952</td> <td>    0.032</td> <td>  -15.642</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.433</td>
</tr>
<tr>
  <th>state[T.NV]</th>                     <td>   -0.3980</td> <td>    0.035</td> <td>  -11.362</td> <td> 0.000</td> <td>   -0.467</td> <td>   -0.329</td>
</tr>
<tr>
  <th>state[T.NY]</th>                     <td>   -0.4960</td> <td>    0.025</td> <td>  -19.729</td> <td> 0.000</td> <td>   -0.545</td> <td>   -0.447</td>
</tr>
<tr>
  <th>state[T.OH]</th>                     <td>   -0.5992</td> <td>    0.025</td> <td>  -23.556</td> <td> 0.000</td> <td>   -0.649</td> <td>   -0.549</td>
</tr>
<tr>
  <th>state[T.OK]</th>                     <td>   -0.9634</td> <td>    0.028</td> <td>  -34.657</td> <td> 0.000</td> <td>   -1.018</td> <td>   -0.909</td>
</tr>
<tr>
  <th>state[T.OR]</th>                     <td>   -0.3852</td> <td>    0.027</td> <td>  -14.242</td> <td> 0.000</td> <td>   -0.438</td> <td>   -0.332</td>
</tr>
<tr>
  <th>state[T.PA]</th>                     <td>   -0.4809</td> <td>    0.026</td> <td>  -18.439</td> <td> 0.000</td> <td>   -0.532</td> <td>   -0.430</td>
</tr>
<tr>
  <th>state[T.RI]</th>                     <td>   -0.5417</td> <td>    0.034</td> <td>  -15.890</td> <td> 0.000</td> <td>   -0.608</td> <td>   -0.475</td>
</tr>
<tr>
  <th>state[T.SC]</th>                     <td>   -0.5264</td> <td>    0.029</td> <td>  -18.178</td> <td> 0.000</td> <td>   -0.583</td> <td>   -0.470</td>
</tr>
<tr>
  <th>state[T.SD]</th>                     <td>   -0.5115</td> <td>    0.043</td> <td>  -11.803</td> <td> 0.000</td> <td>   -0.596</td> <td>   -0.427</td>
</tr>
<tr>
  <th>state[T.TN]</th>                     <td>   -0.4181</td> <td>    0.027</td> <td>  -15.429</td> <td> 0.000</td> <td>   -0.471</td> <td>   -0.365</td>
</tr>
<tr>
  <th>state[T.TX]</th>                     <td>   -0.5711</td> <td>    0.025</td> <td>  -22.409</td> <td> 0.000</td> <td>   -0.621</td> <td>   -0.521</td>
</tr>
<tr>
  <th>state[T.UT]</th>                     <td>   -0.2511</td> <td>    0.049</td> <td>   -5.091</td> <td> 0.000</td> <td>   -0.348</td> <td>   -0.154</td>
</tr>
<tr>
  <th>state[T.VA]</th>                     <td>   -0.4369</td> <td>    0.027</td> <td>  -16.240</td> <td> 0.000</td> <td>   -0.490</td> <td>   -0.384</td>
</tr>
<tr>
  <th>state[T.VT]</th>                     <td>   -0.5315</td> <td>    0.030</td> <td>  -17.557</td> <td> 0.000</td> <td>   -0.591</td> <td>   -0.472</td>
</tr>
<tr>
  <th>state[T.WA]</th>                     <td>   -0.3058</td> <td>    0.030</td> <td>  -10.144</td> <td> 0.000</td> <td>   -0.365</td> <td>   -0.247</td>
</tr>
<tr>
  <th>state[T.WI]</th>                     <td>   -0.4736</td> <td>    0.026</td> <td>  -18.172</td> <td> 0.000</td> <td>   -0.525</td> <td>   -0.423</td>
</tr>
<tr>
  <th>state[T.WV]</th>                     <td>   -0.3404</td> <td>    0.048</td> <td>   -7.143</td> <td> 0.000</td> <td>   -0.434</td> <td>   -0.247</td>
</tr>
<tr>
  <th>state[T.WY]</th>                     <td>   -0.3941</td> <td>    0.058</td> <td>   -6.841</td> <td> 0.000</td> <td>   -0.507</td> <td>   -0.281</td>
</tr>
<tr>
  <th>condition[T.fair]</th>               <td>   -0.0706</td> <td>    0.015</td> <td>   -4.691</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.041</td>
</tr>
<tr>
  <th>condition[T.good]</th>               <td>    0.1512</td> <td>    0.005</td> <td>   31.817</td> <td> 0.000</td> <td>    0.142</td> <td>    0.161</td>
</tr>
<tr>
  <th>condition[T.like new]</th>           <td>    0.1415</td> <td>    0.007</td> <td>   20.266</td> <td> 0.000</td> <td>    0.128</td> <td>    0.155</td>
</tr>
<tr>
  <th>condition[T.new]</th>                <td>    0.2419</td> <td>    0.030</td> <td>    8.153</td> <td> 0.000</td> <td>    0.184</td> <td>    0.300</td>
</tr>
<tr>
  <th>condition[T.salvage]</th>            <td>   -0.2049</td> <td>    0.048</td> <td>   -4.288</td> <td> 0.000</td> <td>   -0.299</td> <td>   -0.111</td>
</tr>
<tr>
  <th>fuel[T.electric]</th>                <td>   -0.6633</td> <td>    0.075</td> <td>   -8.859</td> <td> 0.000</td> <td>   -0.810</td> <td>   -0.517</td>
</tr>
<tr>
  <th>fuel[T.gas]</th>                     <td>   -0.8173</td> <td>    0.010</td> <td>  -79.934</td> <td> 0.000</td> <td>   -0.837</td> <td>   -0.797</td>
</tr>
<tr>
  <th>fuel[T.hybrid]</th>                  <td>   -0.8506</td> <td>    0.022</td> <td>  -38.259</td> <td> 0.000</td> <td>   -0.894</td> <td>   -0.807</td>
</tr>
<tr>
  <th>fuel[T.other]</th>                   <td>   -0.6765</td> <td>    0.018</td> <td>  -37.006</td> <td> 0.000</td> <td>   -0.712</td> <td>   -0.641</td>
</tr>
<tr>
  <th>drive[T.fwd]</th>                    <td>   -0.2047</td> <td>    0.007</td> <td>  -28.085</td> <td> 0.000</td> <td>   -0.219</td> <td>   -0.190</td>
</tr>
<tr>
  <th>drive[T.rwd]</th>                    <td>   -0.0233</td> <td>    0.007</td> <td>   -3.340</td> <td> 0.001</td> <td>   -0.037</td> <td>   -0.010</td>
</tr>
<tr>
  <th>type[T.bus]</th>                     <td>   -0.4298</td> <td>    0.057</td> <td>   -7.526</td> <td> 0.000</td> <td>   -0.542</td> <td>   -0.318</td>
</tr>
<tr>
  <th>type[T.convertible]</th>             <td>    0.5819</td> <td>    0.016</td> <td>   36.026</td> <td> 0.000</td> <td>    0.550</td> <td>    0.614</td>
</tr>
<tr>
  <th>type[T.coupe]</th>                   <td>    0.4497</td> <td>    0.011</td> <td>   42.320</td> <td> 0.000</td> <td>    0.429</td> <td>    0.471</td>
</tr>
<tr>
  <th>type[T.hatchback]</th>               <td>   -0.0172</td> <td>    0.013</td> <td>   -1.369</td> <td> 0.171</td> <td>   -0.042</td> <td>    0.007</td>
</tr>
<tr>
  <th>type[T.mini-van]</th>                <td>   -0.0237</td> <td>    0.015</td> <td>   -1.562</td> <td> 0.118</td> <td>   -0.053</td> <td>    0.006</td>
</tr>
<tr>
  <th>type[T.offroad]</th>                 <td>    0.3700</td> <td>    0.041</td> <td>    9.032</td> <td> 0.000</td> <td>    0.290</td> <td>    0.450</td>
</tr>
<tr>
  <th>type[T.other]</th>                   <td>    0.4613</td> <td>    0.013</td> <td>   35.771</td> <td> 0.000</td> <td>    0.436</td> <td>    0.487</td>
</tr>
<tr>
  <th>type[T.pickup]</th>                  <td>    0.3509</td> <td>    0.009</td> <td>   39.562</td> <td> 0.000</td> <td>    0.334</td> <td>    0.368</td>
</tr>
<tr>
  <th>type[T.sedan]</th>                   <td>   -0.0576</td> <td>    0.007</td> <td>   -8.284</td> <td> 0.000</td> <td>   -0.071</td> <td>   -0.044</td>
</tr>
<tr>
  <th>type[T.truck]</th>                   <td>    0.2246</td> <td>    0.009</td> <td>   25.804</td> <td> 0.000</td> <td>    0.208</td> <td>    0.242</td>
</tr>
<tr>
  <th>type[T.van]</th>                     <td>    0.0404</td> <td>    0.014</td> <td>    2.911</td> <td> 0.004</td> <td>    0.013</td> <td>    0.068</td>
</tr>
<tr>
  <th>type[T.wagon]</th>                   <td>   -0.0903</td> <td>    0.014</td> <td>   -6.396</td> <td> 0.000</td> <td>   -0.118</td> <td>   -0.063</td>
</tr>
<tr>
  <th>year</th>                            <td>    0.5380</td> <td>    0.002</td> <td>  228.278</td> <td> 0.000</td> <td>    0.533</td> <td>    0.543</td>
</tr>
<tr>
  <th>odometer</th>                        <td>   -0.0952</td> <td>    0.002</td> <td>  -40.465</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.091</td>
</tr>
<tr>
  <th>cylinders</th>                       <td>    0.2304</td> <td>    0.003</td> <td>   73.514</td> <td> 0.000</td> <td>    0.224</td> <td>    0.236</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>24476.739</td> <th>  Durbin-Watson:     </th>  <td>   1.997</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>686367.240</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 0.676</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>16.284</td>   <th>  Cond. No.          </th>  <td>    240.</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>
</div>
<div class="cell markdown" id="-vE71Q6UGU7k">
<p>This has a low p-value for all of our predictors, except a vehicle
type of hatchback or mini-van and a handful of manufacturers. Let's see
if we can get more information from the MSE, RMSE, and <span
class="math inline"><em>R</em><sup>2</sup></span> statistics for this
model.</p>
</div>
<div class="cell code" data-execution_count="32" id="M-SdmFn44xuH">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, model.predict(X_train))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, model.predict(X_test))</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, model.predict(X_train))</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, model.predict(X_test))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="OU4S4ornP4mL" data-outputId="b2c1de3e-f7bd-470a-80ea-2061a32a93b0">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of linear model on training data is:&quot;</span>, msetrain)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of linear model on test data is:&quot;</span>, msetest)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of linear model on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of linear model on test data is:&quot;</span>, rmsetest)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of linear model on training data is:&quot;</span>, r2train)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of linear model on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of linear model on training data is: 0.39402592697638356
MSE of linear model on test data is: 0.4140434297320292

RMSE of linear model on training data is: 0.6277148452732209
RMSE of linear model on test data is: 0.6434620654957285

R^2 score of linear model on training data is: 0.6027009671750871
R^2 score of linear model on test data is: 0.5991588069773699
</code></pre>
</div>
</div>
<div class="cell markdown" id="r6yVr1GXEDAI">
<p>The MSE for this model is fairly low. The <span
class="math inline"><em>R</em><sup>2</sup></span> value is good, but
leaves room for improvement. One possible way to change the model is
through feature selection since we know there are a few features that
are not significant to price. Let's try Lasso Regression.</p>
</div>
<section id="lasso-regression" class="cell markdown" id="24kWnrpy_05s">
<h2>Lasso Regression</h2>
</section>
<div class="cell markdown" id="jZtWcTCa_9oU">
<p>Perhaps we need to perform feature selection to better fit our data.
We will use Lasso Regression to perform feature selection. For more
detailed information on Lasso Regression, see this helpful <a
href="https://www.ibm.com/topics/lasso-regression">introduction to Lasso
Regression</a>.</p>
</div>
<div class="cell code" data-execution_count="34" id="6vEuY7yEBMs3">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.get_dummies(model_data.drop(<span class="st">&#39;price&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model_data[<span class="st">&#39;price&#39;</span>]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ZYXYWtOg-VbP" data-outputId="2d8832b2-046a-4643-e5db-97f2e695c297">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Lasso Regression</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>lasso_model <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.0005</span>, fit_intercept<span class="op">=</span><span class="va">True</span>, max_iter<span class="op">=</span><span class="dv">10000</span>).fit(X_train, y_train)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>lasso_model.coef_</span></code></pre></div>
<div class="output execute_result" data-execution_count="35">
<pre><code>array([ 0.00000000e+00,  5.36885806e-01, -9.63525894e-02,  2.38092734e-01,
        7.88910161e-02,  0.00000000e+00,  0.00000000e+00,  3.15289886e-02,
       -8.63965796e-03,  0.00000000e+00,  3.94710498e-02, -6.29542698e-02,
       -1.54108119e-01, -2.17832964e-01,  3.00119498e+00, -8.69706585e-02,
       -9.14256589e-02, -0.00000000e+00,  0.00000000e+00,  5.96846990e-02,
       -1.34568406e-01, -0.00000000e+00,  2.92715136e-02,  8.30896600e-02,
       -1.80470167e-01,  2.99074142e-01,  2.71258267e-01,  9.42816982e-02,
       -3.07673112e-03,  1.45225730e-01, -0.00000000e+00,  0.00000000e+00,
       -5.54843418e-02, -1.72863354e-01,  0.00000000e+00,  8.42200852e-01,
       -4.63843667e-02,  0.00000000e+00, -5.21466119e-03,  0.00000000e+00,
        1.75203248e-01, -9.18716077e-02,  0.00000000e+00,  4.30322684e-01,
        2.83972013e-02, -3.12908849e-01,  0.00000000e+00,  4.68994421e-02,
        2.69853354e-03, -6.92349900e-02, -0.00000000e+00,  0.00000000e+00,
       -1.25696694e-01,  4.15938867e-02,  5.97343534e-02, -0.00000000e+00,
       -0.00000000e+00, -6.72436076e-03,  0.00000000e+00, -1.03604458e-01,
        4.06396038e-02, -2.26187256e-01, -5.60136754e-02,  0.00000000e+00,
       -6.68843961e-02,  0.00000000e+00, -1.76869237e-02, -4.87505284e-02,
        0.00000000e+00,  8.03346992e-03,  7.13621745e-03, -0.00000000e+00,
        0.00000000e+00, -0.00000000e+00, -7.61188673e-03, -0.00000000e+00,
        1.13654483e-02, -3.32466902e-03, -1.04320144e-01, -4.52595150e-01,
        7.62616064e-02,  0.00000000e+00, -0.00000000e+00, -5.02478384e-03,
       -0.00000000e+00,  4.75843794e-02, -7.28844654e-02,  9.87796535e-03,
        2.78248523e-02, -5.18491023e-03,  1.46562901e-01,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -1.28631122e-01, -1.76634438e-01,
        2.33860015e-02,  1.02017870e-02,  0.00000000e+00, -6.67940680e-02,
        6.87163730e-01,  0.00000000e+00, -1.17917254e-01, -9.69884967e-02,
        0.00000000e+00,  2.54345792e-02, -1.89763514e-01,  0.00000000e+00,
       -3.41285545e-02, -8.09082767e-02,  5.40649696e-01,  4.02056908e-01,
       -5.24105215e-02, -4.11908828e-02,  1.47290417e-01,  4.10047671e-01,
        2.91378769e-01, -8.47404567e-02,  1.66644155e-01, -0.00000000e+00,
       -1.10700758e-01])</code></pre>
</div>
</div>
<div class="cell markdown" id="muPf3HAEU78V">
<p>We can see that not every feature has been selected (some features
have a coefficient of 0). Let's see if this improved the fit of our
model by looking at MSE, RMSE, and <span
class="math inline"><em>R</em><sup>2</sup></span> values.</p>
</div>
<div class="cell code" data-execution_count="36" id="htUjwlnZQLU2">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, lasso_model.predict(X_train))</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, lasso_model.predict(X_test))</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, lasso_model.predict(X_train))</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, lasso_model.predict(X_test))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="37"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IIhYSwBHQW9w" data-outputId="2622dfa6-5391-457c-b54e-014db307a5ac">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on training data is:&quot;</span>, msetrain)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on test data is:&quot;</span>, msetest)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on test data is:&quot;</span>, rmsetest)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on training data is:&quot;</span>, r2train)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of lasso regression on training data is: 0.3979560717239735
MSE of lasso regression on test data is: 0.4173643400311472

RMSE of lasso regression on training data is: 0.6308375953634766
RMSE of lasso regression on test data is: 0.6460374138013582

R^2 score of lasso regression on training data is: 0.5987381753886143
R^2 score of lasso regression on test data is: 0.595943787608312
</code></pre>
</div>
</div>
<div class="cell markdown" id="4CfHTtmfDpPc">
<p>Our <span class="math inline"><em>R</em><sup>2</sup></span> test
score is not larger than for linear regression, so this model does not
explain the variability in our data better than linear regression. We
also see that the training and test MSEs and RMSEs are comparable to our
original linear model. Perhaps another modeling technique will better
improve our price prediction.</p>
</div>
<section id="knn" class="cell markdown" id="Kz9gENA14OEW">
<h2>KNN</h2>
</section>
<div class="cell markdown" id="O7dDuL1RlW6j">
<p>We will now try K-Nearest Neighbors to model our data and predict
price.</p>
</div>
<div class="cell code" data-execution_count="38" id="OzeXr2pV4R1f">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> knn.predict(X_train)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="39" id="H6D15TVlr077">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, y_pred_train)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, y_pred_train)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, y_pred)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="E2aUWrBcr45R" data-outputId="308c19cd-1a25-41cc-8d26-914b90c68b0b">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on training data is:&quot;</span>, msetrain)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on test data is:&quot;</span>, msetest)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on test data is:&quot;</span>, rmsetest)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on training data is:&quot;</span>, r2train)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of lasso regression on training data is: 0.15073245227815854
MSE of lasso regression on test data is: 0.2480829963130855

RMSE of lasso regression on training data is: 0.3882427749207428
RMSE of lasso regression on test data is: 0.49807930725245503

R^2 score of lasso regression on training data is: 0.8480154390727972
R^2 score of lasso regression on test data is: 0.7598274068130361
</code></pre>
</div>
</div>
<div class="cell markdown" id="Cc7kJbGZnB8x">
<p>We can see that KNN has a higher <span
class="math inline"><em>R</em><sup>2</sup></span> and lower MSE and RMSE
than our OLS and Lasso Regressors. Therefore, KNN better models our
data.</p>
</div>
<section id="random-forest-tree" class="cell markdown"
id="RWht73whUTKA">
<h3>Random Forest Tree</h3>
</section>
<div class="cell markdown" id="bjt2qaP2lei7">
<p>We will now try Random Forests to model our data and predict
price.</p>
</div>
<div class="cell code" data-execution_count="41"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="C4kDVLHnIGRO" data-outputId="8c4e487b-a62f-4415-a08e-66648a220b00">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> train_df.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;object&#39;</span>]).columns</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> categorical_cols:</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    train_df.loc[:, col] <span class="op">=</span> le.fit_transform(train_df[col])</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> train_df</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>model_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="41">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>-0.080792</td>
      <td>0.235819</td>
      <td>0.133530</td>
      <td>0.040827</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>10</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.875440</td>
      <td>0.033917</td>
      <td>-0.230876</td>
      <td>1.300959</td>
      <td>13</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.361285</td>
      <td>0.841524</td>
      <td>-0.471730</td>
      <td>0.040827</td>
      <td>7</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.391466</td>
      <td>1.447230</td>
      <td>-0.388770</td>
      <td>0.040827</td>
      <td>36</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>10</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.022666</td>
      <td>0.841524</td>
      <td>-0.546677</td>
      <td>0.040827</td>
      <td>7</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="42" id="2kYrl-r4aJMm">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>md <span class="op">=</span> model_data</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> md.pop(<span class="st">&#39;price&#39;</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> md</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="43" id="EO1KskrgodJR">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># param_grid = {</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     &#39;n_estimators&#39;: [50],</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     &#39;min_samples_leaf&#39;: [10, 20, 40],</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     &#39;max_depth&#39;: [10, 20, 30]</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">100</span>],</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>],</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;bootstrap&#39;</span>: [<span class="va">True</span>, <span class="va">False</span>]</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> grid_search.best_params_</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters:&quot;</span>, grid_search.best_params_)</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best score:&quot;</span>, np.sqrt(<span class="op">-</span>grid_search.best_score_))</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/Users/akshitsanoria/Library/Python/3.12/lib/python/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Best parameters: {&#39;bootstrap&#39;: True, &#39;max_depth&#39;: 30, &#39;min_samples_leaf&#39;: 1, &#39;n_estimators&#39;: 100}
Best score: 0.4146053430757306
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="44" id="fldg51j-omNE">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(<span class="op">**</span>best_params)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(X_train, y_train)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="45" id="Ik6mNvf0o46F">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>train_predictions <span class="op">=</span> model.predict(X_train)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>r2_trainRF <span class="op">=</span> r2_score(y_train, train_predictions)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(X_test)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>r2_testRF <span class="op">=</span> r2_score(y_test, predictions)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="46" id="WCR_HXwwrwo2">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>mse_trainRF <span class="op">=</span> mean_squared_error(y_train, train_predictions)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>mse_testRF <span class="op">=</span> mean_squared_error(y_test, predictions)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="47" id="B3M_CS4Aq07T">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;r2 score of Random Forest Regressor model on training data is:&quot;</span>, r2_trainRF)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;r2 score of Random Forest Regressor model on test data is:&quot;</span>, r2_trainRF)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE for the training data: </span><span class="sc">{</span>mse_trainRF<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE for the testing data: </span><span class="sc">{</span>mse_testRF<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>r2 score of Random Forest Regressor model on training data is: 0.9763225405823523
r2 score of Random Forest Regressor model on test data is: 0.9763225405823523
MSE for the training data: 0.023482395185179732
MSE for the testing data: 0.16053359024652747
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="48" id="1HnB6H1Krv8F">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>rmse_trainRF <span class="op">=</span> np.sqrt(mse_trainRF)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>rmse_testRF <span class="op">=</span> np.sqrt(mse_testRF)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE for the training data: </span><span class="sc">{</span>rmse_trainRF<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE for the testing data: </span><span class="sc">{</span>rmse_testRF<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE for the training data: 0.15323966583486057
RMSE for the testing data: 0.40066643264257545
</code></pre>
</div>
</div>
<div class="cell markdown" id="ygzbVCIBs5Jv">
<p>Model's predictions deviate from the actual prices by about 3960
units in the training set and 4585 units in the testing set</p>
</div>
<div class="cell code" data-execution_count="49"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="OESl6nJ-jbft" data-outputId="36862370-7d28-45ca-b0e3-5321712a96a7">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>model_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="49">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>0.235819</td>
      <td>0.133530</td>
      <td>0.040827</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>10</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.033917</td>
      <td>-0.230876</td>
      <td>1.300959</td>
      <td>13</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.841524</td>
      <td>-0.471730</td>
      <td>0.040827</td>
      <td>7</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.447230</td>
      <td>-0.388770</td>
      <td>0.040827</td>
      <td>36</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>10</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.841524</td>
      <td>-0.546677</td>
      <td>0.040827</td>
      <td>7</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lqsBm6JymKQ-" data-outputId="22587558-afe3-4c9e-e618-e77b68f43bcd">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>y</span></code></pre></div>
<div class="output execute_result" data-execution_count="50">
<pre><code>4        -0.080792
5         0.875440
6         1.361285
7         1.391466
8         1.022666
            ...   
426833    1.758795
426839    1.243504
426847    1.287672
426848    0.551543
426851    0.949053
Name: price, Length: 115497, dtype: float64</code></pre>
</div>
</div>
<section id="neural-network" class="cell markdown" id="xFlNaLvQzz43">
<h2>Neural Network</h2>
</section>
<div class="cell markdown" id="OlulrIqNllVU">
<p>We will now create a Neural Network to model our data and predict
price.</p>
</div>
<div class="cell code" data-execution_count="51"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="Y4-0UDT4-XWi" data-outputId="2f54c48c-69a0-4288-9e4d-246dc5801aea">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model_data</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling the features since they have different magnitudes</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural network model, activation used is relu (most common)</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>[X_train.shape[<span class="dv">1</span>]]),</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.3</span>),</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.3</span>),</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">1</span>)</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;mean_squared_error&#39;</span>)</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model and save the training history (change epochs to 50 later)</span></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train_scaled, y_train, epochs<span class="op">=</span><span class="dv">400</span>, batch_size<span class="op">=</span><span class="dv">256</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Model evaluation</span></span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> model.evaluate(X_test_scaled, y_test)</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for the test: </span><span class="sc">{</span>test_loss<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the loss over epochs</span></span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epochs&#39;</span>)</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loss Over Epochs&#39;</span>)</span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 1/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.5146 - val_loss: 0.3470
Epoch 2/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3795 - val_loss: 0.3417
Epoch 3/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3722 - val_loss: 0.3295
Epoch 4/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3558 - val_loss: 0.3214
Epoch 5/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3615 - val_loss: 0.3272
Epoch 6/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3539 - val_loss: 0.3286
Epoch 7/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3560 - val_loss: 0.3172
Epoch 8/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3535 - val_loss: 0.3125
Epoch 9/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3568 - val_loss: 0.3110
Epoch 10/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3369 - val_loss: 0.3097
Epoch 11/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3382 - val_loss: 0.3135
Epoch 12/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3367 - val_loss: 0.3231
Epoch 13/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3363 - val_loss: 0.3012
Epoch 14/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3456 - val_loss: 0.2971
Epoch 15/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3408 - val_loss: 0.3012
Epoch 16/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3229 - val_loss: 0.2945
Epoch 17/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3232 - val_loss: 0.2968
Epoch 18/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3219 - val_loss: 0.2921
Epoch 19/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3258 - val_loss: 0.2919
Epoch 20/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3210 - val_loss: 0.2939
Epoch 21/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3160 - val_loss: 0.2873
Epoch 22/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3118 - val_loss: 0.2877
Epoch 23/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3125 - val_loss: 0.2842
Epoch 24/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3107 - val_loss: 0.2838
Epoch 25/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3040 - val_loss: 0.2827
Epoch 26/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3059 - val_loss: 0.2799
Epoch 27/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3033 - val_loss: 0.2811
Epoch 28/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3029 - val_loss: 0.2823
Epoch 29/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3017 - val_loss: 0.2813
Epoch 30/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3036 - val_loss: 0.2797
Epoch 31/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2918 - val_loss: 0.2753
Epoch 32/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.3064 - val_loss: 0.2774
Epoch 33/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2970 - val_loss: 0.2762
Epoch 34/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3034 - val_loss: 0.2764
Epoch 35/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2895 - val_loss: 0.2733
Epoch 36/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.3013 - val_loss: 0.2719
Epoch 37/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2905 - val_loss: 0.2717
Epoch 38/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2968 - val_loss: 0.2723
Epoch 39/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2927 - val_loss: 0.2734
Epoch 40/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2901 - val_loss: 0.2681
Epoch 41/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2901 - val_loss: 0.2709
Epoch 42/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2944 - val_loss: 0.2698
Epoch 43/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2892 - val_loss: 0.2700
Epoch 44/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2918 - val_loss: 0.2663
Epoch 45/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2874 - val_loss: 0.2659
Epoch 46/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2872 - val_loss: 0.2653
Epoch 47/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2866 - val_loss: 0.2695
Epoch 48/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2858 - val_loss: 0.2663
Epoch 49/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2943 - val_loss: 0.2700
Epoch 50/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2845 - val_loss: 0.2630
Epoch 51/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2858 - val_loss: 0.2636
Epoch 52/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2773 - val_loss: 0.2625
Epoch 53/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2838 - val_loss: 0.2640
Epoch 54/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2881 - val_loss: 0.2639
Epoch 55/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2775 - val_loss: 0.2630
Epoch 56/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2913 - val_loss: 0.2592
Epoch 57/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2890 - val_loss: 0.2591
Epoch 58/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2837 - val_loss: 0.2649
Epoch 59/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2743 - val_loss: 0.2600
Epoch 60/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2795 - val_loss: 0.2625
Epoch 61/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2844 - val_loss: 0.2638
Epoch 62/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2768 - val_loss: 0.2579
Epoch 63/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2766 - val_loss: 0.2595
Epoch 64/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2829 - val_loss: 0.2593
Epoch 65/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2781 - val_loss: 0.2614
Epoch 66/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2765 - val_loss: 0.2568
Epoch 67/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2800 - val_loss: 0.2575
Epoch 68/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2799 - val_loss: 0.2587
Epoch 69/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2748 - val_loss: 0.2643
Epoch 70/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2708 - val_loss: 0.2570
Epoch 71/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2664 - val_loss: 0.2602
Epoch 72/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2818 - val_loss: 0.2550
Epoch 73/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2655 - val_loss: 0.2566
Epoch 74/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2819 - val_loss: 0.2602
Epoch 75/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2698 - val_loss: 0.2550
Epoch 76/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2714 - val_loss: 0.2567
Epoch 77/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2708 - val_loss: 0.2541
Epoch 78/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2688 - val_loss: 0.2614
Epoch 79/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2811 - val_loss: 0.2546
Epoch 80/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2735 - val_loss: 0.2553
Epoch 81/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2818 - val_loss: 0.2544
Epoch 82/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2730 - val_loss: 0.2521
Epoch 83/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2650 - val_loss: 0.2548
Epoch 84/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2755 - val_loss: 0.2521
Epoch 85/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2742 - val_loss: 0.2521
Epoch 86/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2725 - val_loss: 0.2493
Epoch 87/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2697 - val_loss: 0.2571
Epoch 88/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2715 - val_loss: 0.2557
Epoch 89/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2655 - val_loss: 0.2525
Epoch 90/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2675 - val_loss: 0.2540
Epoch 91/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2662 - val_loss: 0.2530
Epoch 92/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2700 - val_loss: 0.2502
Epoch 93/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2670 - val_loss: 0.2513
Epoch 94/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2729 - val_loss: 0.2525
Epoch 95/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2673 - val_loss: 0.2517
Epoch 96/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2729 - val_loss: 0.2531
Epoch 97/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2742 - val_loss: 0.2495
Epoch 98/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2595 - val_loss: 0.2504
Epoch 99/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2654 - val_loss: 0.2504
Epoch 100/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2605 - val_loss: 0.2542
Epoch 101/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2786 - val_loss: 0.2461
Epoch 102/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2577 - val_loss: 0.2496
Epoch 103/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2762 - val_loss: 0.2492
Epoch 104/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2610 - val_loss: 0.2502
Epoch 105/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2697 - val_loss: 0.2514
Epoch 106/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2667 - val_loss: 0.2507
Epoch 107/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2659 - val_loss: 0.2527
Epoch 108/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2606 - val_loss: 0.2548
Epoch 109/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2708 - val_loss: 0.2490
Epoch 110/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2641 - val_loss: 0.2482
Epoch 111/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2606 - val_loss: 0.2481
Epoch 112/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2539 - val_loss: 0.2493
Epoch 113/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2625 - val_loss: 0.2475
Epoch 114/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2613 - val_loss: 0.2470
Epoch 115/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2628 - val_loss: 0.2476
Epoch 116/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2684 - val_loss: 0.2483
Epoch 117/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2688 - val_loss: 0.2474
Epoch 118/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2525 - val_loss: 0.2458
Epoch 119/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2652 - val_loss: 0.2497
Epoch 120/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2584 - val_loss: 0.2481
Epoch 121/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2552 - val_loss: 0.2449
Epoch 122/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2595 - val_loss: 0.2461
Epoch 123/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2647 - val_loss: 0.2488
Epoch 124/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2569 - val_loss: 0.2511
Epoch 125/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2597 - val_loss: 0.2466
Epoch 126/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2633 - val_loss: 0.2461
Epoch 127/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2534 - val_loss: 0.2456
Epoch 128/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2542 - val_loss: 0.2434
Epoch 129/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2590 - val_loss: 0.2466
Epoch 130/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2561 - val_loss: 0.2412
Epoch 131/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2559 - val_loss: 0.2440
Epoch 132/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2615 - val_loss: 0.2430
Epoch 133/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2563 - val_loss: 0.2432
Epoch 134/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2683 - val_loss: 0.2437
Epoch 135/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2483 - val_loss: 0.2482
Epoch 136/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2563 - val_loss: 0.2484
Epoch 137/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2704 - val_loss: 0.2464
Epoch 138/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2589 - val_loss: 0.2442
Epoch 139/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2492 - val_loss: 0.2448
Epoch 140/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2571 - val_loss: 0.2423
Epoch 141/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2532 - val_loss: 0.2449
Epoch 142/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2571 - val_loss: 0.2422
Epoch 143/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2547 - val_loss: 0.2422
Epoch 144/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2443 - val_loss: 0.2441
Epoch 145/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2540 - val_loss: 0.2416
Epoch 146/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2527 - val_loss: 0.2412
Epoch 147/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2563 - val_loss: 0.2410
Epoch 148/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2568 - val_loss: 0.2417
Epoch 149/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2479 - val_loss: 0.2391
Epoch 150/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2540 - val_loss: 0.2433
Epoch 151/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2505 - val_loss: 0.2437
Epoch 152/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2677 - val_loss: 0.2423
Epoch 153/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2489 - val_loss: 0.2435
Epoch 154/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2538 - val_loss: 0.2404
Epoch 155/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2538 - val_loss: 0.2425
Epoch 156/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2482 - val_loss: 0.2412
Epoch 157/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2522 - val_loss: 0.2400
Epoch 158/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2537 - val_loss: 0.2391
Epoch 159/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2541 - val_loss: 0.2414
Epoch 160/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2465 - val_loss: 0.2444
Epoch 161/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2520 - val_loss: 0.2415
Epoch 162/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2514 - val_loss: 0.2399
Epoch 163/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2531 - val_loss: 0.2404
Epoch 164/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2449 - val_loss: 0.2401
Epoch 165/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2487 - val_loss: 0.2409
Epoch 166/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2608 - val_loss: 0.2461
Epoch 167/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2500 - val_loss: 0.2383
Epoch 168/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2537 - val_loss: 0.2395
Epoch 169/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2448 - val_loss: 0.2396
Epoch 170/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2525 - val_loss: 0.2403
Epoch 171/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2455 - val_loss: 0.2405
Epoch 172/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2576 - val_loss: 0.2373
Epoch 173/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2533 - val_loss: 0.2397
Epoch 174/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2462 - val_loss: 0.2402
Epoch 175/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2464 - val_loss: 0.2403
Epoch 176/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2504 - val_loss: 0.2402
Epoch 177/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2371 - val_loss: 0.2400
Epoch 178/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2518 - val_loss: 0.2427
Epoch 179/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2422 - val_loss: 0.2427
Epoch 180/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2442 - val_loss: 0.2391
Epoch 181/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2557 - val_loss: 0.2356
Epoch 182/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2538 - val_loss: 0.2365
Epoch 183/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2420 - val_loss: 0.2382
Epoch 184/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2580 - val_loss: 0.2404
Epoch 185/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2460 - val_loss: 0.2385
Epoch 186/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2526 - val_loss: 0.2392
Epoch 187/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2480 - val_loss: 0.2388
Epoch 188/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2532 - val_loss: 0.2354
Epoch 189/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2490 - val_loss: 0.2389
Epoch 190/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2479 - val_loss: 0.2394
Epoch 191/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2592 - val_loss: 0.2377
Epoch 192/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2464 - val_loss: 0.2417
Epoch 193/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2486 - val_loss: 0.2371
Epoch 194/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2460 - val_loss: 0.2375
Epoch 195/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2449 - val_loss: 0.2414
Epoch 196/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2494 - val_loss: 0.2370
Epoch 197/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2468 - val_loss: 0.2349
Epoch 198/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2478 - val_loss: 0.2402
Epoch 199/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2599 - val_loss: 0.2363
Epoch 200/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2395 - val_loss: 0.2353
Epoch 201/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2393 - val_loss: 0.2412
Epoch 202/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2469 - val_loss: 0.2367
Epoch 203/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2472 - val_loss: 0.2348
Epoch 204/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2460 - val_loss: 0.2386
Epoch 205/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2531 - val_loss: 0.2359
Epoch 206/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2400 - val_loss: 0.2364
Epoch 207/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2474 - val_loss: 0.2356
Epoch 208/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2455 - val_loss: 0.2357
Epoch 209/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2393 - val_loss: 0.2384
Epoch 210/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2443 - val_loss: 0.2347
Epoch 211/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2498 - val_loss: 0.2377
Epoch 212/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2325 - val_loss: 0.2399
Epoch 213/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2444 - val_loss: 0.2387
Epoch 214/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2404 - val_loss: 0.2368
Epoch 215/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2494 - val_loss: 0.2365
Epoch 216/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2447 - val_loss: 0.2350
Epoch 217/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2408 - val_loss: 0.2367
Epoch 218/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2488 - val_loss: 0.2375
Epoch 219/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2449 - val_loss: 0.2342
Epoch 220/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2457 - val_loss: 0.2351
Epoch 221/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2412 - val_loss: 0.2374
Epoch 222/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2449 - val_loss: 0.2352
Epoch 223/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2443 - val_loss: 0.2359
Epoch 224/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2415 - val_loss: 0.2339
Epoch 225/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2396 - val_loss: 0.2379
Epoch 226/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2408 - val_loss: 0.2383
Epoch 227/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2483 - val_loss: 0.2379
Epoch 228/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2471 - val_loss: 0.2353
Epoch 229/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2490 - val_loss: 0.2377
Epoch 230/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2401 - val_loss: 0.2387
Epoch 231/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2457 - val_loss: 0.2349
Epoch 232/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2367 - val_loss: 0.2296
Epoch 233/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2358 - val_loss: 0.2331
Epoch 234/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2360 - val_loss: 0.2371
Epoch 235/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2468 - val_loss: 0.2332
Epoch 236/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2409 - val_loss: 0.2359
Epoch 237/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2379 - val_loss: 0.2350
Epoch 238/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2421 - val_loss: 0.2354
Epoch 239/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2443 - val_loss: 0.2348
Epoch 240/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2420 - val_loss: 0.2358
Epoch 241/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2472 - val_loss: 0.2313
Epoch 242/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2363 - val_loss: 0.2372
Epoch 243/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2423 - val_loss: 0.2335
Epoch 244/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2364 - val_loss: 0.2345
Epoch 245/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2481 - val_loss: 0.2323
Epoch 246/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2370 - val_loss: 0.2342
Epoch 247/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2342 - val_loss: 0.2366
Epoch 248/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2524 - val_loss: 0.2349
Epoch 249/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2366 - val_loss: 0.2315
Epoch 250/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2388 - val_loss: 0.2336
Epoch 251/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2452 - val_loss: 0.2342
Epoch 252/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2441 - val_loss: 0.2314
Epoch 253/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2362 - val_loss: 0.2353
Epoch 254/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2456 - val_loss: 0.2330
Epoch 255/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2359 - val_loss: 0.2330
Epoch 256/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2430 - val_loss: 0.2331
Epoch 257/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2389 - val_loss: 0.2359
Epoch 258/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2395 - val_loss: 0.2339
Epoch 259/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2472 - val_loss: 0.2328
Epoch 260/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2328 - val_loss: 0.2347
Epoch 261/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2340 - val_loss: 0.2340
Epoch 262/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2410 - val_loss: 0.2375
Epoch 263/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2475 - val_loss: 0.2350
Epoch 264/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2392 - val_loss: 0.2327
Epoch 265/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2477 - val_loss: 0.2313
Epoch 266/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2377 - val_loss: 0.2315
Epoch 267/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2335 - val_loss: 0.2348
Epoch 268/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2462 - val_loss: 0.2374
Epoch 269/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2353 - val_loss: 0.2320
Epoch 270/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2405 - val_loss: 0.2326
Epoch 271/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2354 - val_loss: 0.2352
Epoch 272/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2343 - val_loss: 0.2339
Epoch 273/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2403 - val_loss: 0.2331
Epoch 274/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2353 - val_loss: 0.2312
Epoch 275/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2336 - val_loss: 0.2335
Epoch 276/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2291 - val_loss: 0.2351
Epoch 277/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2399 - val_loss: 0.2346
Epoch 278/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2436 - val_loss: 0.2351
Epoch 279/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2444 - val_loss: 0.2342
Epoch 280/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2367 - val_loss: 0.2322
Epoch 281/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2370 - val_loss: 0.2335
Epoch 282/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2387 - val_loss: 0.2324
Epoch 283/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2372 - val_loss: 0.2314
Epoch 284/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2379 - val_loss: 0.2332
Epoch 285/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2336 - val_loss: 0.2319
Epoch 286/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2453 - val_loss: 0.2322
Epoch 287/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2381 - val_loss: 0.2310
Epoch 288/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2453 - val_loss: 0.2311
Epoch 289/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2409 - val_loss: 0.2302
Epoch 290/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2265 - val_loss: 0.2332
Epoch 291/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2376 - val_loss: 0.2313
Epoch 292/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2366 - val_loss: 0.2332
Epoch 293/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2419 - val_loss: 0.2297
Epoch 294/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2305 - val_loss: 0.2317
Epoch 295/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2373 - val_loss: 0.2309
Epoch 296/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2357 - val_loss: 0.2323
Epoch 297/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2232 - val_loss: 0.2335
Epoch 298/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2364 - val_loss: 0.2306
Epoch 299/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2369 - val_loss: 0.2343
Epoch 300/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2309 - val_loss: 0.2322
Epoch 301/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2325 - val_loss: 0.2289
Epoch 302/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2291 - val_loss: 0.2328
Epoch 303/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2358 - val_loss: 0.2305
Epoch 304/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2305 - val_loss: 0.2265
Epoch 305/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2426 - val_loss: 0.2292
Epoch 306/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2355 - val_loss: 0.2298
Epoch 307/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2387 - val_loss: 0.2309
Epoch 308/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2408 - val_loss: 0.2287
Epoch 309/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2317 - val_loss: 0.2310
Epoch 310/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2345 - val_loss: 0.2280
Epoch 311/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2384 - val_loss: 0.2291
Epoch 312/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2330 - val_loss: 0.2337
Epoch 313/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2311 - val_loss: 0.2306
Epoch 314/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2295 - val_loss: 0.2348
Epoch 315/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2309 - val_loss: 0.2326
Epoch 316/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2309 - val_loss: 0.2296
Epoch 317/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2335 - val_loss: 0.2359
Epoch 318/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2333 - val_loss: 0.2306
Epoch 319/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2360 - val_loss: 0.2308
Epoch 320/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2331 - val_loss: 0.2319
Epoch 321/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2300 - val_loss: 0.2319
Epoch 322/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2314 - val_loss: 0.2285
Epoch 323/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2371 - val_loss: 0.2300
Epoch 324/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2343 - val_loss: 0.2314
Epoch 325/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2389 - val_loss: 0.2293
Epoch 326/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2362 - val_loss: 0.2303
Epoch 327/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2310 - val_loss: 0.2276
Epoch 328/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2338 - val_loss: 0.2306
Epoch 329/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2282 - val_loss: 0.2292
Epoch 330/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2265 - val_loss: 0.2298
Epoch 331/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2399 - val_loss: 0.2295
Epoch 332/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2313 - val_loss: 0.2284
Epoch 333/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2327 - val_loss: 0.2281
Epoch 334/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2311 - val_loss: 0.2282
Epoch 335/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2415 - val_loss: 0.2307
Epoch 336/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2378 - val_loss: 0.2271
Epoch 337/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2402 - val_loss: 0.2299
Epoch 338/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2432 - val_loss: 0.2295
Epoch 339/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2307 - val_loss: 0.2293
Epoch 340/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2344 - val_loss: 0.2267
Epoch 341/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2358 - val_loss: 0.2284
Epoch 342/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2426 - val_loss: 0.2310
Epoch 343/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2389 - val_loss: 0.2293
Epoch 344/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2357 - val_loss: 0.2270
Epoch 345/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2267 - val_loss: 0.2255
Epoch 346/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2301 - val_loss: 0.2323
Epoch 347/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2295 - val_loss: 0.2276
Epoch 348/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2264 - val_loss: 0.2283
Epoch 349/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2239 - val_loss: 0.2270
Epoch 350/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2250 - val_loss: 0.2261
Epoch 351/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2346 - val_loss: 0.2337
Epoch 352/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2303 - val_loss: 0.2293
Epoch 353/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2313 - val_loss: 0.2272
Epoch 354/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2324 - val_loss: 0.2268
Epoch 355/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2331 - val_loss: 0.2296
Epoch 356/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2244 - val_loss: 0.2270
Epoch 357/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2302 - val_loss: 0.2284
Epoch 358/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2357 - val_loss: 0.2269
Epoch 359/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2382 - val_loss: 0.2289
Epoch 360/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2278 - val_loss: 0.2263
Epoch 361/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2215 - val_loss: 0.2278
Epoch 362/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2249 - val_loss: 0.2298
Epoch 363/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2329 - val_loss: 0.2295
Epoch 364/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2234 - val_loss: 0.2261
Epoch 365/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2299 - val_loss: 0.2269
Epoch 366/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2324 - val_loss: 0.2286
Epoch 367/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2320 - val_loss: 0.2291
Epoch 368/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2367 - val_loss: 0.2315
Epoch 369/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2255 - val_loss: 0.2268
Epoch 370/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2291 - val_loss: 0.2287
Epoch 371/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2360 - val_loss: 0.2280
Epoch 372/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2243 - val_loss: 0.2261
Epoch 373/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2217 - val_loss: 0.2274
Epoch 374/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2371 - val_loss: 0.2268
Epoch 375/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2295 - val_loss: 0.2296
Epoch 376/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2243 - val_loss: 0.2272
Epoch 377/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2358 - val_loss: 0.2290
Epoch 378/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2256 - val_loss: 0.2276
Epoch 379/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2322 - val_loss: 0.2281
Epoch 380/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2455 - val_loss: 0.2277
Epoch 381/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2288 - val_loss: 0.2256
Epoch 382/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2279 - val_loss: 0.2271
Epoch 383/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2386 - val_loss: 0.2285
Epoch 384/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2314 - val_loss: 0.2307
Epoch 385/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2281 - val_loss: 0.2262
Epoch 386/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2313 - val_loss: 0.2238
Epoch 387/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2424 - val_loss: 0.2266
Epoch 388/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2379 - val_loss: 0.2288
Epoch 389/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2267 - val_loss: 0.2254
Epoch 390/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - loss: 0.2308 - val_loss: 0.2238
Epoch 391/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step - loss: 0.2285 - val_loss: 0.2296
Epoch 392/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.2320 - val_loss: 0.2299
Epoch 393/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2240 - val_loss: 0.2291
Epoch 394/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2273 - val_loss: 0.2261
Epoch 395/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2338 - val_loss: 0.2258
Epoch 396/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2252 - val_loss: 0.2275
Epoch 397/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2283 - val_loss: 0.2263
Epoch 398/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2297 - val_loss: 0.2261
Epoch 399/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.2315 - val_loss: 0.2251
Epoch 400/400
289/289 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.2278 - val_loss: 0.2260
722/722 ━━━━━━━━━━━━━━━━━━━━ 0s 294us/step - loss: 0.2311
MSE for the test: 0.23136460781097412
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_32fc8dc2e3fb4a948bcc04c0c4e09be0/10002ca21a894414910f124a75a34fc863900c0f.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="52" id="ka0ZMzCbvBSs">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># weights, biases = model.layers[0].get_weights()</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="co"># print(weights,biases )</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="53"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="82Cp5R_G5fRY" data-outputId="df64e993-a564-4578-b2de-c9f2fa944d38">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> model.predict(X_train_scaled)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test_scaled)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>train_mse <span class="op">=</span> mean_squared_error(y_train, y_train_pred)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> train_mse <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>train_r2 <span class="op">=</span> r2_score(y_train, y_train_pred)</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el Root Mean Squared Error (RMSE) para el conjunto de prueba</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>test_mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> test_mse <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>test_r2 <span class="op">=</span> r2_score(y_test, y_test_pred)</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for train: </span><span class="sc">{</span>train_mse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE for train: </span><span class="sc">{</span>train_rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;R2 for train: </span><span class="sc">{</span>train_r2<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for test: </span><span class="sc">{</span>test_mse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE for test: </span><span class="sc">{</span>test_rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;R2 for test: </span><span class="sc">{</span>test_r2<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>  89/2888 ━━━━━━━━━━━━━━━━━━━━ 1s 570us/step </code></pre>
</div>
<div class="output stream stdout">
<pre><code>2888/2888 ━━━━━━━━━━━━━━━━━━━━ 1s 379us/step
722/722 ━━━━━━━━━━━━━━━━━━━━ 0s 258us/step
MSE for train: 0.19468029745350293
RMSE for train: 0.44122590297205233
R2 for train: 0.8049596858622097
MSE for test: 0.23136465438130943
RMSE for test: 0.4810037987181696
R2 for test: 0.7703309804994096
</code></pre>
</div>
</div>
<section id="conclusion" class="cell markdown" id="ePHtO8Rlv8E0">
<h1><strong>Conclusion</strong></h1>
<p><strong><h3>Statistical Conclusions</h3></strong></p>
<p>When testing against test data, we found that our models had the
following MSE, RMSE and R2 scores:</p>
<table >
<tr>
<th>
<p>Model<th><th>MSE<th><th>RMSE<th><th>R2<th><tr> <tr> <td>Linear
Regression<td><td>0.414<td><td>0.634<td><td>0.599<td> <tr> <tr>
<td>Lasso Regression<td><td>0.417<td><td>0.646<td><td>0.596<td> <tr>
<tr> <td>KNN<td><td>0.248<td><td>0.498<td><td>0.760<td> <tr> <tr>
<td>Random Forest Tree<td><td>0.<td><td>0.<td><td>0.<td> <tr> <tr>
<td>Neural Network<td><td>0.446<td><td>0.234<td><td>0.768<td> <tr>
<table></p>
<p>Based off these statistics, we found that the <strong>KNN
model</strong> was the best model for predicting a used vehicle's price,
with a Mean Squared Error of 0.248, a Root Mean Squared Error of 0.498,
and a R2 Score of 0.760.</p>
<p><strong><h3>Importance</h3></strong></p>
<p>In summary, given the significant and growing reliance of used
vehicles in American daily life, and growing vehicle prices, it is more
important now than ever to navigate the automotive market effectively.
Our project aimed to meet this need by developing a reliable price
predictor for used cars, ensuring that people get a fair price on their
used vehicles. Ultimately, this project seeks to give individuals the
knowledge needed to make informed decisions when purchasing or selling a
car.</p>
</section>
</body>
</html>
