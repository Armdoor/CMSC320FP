<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Final Tutorial</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section
id="comprehensive-analysis-of-the-american-used-car-market-price-trends-and-predictive-modeling"
class="cell markdown" id="O-JBwqIMTXlw">
<h1>Comprehensive Analysis of the American Used Car Market: Price Trends
and Predictive Modeling</h1>
</section>
<div class="cell markdown" id="GQdc2Cw2Tl_T">
<p>Collaborators: Aarmabh Sanoria, Emily Sheridan, Lucia Soto Garcia,
Ammar Khawaja</p>
</div>
<section id="introduction" class="cell markdown" id="nVPplLIzC5l3">
<h1>Introduction</h1>
</section>
<div class="cell markdown" id="TeA4AJ6QC8mW">
<p>Daily travel in the US is largely dominated by cars. Cars are a
necessary part of American life due to the current state of public
transportation. Very few places in America can boast adequate public
transportation, and 45% of Americas have no access to public
transportation (Source: <a
href="https://www.apta.com/news-publications/public-transportation-facts/">APTA</a>).
As a result, the American commute is primarily made via car, with 76% of
American commuters using a personal vehicle to get to their workplace
(Source: <a
href="https://www.weforum.org/agenda/2022/05/commute-america-sustainability-cars/">World
Economic Forum</a>). For these Americans, their livelihood is tied to
access to a car.</p>
<p>In recent years, the spike in prices of new cars and trucks has
caused many Americans to look towards buying used cars when the need for
a new car arises (Sources: <a
href="https://www.cbsnews.com/newyork/news/car-values-increasing-along-with-demand-for-used-vehicles-average-years-on-the-road/">CBS</a>,
<a
href="https://www.majorworld.com/why-are-more-people-buying-used-cars-in-2024/">Major
World</a>). In 2023, the average price of a new car had increased by
around $10,000 since 2020, largely because of inflation and
manufacturing delays related to the COVID-19 pandemic (Source: <a
href="https://www.consumerreports.org/cars/buying-a-car/people-spending-more-on-new-cars-but-prices-not-necessarily-rising-a3134608893/">Consumer
Reports</a>). Many manufacturers have also divested from their more
affordable models in favor of models that produce more profit (Source:
<a
href="https://www.consumerreports.org/cars/buying-a-car/people-spending-more-on-new-cars-but-prices-not-necessarily-rising-a3134608893/">Consumer
Reports</a>).</p>
<p>Used car prices have also risen to meet the growing demand, but these
vehicles are still seen by many as a more affordable and adequate
alternative to a new vehicle.</p>
<p>In our project, we hope to develop a price predictor for used cars
based on a combination of various features, including the location of
car (state), the year the car was built, the manufacturer, the number of
miled on the car (odometer), etc. This price predictor could be useful
for people looking to sell used cars to ensure (1) they are asking a
reasonable price for their car and (2) they are receiving resonable
offers for their car to avoid low-balling from buyers. It could also be
useful for people looking to buy a used car to ensure that they are not
taken advantage of by sellers hiking up the price of their car.</p>
</div>
<div class="cell markdown" id="-EVDnsMRE8Bp">
<p>Over this tutorial we will be going through the Data Science
Lifecycle as following:</p>
<p>Data Collection</p>
<ul>
<li>Data Collection &amp; Data Processing</li>
<li>Data Visualization</li>
<li>Model: Analysis, Hypothesis Testing, &amp; ML</li>
<li>Interpretation: Insight &amp; Policy Decision</li>
</ul>
</div>
<section id="imports" class="cell markdown" id="xx23m12dKMZ5">
<h2><strong>Imports</strong></h2>
<p>We will start by including some libraries for our analysis</p>
</section>
<div class="cell code" data-execution_count="1" id="nvg8zyM3vBwN">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime <span class="im">as</span> dt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dateutil <span class="im">import</span> parser</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score, accuracy_score</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, StandardScaler</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> regularizers</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> joblib <span class="im">import</span> parallel_backend</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span></code></pre></div>
</div>
<section id="data-collection" class="cell markdown" id="tlyEMM23NvQw">
<h1><strong>Data Collection</strong></h1>
<p>The initial phase of our analysis involves data extraction. Our focus
will be on the collaboration between different regions, so it would be
beneficial to gather some general data on these regions, such as the
type of vehicles commonly found there. Although our current analysis
does not consider the state of the region, it might be intriguing to
incorporate this variable in future studies.</p>
<p>All the data was sourced from the following link which contains
information about various vehicles, their conditions, prices, and other
relevant details.</p>
<p>Data was downloaded from <a
href="https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data"
class="uri">https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data</a></p>
</section>
<div class="cell code" data-execution_count="2" id="lQWslMyUKLUs">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&#39;data.csv&#39;</span>, on_bad_lines<span class="op">=</span><span class="st">&#39;warn&#39;</span>)</span></code></pre></div>
</div>
<section id="data-processing" class="cell markdown" id="yObN2Tf3PmYr">
<h1><strong>Data Processing</strong></h1>
<p>Now that we have our dataframe we need to clean our dataset of
vehicle information. The primary focus is on correcting inconsistencies
in the column, replacing missing data, and removing unnecessary columns,
thereby preparing the data for further analysis or modeling.</p>
</section>
<div class="cell markdown" id="FJXEQShDY1GK">
<p>We'll begin by limiting our data to cars made in 2001 or later. This
was chosen because the average year in our dataset is 2011 and the
standard deviation is ~9.5 years. Rounding up to 10 years, one standard
deviation below the mean is 2001. Limiting our data to cars manufactured
after 2001 maintains 92.97% of our original data. We also exclude cars
produced in 2022 since we are interested in used cars. Moreover, we also
removed some columns whose information was not particularly
relevant.</p>
</div>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}"
id="7G3JBrKJZD_s" data-outputId="41268930-47d9-481f-a433-e10482e738fe">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data.drop(columns<span class="op">=</span>[<span class="st">&#39;id&#39;</span>,<span class="st">&#39;VIN&#39;</span>, <span class="st">&#39;paint_color&#39;</span>, <span class="st">&#39;lat&#39;</span>, <span class="st">&#39;long&#39;</span>, <span class="st">&#39;size&#39;</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="3">

  <div id="df-b9467b18-6ea6-4000-84fb-45c87bb0d160" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>odometer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4.268530e+05</td>
      <td>425675.000000</td>
      <td>4.224800e+05</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.520308e+04</td>
      <td>2011.235191</td>
      <td>9.804333e+04</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.218267e+07</td>
      <td>9.452120</td>
      <td>2.138815e+05</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000e+00</td>
      <td>1900.000000</td>
      <td>0.000000e+00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.900000e+03</td>
      <td>2008.000000</td>
      <td>3.770400e+04</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.395000e+04</td>
      <td>2013.000000</td>
      <td>8.554800e+04</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.648800e+04</td>
      <td>2017.000000</td>
      <td>1.335425e+05</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.736929e+09</td>
      <td>2022.000000</td>
      <td>1.000000e+07</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-b9467b18-6ea6-4000-84fb-45c87bb0d160')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-b9467b18-6ea6-4000-84fb-45c87bb0d160 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-b9467b18-6ea6-4000-84fb-45c87bb0d160');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-190c38a1-44a7-40c6-a778-1daaca7e7877">
  <button class="colab-df-quickchart" onclick="quickchart('df-190c38a1-44a7-40c6-a778-1daaca7e7877')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-190c38a1-44a7-40c6-a778-1daaca7e7877 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="FM6lJc-5QbY3">
<p>We now drop rows with missing data from our data frame. This still
leaves us with plenty of data to work with and avoids a false perception
of data.</p>
</div>
<div class="cell code" data-execution_count="4" id="8cStwmAwHZmG">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;year&#39;</span>]<span class="op">&gt;</span><span class="dv">2000</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;year&#39;</span>]<span class="op">&lt;</span><span class="dv">2022</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.dropna()</span></code></pre></div>
</div>
<div class="cell markdown" id="hO2cbTu3a5QZ">
<p>Because the type of information given by region varies (some values
are cities, some are states, some are parts of states, some are large
geographic regions, etc.), we will not use region in our data analysis.
Instead, we will use state to determine the geographic location of the
vehicle. Here, we drop region and format state values to be uppercase,
as is the standard for state abbreviations.</p>
</div>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="-OsE27EUbSea" data-outputId="24abf75a-3ffb-4fde-dae3-1590572ddfd9">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropping region &amp; formatting state</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data.drop(<span class="st">&#39;region&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;state&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;state&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.upper())</span></code></pre></div>
<div class="output stream stderr">
<pre><code>&lt;ipython-input-5-df9f8385ac89&gt;:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data.drop(&#39;region&#39;, axis=1, inplace=True)
&lt;ipython-input-5-df9f8385ac89&gt;:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data[&#39;state&#39;] = data[&#39;state&#39;].apply(lambda x: x.upper())
</code></pre>
</div>
</div>
<div class="cell markdown" id="td5RbcDdcs4o">
<p>We now want ensure consistent formatting of year and posting
date.</p>
</div>
<div class="cell code" data-execution_count="6" id="Re360fsPblmo">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set format of year and posting_date</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> pd.to_datetime(data[<span class="st">&#39;year&#39;</span>], <span class="bu">format</span><span class="op">=</span><span class="st">&#39;%Y&#39;</span>).dt.strftime(<span class="st">&#39;%Y&#39;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;posting_date&#39;</span>] <span class="op">=</span>  pd.to_datetime(data[<span class="st">&#39;posting_date&#39;</span>], utc<span class="op">=</span><span class="va">True</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;mixed&#39;</span>).dt.strftime(<span class="st">&#39;%m-</span><span class="sc">%d</span><span class="st">-%Y&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="-dowxU3wfY-c">
<p>We next add a column for car age, which is calculated by subtracting
the model year from the year of posting (2021). If the model is 2022,
the car age is set to 0. If the age is unknown, it is also set to 0.</p>
</div>
<div class="cell code" data-execution_count="7" id="aTM7uthUfXwV">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate car age based on posting date and year</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>data.loc[:, <span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;posting_date&#39;</span>].<span class="bu">str</span>[<span class="op">-</span><span class="dv">4</span>:].astype(<span class="bu">float</span>) <span class="op">-</span> data[<span class="st">&#39;year&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Replacing cars with negative or no age to have age of 0</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;car_age&#39;</span>].replace(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;car_age&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;car_age&#39;</span>].replace(np.nan, <span class="fl">0.0</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Rearranging the columns for organization</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[[<span class="st">&#39;state&#39;</span>, <span class="st">&#39;price&#39;</span>, <span class="st">&#39;year&#39;</span>, <span class="st">&#39;car_age&#39;</span>, <span class="st">&#39;manufacturer&#39;</span>, <span class="st">&#39;model&#39;</span>, <span class="st">&#39;condition&#39;</span>, <span class="st">&#39;odometer&#39;</span>, <span class="st">&#39;title_status&#39;</span>, <span class="st">&#39;transmission&#39;</span>, <span class="st">&#39;posting_date&#39;</span>,<span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;fuel&#39;</span>, <span class="st">&#39;drive&#39;</span>, <span class="st">&#39;type&#39;</span>]]</span></code></pre></div>
</div>
<div class="cell markdown" id="zrqkkRHTfyLY">
<p>Now we will format the cylinder column to contain only an integer
representing the number of cylinders.</p>
</div>
<div class="cell code" data-execution_count="8" id="yAEQTklwhGyx">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;cylinders&#39;</span>] <span class="op">!=</span> <span class="st">&#39;other&#39;</span>]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data.loc[:,<span class="st">&#39;cylinders&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;cylinders&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">int</span>(x.split(<span class="st">&#39; &#39;</span>)[<span class="dv">0</span>]))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;cylinders&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;cylinders&#39;</span>].astype(<span class="bu">int</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="DeWJS6mDn41K">
<p>We now move on to properly format the manufacturer column to
capitalize the brand names.</p>
</div>
<div class="cell code" data-execution_count="9" id="8-izoGWan5PM">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Format manufacturers</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace(a,b):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&quot;manufacturer&quot;</span>].replace(a,b,inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyphonated/Two Word Names</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;mercedes-benz&#39;</span>,<span class="st">&#39;Mercedes-Benz&#39;</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;alfa-romeo&#39;</span>,<span class="st">&#39;Alfa-Romeo&#39;</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;harley-davidson&#39;</span>,<span class="st">&#39;Harley-Davidson&#39;</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;aston-marin&#39;</span>,<span class="st">&#39;Aston-Martin&#39;</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;land rover&#39;</span>,<span class="st">&#39;Land Rover&#39;</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># All Caps</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;gmc&#39;</span>, <span class="st">&quot;GMC&quot;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;bmw&#39;</span>, <span class="st">&#39;BMW&#39;</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Based on car models, &#39;rover&#39; is &#39;land rover&#39;</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>replace(<span class="st">&#39;rover&#39;</span>,<span class="st">&#39;Land Rover&#39;</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Capitalize every manufacturer that is not already formatted</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;manufacturer&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;manufacturer&quot;</span>].astype(<span class="bu">str</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.capitalize() <span class="cf">if</span> x <span class="kw">and</span> <span class="kw">not</span> x[<span class="dv">0</span>].isupper() <span class="cf">else</span> x)</span></code></pre></div>
</div>
<div class="cell markdown" id="WEQLsT3ctbdF">
<p>Next, we'll ensure that the dtype of year is an integer.</p>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="8ICdCCqvtosH" data-outputId="85b81527-fd41-45de-d1ce-86dd140a81e6">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>data.dtypes</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">
<pre><code>state            object
price             int64
year             object
car_age         float64
manufacturer     object
model            object
condition        object
odometer        float64
title_status     object
transmission     object
posting_date     object
cylinders         int64
fuel             object
drive            object
type             object
dtype: object</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="11" id="cmrJSmtqtb20">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_type_chnge(ch):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  data[ch] <span class="op">=</span> pd.to_numeric(data[ch], errors<span class="op">=</span><span class="st">&#39;coerce&#39;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  data[ch].fillna(<span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  data[ch] <span class="op">=</span> data[ch].astype(<span class="bu">int</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>chn<span class="op">=</span> [<span class="st">&#39;year&#39;</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> chn:</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  data_type_chnge(i)</span></code></pre></div>
</div>
<div class="cell markdown" id="2tz1-L5dZpCu">
<p>We noticed a handful of outliers with prices that are beyond
reasonable. We drop these outliers here.</p>
</div>
<div class="cell code" data-execution_count="12" id="QNWO7oUWZoOo">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>data[data[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> <span class="dv">1000000</span>] <span class="co"># Outliers</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">&#39;price&#39;</span>] <span class="op">&lt;</span> <span class="dv">1000000</span>] <span class="co"># Drop the outliers</span></span></code></pre></div>
</div>
<div class="cell markdown" id="HSx-90V2TnYW">
<p>After cleaning, we are left with 115,497 data observations. Our
dataframe is the following format:</p>
</div>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:223}"
id="jlP2d1hhh_Ay" data-outputId="34ad5b6a-b036-4045-e213-0af580dc2b58">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Dimensions: </span><span class="sc">{}</span><span class="st"> x </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(data.shape[<span class="dv">0</span>], data.shape[<span class="dv">1</span>]))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>data.head(<span class="dv">5</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Dimensions: 115497 x 15
</code></pre>
</div>
<div class="output execute_result" data-execution_count="13">

  <div id="df-a962e82a-6842-483a-92a3-01e041fcdfaf" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>price</th>
      <th>year</th>
      <th>car_age</th>
      <th>manufacturer</th>
      <th>model</th>
      <th>condition</th>
      <th>odometer</th>
      <th>title_status</th>
      <th>transmission</th>
      <th>posting_date</th>
      <th>cylinders</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>15000</td>
      <td>2013</td>
      <td>8.0</td>
      <td>Ford</td>
      <td>f-150 xlt</td>
      <td>excellent</td>
      <td>128000.0</td>
      <td>clean</td>
      <td>automatic</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>rwd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>5</th>
      <td>AL</td>
      <td>27990</td>
      <td>2012</td>
      <td>9.0</td>
      <td>GMC</td>
      <td>sierra 2500 hd extended cab</td>
      <td>good</td>
      <td>68696.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>8</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>6</th>
      <td>AL</td>
      <td>34590</td>
      <td>2016</td>
      <td>5.0</td>
      <td>Chevrolet</td>
      <td>silverado 1500 double</td>
      <td>good</td>
      <td>29499.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>7</th>
      <td>AL</td>
      <td>35000</td>
      <td>2019</td>
      <td>2.0</td>
      <td>Toyota</td>
      <td>tacoma</td>
      <td>excellent</td>
      <td>43000.0</td>
      <td>clean</td>
      <td>automatic</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>8</th>
      <td>AL</td>
      <td>29990</td>
      <td>2016</td>
      <td>5.0</td>
      <td>Chevrolet</td>
      <td>colorado extended cab</td>
      <td>good</td>
      <td>17302.0</td>
      <td>clean</td>
      <td>other</td>
      <td>05-03-2021</td>
      <td>6</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-a962e82a-6842-483a-92a3-01e041fcdfaf')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-a962e82a-6842-483a-92a3-01e041fcdfaf button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-a962e82a-6842-483a-92a3-01e041fcdfaf');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-d2163aad-4678-40f6-bd02-1c489886b051">
  <button class="colab-df-quickchart" onclick="quickchart('df-d2163aad-4678-40f6-bd02-1c489886b051')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-d2163aad-4678-40f6-bd02-1c489886b051 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<section id="data-visualization" class="cell markdown"
id="IkRltsCS3Iq8">
<h1><strong>Data Visualization</strong></h1>
<p>Data visualization plays a crucial role in understanding the
underlying patterns and insights within our dataset. By visually
representing the data, we can more easily identify trends, outliers, and
distributions that might not be apparent from raw data alone. In this
section, we explore various aspects of the used car market, including
manufacturer popularity, price depreciation by car age, and regional
price variations. Each visualization is designed to help us draw
meaningful conclusions that can inform both sellers and buyers in the
used car market.</p>
</section>
<div class="cell markdown" id="ItueCAfAeRVv">
<p><strong>Proportion of Vehicles by Manufacturer</strong></p>
</div>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:528}"
id="D3BLxMq5a_ud" data-outputId="5c0f1179-6e4b-491f-83bf-75eafc65d1eb">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>manufacturer_counts <span class="op">=</span> data[<span class="st">&#39;manufacturer&#39;</span>].value_counts()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.02</span> <span class="op">*</span> manufacturer_counts.<span class="bu">sum</span>()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>other_count <span class="op">=</span> manufacturer_counts[manufacturer_counts <span class="op">&lt;</span> threshold].<span class="bu">sum</span>()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>manufacturer_counts <span class="op">=</span> manufacturer_counts[manufacturer_counts <span class="op">&gt;=</span> threshold]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>manufacturer_counts[<span class="st">&#39;Other&#39;</span>] <span class="op">=</span> other_count</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> sns.color_palette(<span class="st">&#39;tab20&#39;</span>, <span class="bu">len</span>(manufacturer_counts))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>wedges, texts, autotexts <span class="op">=</span> ax.pie(manufacturer_counts, labels<span class="op">=</span>manufacturer_counts.index, autopct<span class="op">=</span><span class="st">&#39;</span><span class="sc">%1.1f%%</span><span class="st">&#39;</span>, startangle<span class="op">=</span><span class="dv">90</span>, colors<span class="op">=</span>colors, explode<span class="op">=</span>[<span class="fl">0.1</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">&#39;Other&#39;</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> manufacturer_counts.index])</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    text.set_fontsize(<span class="dv">10</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> autotext <span class="kw">in</span> autotexts:</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    autotext.set_fontsize(<span class="dv">8</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    autotext.set_color(<span class="st">&#39;white&#39;</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">&#39;equal&#39;</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Proportion of Vehicles by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>plt.legend(wedges, manufacturer_counts.index, title<span class="op">=</span><span class="st">&quot;Manufacturers&quot;</span>, loc<span class="op">=</span><span class="st">&quot;center left&quot;</span>, bbox_to_anchor<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>))</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/39e83b1bfc499056e992560d74a3be3ab60bfff7.png" /></p>
</div>
</div>
<div class="cell markdown" id="K_AmIFJ3JEZr">
<p>This visualization is a pie chart that shows the proportion of
vehicles listed for sale by different manufacturers in 2021. This helps
us understand which car manufacturers dominate the used car market. A
significant presence in the market can indicate popular brands that are
preferred by consumers for their reliability, resale value, or
availability of parts. From the pie chart, it is evident that Ford and
Chevrolet are the most popular manufacturers, indicating a strong
preference for these brands among used car buyers. This popularity might
be attributed to their reputation for reliability and the wide
availability of parts and services.</p>
</div>
<div class="cell markdown" id="BD98SE9jJukd">
<p><strong>Average Price of a Used Car by Age</strong></p>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:583}"
id="h5SCUuZOu1cs" data-outputId="071b0e73-c3c6-4370-ae68-e87f328b5408">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average price of a car for each age group</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;car_age&quot;</span>).describe()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>avg_prices <span class="op">=</span> avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>avg_prices.index, y<span class="op">=</span>avg_prices, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, edgecolor<span class="op">=</span><span class="st">&#39;w&#39;</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Age (years)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by Age&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/e14414dd5a611d8075408337b08803814dfc4352.png" /></p>
</div>
</div>
<div class="cell markdown" id="-JbIJPCNxRYd">
<p>This scatter plot illustrates how the age of a car impacts its market
price, providing insights into the depreciation rate of cars. The plot
clearly shows that as cars age, their average price tends to decrease.
This trend underscores the importance of considering car age when
setting prices or making purchase decisions, as older cars generally
offer more value for money but might come with higher maintenance
costs.</p>
</div>
<div class="cell markdown" id="Gs5nYxD2KCVJ">
<p><strong>Average Price of a Used Car by Manufacturer</strong></p>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:582}"
id="rdLXtfuUUVMA" data-outputId="56248545-4751-4451-fb35-bdeab3cacf48">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the price statistics of a car for each manufacturer</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;manufacturer&quot;</span>).describe()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>avg_prices <span class="op">=</span> avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>]</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>avg_prices.index, y<span class="op">=</span>avg_prices, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, edgecolor<span class="op">=</span><span class="st">&#39;w&#39;</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/e4f103811e7fc04453d1ca167b03b63b1cb1e617.png" /></p>
</div>
</div>
<div class="cell markdown" id="Lno2FXC2agYu">
<p>This scatter plot shows the average price of used cars by
manufacturer, highlighting the premium associated with different brands.
It appears that each manufacturer has a distinct set of prices.
Additionally, the visualization reveals that luxury brands like Ferrari
and Aston Martin command higher average prices in the used car market.
It is also interesting to note that most cars from various brands can be
bought for under or around the $20,000 mark.</p>
</div>
<div class="cell markdown" id="X6VY7ARRqso8">
<p>A violin plot will give us an idea of how the data is distributed for
each manufacturer. For more detailed information on using and making
violin plots, see this helpful <a
href="https://www.atlassian.com/data/charts/violin-plot-complete-guide">guide
to violin plots</a>.</p>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:783}"
id="sV44aeVitDiP" data-outputId="ca4fcf06-165e-4a0e-ee64-44706f111760">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filtering to handle kernel density estimation used in seaborn</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>filtered_data <span class="op">=</span> data[(data[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> <span class="dv">100</span>) <span class="op">|</span> ((data[<span class="st">&#39;manufacturer&#39;</span>] <span class="op">!=</span> <span class="st">&#39;Ferrari&#39;</span>) <span class="op">&amp;</span> (data[<span class="st">&#39;manufacturer&#39;</span>] <span class="op">!=</span> <span class="st">&#39;Tesla&#39;</span>))]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a violin plot for prices by manufacturer</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>))</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">&quot;husl&quot;</span>, <span class="bu">len</span>(filtered_data[<span class="st">&#39;manufacturer&#39;</span>].unique()))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>sns.violinplot(data<span class="op">=</span>filtered_data, x<span class="op">=</span><span class="st">&#39;manufacturer&#39;</span>, y<span class="op">=</span><span class="st">&#39;price&#39;</span>, hue<span class="op">=</span><span class="st">&#39;manufacturer&#39;</span>, palette<span class="op">=</span>palette, dodge<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Car Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Price of a Used Car by Manufacturer&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/8a9fa04db05ca2c8eef0182725e8502a83c07ca2.png" /></p>
</div>
</div>
<div class="cell markdown" id="18DxsuTsmT-P">
<p>The manufacturers have different distributions of prices, although
some manufacturers (e.g. Volkswagen and Mazda) have similar
distributions. Ferrari and Aston Martin have a wider distribution at
higher price points, indicating that their cars are generally more
expensive.The boxes for these brands are positioned higher on the price
scale, indicating higher median prices. Porsche and Mercedes-Benz also
show a significant spread towards higher prices, though not as extreme
as Ferrari and Aston Martin. This indicates that while they have some
more affordable models, they also have many high-end, expensive cars.
Ford, Chevrolet, Toyota, and Honda have a more concentrated distribution
around lower price points, typically under $20,000. The violins are
wider in the lower price range, indicating a higher density of cars in
this range. This suggests that these brands are more accessible to a
broader range of buyers. The violin for Tesla is intresting which shows
a concentration of prices in the mid to high range, reflecting the
premium nature of their electric vehicles.</p>
</div>
<div class="cell markdown" id="7xeMus3DfwAw">
<p><strong>Average Price of a Used Car by State</strong></p>
</div>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:383}"
id="NRY-lZYygCzv" data-outputId="f711dab8-e364-4bd2-fb07-d48d0c37b83a">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the price statistics of a car for each state</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>avgs <span class="op">=</span> data.groupby(<span class="st">&quot;state&quot;</span>).describe()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot average price for each state</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(avgs.index, avgs[<span class="st">&#39;price&#39;</span>][<span class="st">&#39;mean&#39;</span>])</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;State&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Average Price&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Price of a Used Car by State&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/d0690fb87bba1b8814c5bae540ad3c86441f9a64.png" /></p>
</div>
</div>
<div class="cell markdown" id="0_zKBEBZgKNp">
<p>The scatter plot reveals significant regional variations in the
average price of used cars. States like Alaska and Wyoming have higher
average prices, possibly due to supply constraints and higher
transportation costs. In contrast, states like Michigan and Ohio have
lower average prices, likely influenced by higher supply and lower
demand. Understanding these regional differences can help buyers and
sellers make more informed decisions based on local market
conditions.</p>
</div>
<div class="cell markdown" id="WhQReVbpPmic">
<p>Now lets create a violin plot for prices by state</p>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:783}"
id="31O1gUqMgWjc" data-outputId="103f0942-9ce6-4dff-a903-72ca69819628">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a violin plot for prices by state</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&quot;whitegrid&quot;</span>, context<span class="op">=</span><span class="st">&quot;talk&quot;</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">&quot;husl&quot;</span>, <span class="bu">len</span>(data[<span class="st">&#39;state&#39;</span>].unique()))</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>sns.violinplot(data<span class="op">=</span>data, x<span class="op">=</span><span class="st">&#39;state&#39;</span>, y<span class="op">=</span><span class="st">&#39;price&#39;</span>, hue<span class="op">=</span><span class="st">&#39;state&#39;</span>, palette<span class="op">=</span>palette, dodge<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;State&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Price (USD)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Price of a Used Car by State&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">&#39;both&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/818b793d891f52524322263adf34fb9b14603bdf.png" /></p>
</div>
</div>
<div class="cell markdown" id="uebFMZtGginJ">
<p>The violin plots, combined with the box plots inside them, provide a
comprehensive view of the price distributions for used cars across
different states. States like Alaska and Wyoming have higher median
prices and greater variance, indicating a higher density of expensive
cars. In contrast, states like Michigan and Ohio have lower median
prices and less variance, indicating a higher density of affordable
cars. This aslo shows us that the bulk of the data for each state has a
price of under 50,000 USD, but each state has varying levels of
variation in the upper extreme of &gt; 50,000 USD.</p>
</div>
<section id="correlation----numeric-data" class="cell markdown"
id="FAQnIF5ugvV0">
<h3>Correlation -- Numeric Data</h3>
</section>
<div class="cell markdown" id="t8oNoaYrx55v">
<p>We are interested in correlation between numeric variables. We will
now visualize correlation between numeric data.</p>
</div>
<div class="cell code" data-execution_count="20"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="aLiHHPvFWUvK" data-outputId="60514973-f979-4635-fe51-c5017c67d3ed">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric data</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>num_data <span class="op">=</span> data.select_dtypes(include<span class="op">=</span>[np.number])</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pairwise correlation between columns</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> pd.DataFrame(num_data).corr()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>mat</span></code></pre></div>
<div class="output execute_result" data-execution_count="20">

  <div id="df-e8e13178-0afa-47e0-b8e0-b61d96f1ac20" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>car_age</th>
      <th>odometer</th>
      <th>cylinders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>price</th>
      <td>1.000000</td>
      <td>0.555635</td>
      <td>-0.555635</td>
      <td>-0.221816</td>
      <td>0.364257</td>
    </tr>
    <tr>
      <th>year</th>
      <td>0.555635</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>-0.249332</td>
      <td>-0.063077</td>
    </tr>
    <tr>
      <th>car_age</th>
      <td>-0.555635</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>0.249332</td>
      <td>0.063077</td>
    </tr>
    <tr>
      <th>odometer</th>
      <td>-0.221816</td>
      <td>-0.249332</td>
      <td>0.249332</td>
      <td>1.000000</td>
      <td>0.016222</td>
    </tr>
    <tr>
      <th>cylinders</th>
      <td>0.364257</td>
      <td>-0.063077</td>
      <td>0.063077</td>
      <td>0.016222</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e8e13178-0afa-47e0-b8e0-b61d96f1ac20')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e8e13178-0afa-47e0-b8e0-b61d96f1ac20 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e8e13178-0afa-47e0-b8e0-b61d96f1ac20');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-b09e2298-7d0b-4548-bf93-2595e2e1c07a">
  <button class="colab-df-quickchart" onclick="quickchart('df-b09e2298-7d0b-4548-bf93-2595e2e1c07a')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-b09e2298-7d0b-4548-bf93-2595e2e1c07a button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:606}"
id="2HQ4vdEtWarM" data-outputId="95f25bfb-011f-4dc1-da3c-ed8aada2187e">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(mat, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&quot;.1f&quot;</span>, cmap<span class="op">=</span><span class="st">&#39;coolwarm&#39;</span>, cbar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Heatmap Representation&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/ae39941ba5f9285b171cbeaf8200bbc6b64b7e6d.png" /></p>
</div>
</div>
<div class="cell markdown" id="faLdC8Scg61k">
<p>The heatmap provides a visual representation of the correlations
between different numeric variables related to used cars. Here, we
notice a moderate positive correlation between price and year, as well
as between cylinders and price. There is also a moderate negative
correlation between price and car age, and weak correlations between
price and odometer. Understanding these correlations further helps in
predicting car prices and understanding the relationships between
different car attributes.</p>
</div>
<section id="ml" class="cell markdown" id="OyzOXibVvi8T">
<h1><strong>ML</strong></h1>
</section>
<div class="cell markdown" id="gduuIXKqjP--">
<p>We would like to train a model to predict a used car's price given
the car's year, odometer, number of cylinders, manufacturer, state,
condition, fuel-type, drive-type, and vehicle-type. Below, we fit a
linear model using OLS and Lasso Regression, a KNN model, a Random
Forest Model, and a Neural Network. We collected the score results for
all of them so we could conclude which one is our most efficient model
for the data that we are working with.</p>
</div>
<div class="cell markdown" id="8YGaNKRQfSXa">
<p>We'll begin by organizing the data for our model and standardizing
numeric values.</p>
</div>
<div class="cell code" data-execution_count="22" id="GDAL9YLtKZRj">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> data[[<span class="st">&#39;price&#39;</span>, <span class="st">&#39;year&#39;</span>, <span class="st">&#39;odometer&#39;</span>, <span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;manufacturer&#39;</span>, <span class="st">&#39;state&#39;</span>, <span class="st">&#39;condition&#39;</span>, <span class="st">&#39;fuel&#39;</span>, <span class="st">&#39;drive&#39;</span>, <span class="st">&#39;type&#39;</span>]]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize numeric data</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> train_df.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;int64&#39;</span>, <span class="st">&#39;float64&#39;</span>]).columns</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>train_df.loc[:, numeric_cols] <span class="op">=</span> scaler.fit_transform(train_df[numeric_cols])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="aFwUlRwy1B7I" data-outputId="9c386bbd-fe33-4f52-eed5-6352cf692f98">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create df to hold model data</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> train_df</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>model_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="23">

  <div id="df-3c769690-5996-43cb-bcf8-e95be2be0a48" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>-0.080792</td>
      <td>0.235819</td>
      <td>0.133530</td>
      <td>0.040827</td>
      <td>Ford</td>
      <td>AL</td>
      <td>excellent</td>
      <td>gas</td>
      <td>rwd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.875440</td>
      <td>0.033917</td>
      <td>-0.230876</td>
      <td>1.300959</td>
      <td>GMC</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.361285</td>
      <td>0.841524</td>
      <td>-0.471730</td>
      <td>0.040827</td>
      <td>Chevrolet</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.391466</td>
      <td>1.447230</td>
      <td>-0.388770</td>
      <td>0.040827</td>
      <td>Toyota</td>
      <td>AL</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.022666</td>
      <td>0.841524</td>
      <td>-0.546677</td>
      <td>0.040827</td>
      <td>Chevrolet</td>
      <td>AL</td>
      <td>good</td>
      <td>gas</td>
      <td>4wd</td>
      <td>pickup</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-3c769690-5996-43cb-bcf8-e95be2be0a48')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-3c769690-5996-43cb-bcf8-e95be2be0a48 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3c769690-5996-43cb-bcf8-e95be2be0a48');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-118faf1b-a57f-428b-ba05-0f5e2e4d7c2c">
  <button class="colab-df-quickchart" onclick="quickchart('df-118faf1b-a57f-428b-ba05-0f5e2e4d7c2c')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-118faf1b-a57f-428b-ba05-0f5e2e4d7c2c button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="24" id="Hm_AnQgo_whg">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to split data into test and training data</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split(X, y):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 80-20 ratio of train to test</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">10</span>) <span class="co"># Set a random state so the split is reproducible</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> X_train, X_test, y_train, y_test</span></code></pre></div>
</div>
<section id="model-implementations" class="cell markdown"
id="_kgSj0BxKdWP">
<h1>Model Implementations</h1>
<p>Now that we've gathered, refined, and analyzed our data, it's time to
delve into constructing various models based off this data. We created
linear regression, lasso regression, KNN, and neural network models to
analyze the factors influencing the American used vehicle market. We'll
utilize our independent variables such as vehicle condition,
manufacturer, engine, and other factors, to develop these various models
aimed at uncovering their correlations with a used vehicle's market
value.</p>
</section>
<section id="linear-regression" class="cell markdown" id="pQZJZTFk1VHr">
<h2>Linear regression</h2>
</section>
<div class="cell markdown" id="oZceicVloHik">
<p>We start with a multi-variate linear regression model, trained using
OLS (Ordinary Least Squares). For more information on OLS and linear
regression, see this helpful guide to <a
href="https://builtin.com/data-science/ols-regression">understanding OLS
regression</a>.</p>
</div>
<div class="cell code" data-execution_count="25" id="SJKbqCLm1TW0">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model_data.drop(<span class="st">&#39;price&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model_data[<span class="st">&#39;price&#39;</span>]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="26" id="L9cHpKPR6vs6">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> X_train</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;price&#39;</span>] <span class="op">=</span> y_train</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="VvKU8lX16oo2" data-outputId="b89d1aff-17f0-43ff-e602-cafa4357fdf0">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="27">

  <div id="df-d85be4e8-9e88-4bb6-b7f9-1906a0437b92" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>odometer</th>
      <th>cylinders</th>
      <th>manufacturer</th>
      <th>state</th>
      <th>condition</th>
      <th>fuel</th>
      <th>drive</th>
      <th>type</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>200584</th>
      <td>0.639622</td>
      <td>-0.360007</td>
      <td>1.300959</td>
      <td>Dodge</td>
      <td>MI</td>
      <td>excellent</td>
      <td>gas</td>
      <td>rwd</td>
      <td>coupe</td>
      <td>1.535380</td>
    </tr>
    <tr>
      <th>220065</th>
      <td>0.437721</td>
      <td>0.103919</td>
      <td>0.040827</td>
      <td>Jeep</td>
      <td>MO</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>SUV</td>
      <td>0.506860</td>
    </tr>
    <tr>
      <th>89817</th>
      <td>-1.783200</td>
      <td>1.276447</td>
      <td>0.040827</td>
      <td>Toyota</td>
      <td>DC</td>
      <td>good</td>
      <td>gas</td>
      <td>fwd</td>
      <td>mini-van</td>
      <td>-1.037761</td>
    </tr>
    <tr>
      <th>207496</th>
      <td>-0.773690</td>
      <td>-0.201498</td>
      <td>1.300959</td>
      <td>Chevrolet</td>
      <td>MI</td>
      <td>good</td>
      <td>gas</td>
      <td>rwd</td>
      <td>coupe</td>
      <td>0.802489</td>
    </tr>
    <tr>
      <th>135972</th>
      <td>1.043426</td>
      <td>-0.347896</td>
      <td>1.300959</td>
      <td>GMC</td>
      <td>ID</td>
      <td>excellent</td>
      <td>gas</td>
      <td>4wd</td>
      <td>truck</td>
      <td>1.896451</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d85be4e8-9e88-4bb6-b7f9-1906a0437b92')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d85be4e8-9e88-4bb6-b7f9-1906a0437b92 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d85be4e8-9e88-4bb6-b7f9-1906a0437b92');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-e49492cf-38c2-4ca3-9db4-87f113eb3e9d">
  <button class="colab-df-quickchart" onclick="quickchart('df-e49492cf-38c2-4ca3-9db4-87f113eb3e9d')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-e49492cf-38c2-4ca3-9db4-87f113eb3e9d button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="OSyNc9AcN0ta">
<p>Here, we train the model using training data.</p>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="32XS3wAQ2VJN" data-outputId="c1e34b13-7108-4599-ca65-b38db7240b20">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.formula.ols(formula<span class="op">=</span><span class="st">&quot;price ~ year + odometer + cylinders + manufacturer + state + condition + fuel + drive + type&quot;</span>, data<span class="op">=</span>train)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="28">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.603</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.602</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1228.</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 17 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  
</tr>
<tr>
  <th>Time:</th>                 <td>19:27:01</td>     <th>  Log-Likelihood:    </th> <td> -88079.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 92397</td>      <th>  AIC:               </th> <td>1.764e+05</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 92282</td>      <th>  BIC:               </th> <td>1.775e+05</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>   114</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                       <td>    1.3165</td> <td>    0.032</td> <td>   40.733</td> <td> 0.000</td> <td>    1.253</td> <td>    1.380</td>
</tr>
<tr>
  <th>manufacturer[T.Alfa-Romeo]</th>      <td>    0.1905</td> <td>    0.125</td> <td>    1.524</td> <td> 0.127</td> <td>   -0.054</td> <td>    0.435</td>
</tr>
<tr>
  <th>manufacturer[T.Aston-martin]</th>    <td>    2.2805</td> <td>    0.315</td> <td>    7.235</td> <td> 0.000</td> <td>    1.663</td> <td>    2.898</td>
</tr>
<tr>
  <th>manufacturer[T.Audi]</th>            <td>   -0.0444</td> <td>    0.027</td> <td>   -1.624</td> <td> 0.104</td> <td>   -0.098</td> <td>    0.009</td>
</tr>
<tr>
  <th>manufacturer[T.BMW]</th>             <td>   -0.1404</td> <td>    0.023</td> <td>   -6.027</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.095</td>
</tr>
<tr>
  <th>manufacturer[T.Buick]</th>           <td>   -0.0885</td> <td>    0.026</td> <td>   -3.345</td> <td> 0.001</td> <td>   -0.140</td> <td>   -0.037</td>
</tr>
<tr>
  <th>manufacturer[T.Cadillac]</th>        <td>   -0.0367</td> <td>    0.026</td> <td>   -1.412</td> <td> 0.158</td> <td>   -0.088</td> <td>    0.014</td>
</tr>
<tr>
  <th>manufacturer[T.Chevrolet]</th>       <td>   -0.1901</td> <td>    0.020</td> <td>   -9.372</td> <td> 0.000</td> <td>   -0.230</td> <td>   -0.150</td>
</tr>
<tr>
  <th>manufacturer[T.Chrysler]</th>        <td>   -0.2976</td> <td>    0.025</td> <td>  -11.948</td> <td> 0.000</td> <td>   -0.346</td> <td>   -0.249</td>
</tr>
<tr>
  <th>manufacturer[T.Dodge]</th>           <td>   -0.3463</td> <td>    0.022</td> <td>  -15.442</td> <td> 0.000</td> <td>   -0.390</td> <td>   -0.302</td>
</tr>
<tr>
  <th>manufacturer[T.Ferrari]</th>         <td>    5.4557</td> <td>    0.150</td> <td>   36.429</td> <td> 0.000</td> <td>    5.162</td> <td>    5.749</td>
</tr>
<tr>
  <th>manufacturer[T.Fiat]</th>            <td>   -0.5809</td> <td>    0.058</td> <td>   -9.966</td> <td> 0.000</td> <td>   -0.695</td> <td>   -0.467</td>
</tr>
<tr>
  <th>manufacturer[T.Ford]</th>            <td>   -0.2195</td> <td>    0.020</td> <td>  -10.833</td> <td> 0.000</td> <td>   -0.259</td> <td>   -0.180</td>
</tr>
<tr>
  <th>manufacturer[T.GMC]</th>             <td>   -0.1329</td> <td>    0.022</td> <td>   -5.995</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.089</td>
</tr>
<tr>
  <th>manufacturer[T.Harley-Davidson]</th> <td>   -0.1294</td> <td>    0.142</td> <td>   -0.911</td> <td> 0.362</td> <td>   -0.408</td> <td>    0.149</td>
</tr>
<tr>
  <th>manufacturer[T.Honda]</th>           <td>   -0.0552</td> <td>    0.021</td> <td>   -2.602</td> <td> 0.009</td> <td>   -0.097</td> <td>   -0.014</td>
</tr>
<tr>
  <th>manufacturer[T.Hyundai]</th>         <td>   -0.2788</td> <td>    0.023</td> <td>  -11.914</td> <td> 0.000</td> <td>   -0.325</td> <td>   -0.233</td>
</tr>
<tr>
  <th>manufacturer[T.Infiniti]</th>        <td>   -0.1473</td> <td>    0.026</td> <td>   -5.620</td> <td> 0.000</td> <td>   -0.199</td> <td>   -0.096</td>
</tr>
<tr>
  <th>manufacturer[T.Jaguar]</th>          <td>    0.0919</td> <td>    0.043</td> <td>    2.114</td> <td> 0.034</td> <td>    0.007</td> <td>    0.177</td>
</tr>
<tr>
  <th>manufacturer[T.Jeep]</th>            <td>   -0.0333</td> <td>    0.022</td> <td>   -1.529</td> <td> 0.126</td> <td>   -0.076</td> <td>    0.009</td>
</tr>
<tr>
  <th>manufacturer[T.Kia]</th>             <td>   -0.3327</td> <td>    0.025</td> <td>  -13.577</td> <td> 0.000</td> <td>   -0.381</td> <td>   -0.285</td>
</tr>
<tr>
  <th>manufacturer[T.Land Rover]</th>      <td>    0.3149</td> <td>    0.039</td> <td>    8.052</td> <td> 0.000</td> <td>    0.238</td> <td>    0.392</td>
</tr>
<tr>
  <th>manufacturer[T.Lexus]</th>           <td>    0.1793</td> <td>    0.024</td> <td>    7.508</td> <td> 0.000</td> <td>    0.133</td> <td>    0.226</td>
</tr>
<tr>
  <th>manufacturer[T.Lincoln]</th>         <td>    0.0306</td> <td>    0.029</td> <td>    1.072</td> <td> 0.284</td> <td>   -0.025</td> <td>    0.087</td>
</tr>
<tr>
  <th>manufacturer[T.Mazda]</th>           <td>   -0.1721</td> <td>    0.027</td> <td>   -6.321</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.119</td>
</tr>
<tr>
  <th>manufacturer[T.Mercedes-Benz]</th>   <td>    0.0545</td> <td>    0.024</td> <td>    2.283</td> <td> 0.022</td> <td>    0.008</td> <td>    0.101</td>
</tr>
<tr>
  <th>manufacturer[T.Mercury]</th>         <td>   -0.1997</td> <td>    0.042</td> <td>   -4.761</td> <td> 0.000</td> <td>   -0.282</td> <td>   -0.118</td>
</tr>
<tr>
  <th>manufacturer[T.Mini]</th>            <td>   -0.1239</td> <td>    0.036</td> <td>   -3.439</td> <td> 0.001</td> <td>   -0.194</td> <td>   -0.053</td>
</tr>
<tr>
  <th>manufacturer[T.Mitsubishi]</th>      <td>   -0.2581</td> <td>    0.031</td> <td>   -8.302</td> <td> 0.000</td> <td>   -0.319</td> <td>   -0.197</td>
</tr>
<tr>
  <th>manufacturer[T.Nissan]</th>          <td>   -0.3071</td> <td>    0.021</td> <td>  -14.442</td> <td> 0.000</td> <td>   -0.349</td> <td>   -0.265</td>
</tr>
<tr>
  <th>manufacturer[T.Pontiac]</th>         <td>   -0.0804</td> <td>    0.033</td> <td>   -2.414</td> <td> 0.016</td> <td>   -0.146</td> <td>   -0.015</td>
</tr>
<tr>
  <th>manufacturer[T.Porsche]</th>         <td>    0.9402</td> <td>    0.048</td> <td>   19.737</td> <td> 0.000</td> <td>    0.847</td> <td>    1.034</td>
</tr>
<tr>
  <th>manufacturer[T.Ram]</th>             <td>   -0.1985</td> <td>    0.023</td> <td>   -8.693</td> <td> 0.000</td> <td>   -0.243</td> <td>   -0.154</td>
</tr>
<tr>
  <th>manufacturer[T.Saturn]</th>          <td>   -0.0355</td> <td>    0.039</td> <td>   -0.909</td> <td> 0.363</td> <td>   -0.112</td> <td>    0.041</td>
</tr>
<tr>
  <th>manufacturer[T.Subaru]</th>          <td>   -0.1418</td> <td>    0.024</td> <td>   -5.827</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.094</td>
</tr>
<tr>
  <th>manufacturer[T.Tesla]</th>           <td>    1.1418</td> <td>    0.285</td> <td>    4.002</td> <td> 0.000</td> <td>    0.583</td> <td>    1.701</td>
</tr>
<tr>
  <th>manufacturer[T.Toyota]</th>          <td>    0.0568</td> <td>    0.021</td> <td>    2.747</td> <td> 0.006</td> <td>    0.016</td> <td>    0.097</td>
</tr>
<tr>
  <th>manufacturer[T.Volkswagen]</th>      <td>   -0.2453</td> <td>    0.025</td> <td>   -9.956</td> <td> 0.000</td> <td>   -0.294</td> <td>   -0.197</td>
</tr>
<tr>
  <th>manufacturer[T.Volvo]</th>           <td>   -0.0790</td> <td>    0.032</td> <td>   -2.499</td> <td> 0.012</td> <td>   -0.141</td> <td>   -0.017</td>
</tr>
<tr>
  <th>state[T.AL]</th>                     <td>   -0.4199</td> <td>    0.031</td> <td>  -13.735</td> <td> 0.000</td> <td>   -0.480</td> <td>   -0.360</td>
</tr>
<tr>
  <th>state[T.AR]</th>                     <td>   -0.8555</td> <td>    0.032</td> <td>  -26.446</td> <td> 0.000</td> <td>   -0.919</td> <td>   -0.792</td>
</tr>
<tr>
  <th>state[T.AZ]</th>                     <td>   -0.4759</td> <td>    0.028</td> <td>  -17.007</td> <td> 0.000</td> <td>   -0.531</td> <td>   -0.421</td>
</tr>
<tr>
  <th>state[T.CA]</th>                     <td>   -0.4366</td> <td>    0.024</td> <td>  -17.849</td> <td> 0.000</td> <td>   -0.485</td> <td>   -0.389</td>
</tr>
<tr>
  <th>state[T.CO]</th>                     <td>   -0.4541</td> <td>    0.028</td> <td>  -16.163</td> <td> 0.000</td> <td>   -0.509</td> <td>   -0.399</td>
</tr>
<tr>
  <th>state[T.CT]</th>                     <td>   -0.5946</td> <td>    0.030</td> <td>  -20.119</td> <td> 0.000</td> <td>   -0.653</td> <td>   -0.537</td>
</tr>
<tr>
  <th>state[T.DC]</th>                     <td>   -0.4880</td> <td>    0.035</td> <td>  -13.949</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.419</td>
</tr>
<tr>
  <th>state[T.DE]</th>                     <td>   -0.3920</td> <td>    0.046</td> <td>   -8.442</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.301</td>
</tr>
<tr>
  <th>state[T.FL]</th>                     <td>   -0.6227</td> <td>    0.025</td> <td>  -25.011</td> <td> 0.000</td> <td>   -0.671</td> <td>   -0.574</td>
</tr>
<tr>
  <th>state[T.GA]</th>                     <td>   -0.4152</td> <td>    0.029</td> <td>  -14.176</td> <td> 0.000</td> <td>   -0.473</td> <td>   -0.358</td>
</tr>
<tr>
  <th>state[T.HI]</th>                     <td>   -0.3255</td> <td>    0.038</td> <td>   -8.610</td> <td> 0.000</td> <td>   -0.400</td> <td>   -0.251</td>
</tr>
<tr>
  <th>state[T.IA]</th>                     <td>   -0.4976</td> <td>    0.027</td> <td>  -18.672</td> <td> 0.000</td> <td>   -0.550</td> <td>   -0.445</td>
</tr>
<tr>
  <th>state[T.ID]</th>                     <td>   -0.4919</td> <td>    0.029</td> <td>  -16.752</td> <td> 0.000</td> <td>   -0.549</td> <td>   -0.434</td>
</tr>
<tr>
  <th>state[T.IL]</th>                     <td>   -0.5125</td> <td>    0.027</td> <td>  -18.739</td> <td> 0.000</td> <td>   -0.566</td> <td>   -0.459</td>
</tr>
<tr>
  <th>state[T.IN]</th>                     <td>   -0.4607</td> <td>    0.028</td> <td>  -16.336</td> <td> 0.000</td> <td>   -0.516</td> <td>   -0.405</td>
</tr>
<tr>
  <th>state[T.KS]</th>                     <td>   -0.6185</td> <td>    0.028</td> <td>  -21.719</td> <td> 0.000</td> <td>   -0.674</td> <td>   -0.563</td>
</tr>
<tr>
  <th>state[T.KY]</th>                     <td>   -0.4060</td> <td>    0.030</td> <td>  -13.543</td> <td> 0.000</td> <td>   -0.465</td> <td>   -0.347</td>
</tr>
<tr>
  <th>state[T.LA]</th>                     <td>   -0.8014</td> <td>    0.036</td> <td>  -22.124</td> <td> 0.000</td> <td>   -0.872</td> <td>   -0.730</td>
</tr>
<tr>
  <th>state[T.MA]</th>                     <td>   -0.5657</td> <td>    0.027</td> <td>  -20.909</td> <td> 0.000</td> <td>   -0.619</td> <td>   -0.513</td>
</tr>
<tr>
  <th>state[T.MD]</th>                     <td>   -0.4581</td> <td>    0.032</td> <td>  -14.321</td> <td> 0.000</td> <td>   -0.521</td> <td>   -0.395</td>
</tr>
<tr>
  <th>state[T.ME]</th>                     <td>   -0.6230</td> <td>    0.035</td> <td>  -18.020</td> <td> 0.000</td> <td>   -0.691</td> <td>   -0.555</td>
</tr>
<tr>
  <th>state[T.MI]</th>                     <td>   -0.4778</td> <td>    0.026</td> <td>  -18.467</td> <td> 0.000</td> <td>   -0.528</td> <td>   -0.427</td>
</tr>
<tr>
  <th>state[T.MN]</th>                     <td>   -0.5215</td> <td>    0.027</td> <td>  -19.081</td> <td> 0.000</td> <td>   -0.575</td> <td>   -0.468</td>
</tr>
<tr>
  <th>state[T.MO]</th>                     <td>   -0.5754</td> <td>    0.031</td> <td>  -18.845</td> <td> 0.000</td> <td>   -0.635</td> <td>   -0.516</td>
</tr>
<tr>
  <th>state[T.MS]</th>                     <td>   -0.4788</td> <td>    0.046</td> <td>  -10.510</td> <td> 0.000</td> <td>   -0.568</td> <td>   -0.390</td>
</tr>
<tr>
  <th>state[T.MT]</th>                     <td>   -0.4202</td> <td>    0.032</td> <td>  -13.111</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.357</td>
</tr>
<tr>
  <th>state[T.NC]</th>                     <td>   -0.4641</td> <td>    0.026</td> <td>  -17.879</td> <td> 0.000</td> <td>   -0.515</td> <td>   -0.413</td>
</tr>
<tr>
  <th>state[T.ND]</th>                     <td>   -0.5496</td> <td>    0.053</td> <td>  -10.452</td> <td> 0.000</td> <td>   -0.653</td> <td>   -0.447</td>
</tr>
<tr>
  <th>state[T.NE]</th>                     <td>   -0.4110</td> <td>    0.046</td> <td>   -8.954</td> <td> 0.000</td> <td>   -0.501</td> <td>   -0.321</td>
</tr>
<tr>
  <th>state[T.NH]</th>                     <td>   -0.5309</td> <td>    0.035</td> <td>  -15.330</td> <td> 0.000</td> <td>   -0.599</td> <td>   -0.463</td>
</tr>
<tr>
  <th>state[T.NJ]</th>                     <td>   -0.5108</td> <td>    0.027</td> <td>  -18.776</td> <td> 0.000</td> <td>   -0.564</td> <td>   -0.457</td>
</tr>
<tr>
  <th>state[T.NM]</th>                     <td>   -0.4952</td> <td>    0.032</td> <td>  -15.642</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.433</td>
</tr>
<tr>
  <th>state[T.NV]</th>                     <td>   -0.3980</td> <td>    0.035</td> <td>  -11.362</td> <td> 0.000</td> <td>   -0.467</td> <td>   -0.329</td>
</tr>
<tr>
  <th>state[T.NY]</th>                     <td>   -0.4960</td> <td>    0.025</td> <td>  -19.729</td> <td> 0.000</td> <td>   -0.545</td> <td>   -0.447</td>
</tr>
<tr>
  <th>state[T.OH]</th>                     <td>   -0.5992</td> <td>    0.025</td> <td>  -23.556</td> <td> 0.000</td> <td>   -0.649</td> <td>   -0.549</td>
</tr>
<tr>
  <th>state[T.OK]</th>                     <td>   -0.9634</td> <td>    0.028</td> <td>  -34.657</td> <td> 0.000</td> <td>   -1.018</td> <td>   -0.909</td>
</tr>
<tr>
  <th>state[T.OR]</th>                     <td>   -0.3852</td> <td>    0.027</td> <td>  -14.242</td> <td> 0.000</td> <td>   -0.438</td> <td>   -0.332</td>
</tr>
<tr>
  <th>state[T.PA]</th>                     <td>   -0.4809</td> <td>    0.026</td> <td>  -18.439</td> <td> 0.000</td> <td>   -0.532</td> <td>   -0.430</td>
</tr>
<tr>
  <th>state[T.RI]</th>                     <td>   -0.5417</td> <td>    0.034</td> <td>  -15.890</td> <td> 0.000</td> <td>   -0.608</td> <td>   -0.475</td>
</tr>
<tr>
  <th>state[T.SC]</th>                     <td>   -0.5264</td> <td>    0.029</td> <td>  -18.178</td> <td> 0.000</td> <td>   -0.583</td> <td>   -0.470</td>
</tr>
<tr>
  <th>state[T.SD]</th>                     <td>   -0.5115</td> <td>    0.043</td> <td>  -11.803</td> <td> 0.000</td> <td>   -0.596</td> <td>   -0.427</td>
</tr>
<tr>
  <th>state[T.TN]</th>                     <td>   -0.4181</td> <td>    0.027</td> <td>  -15.429</td> <td> 0.000</td> <td>   -0.471</td> <td>   -0.365</td>
</tr>
<tr>
  <th>state[T.TX]</th>                     <td>   -0.5711</td> <td>    0.025</td> <td>  -22.409</td> <td> 0.000</td> <td>   -0.621</td> <td>   -0.521</td>
</tr>
<tr>
  <th>state[T.UT]</th>                     <td>   -0.2511</td> <td>    0.049</td> <td>   -5.091</td> <td> 0.000</td> <td>   -0.348</td> <td>   -0.154</td>
</tr>
<tr>
  <th>state[T.VA]</th>                     <td>   -0.4369</td> <td>    0.027</td> <td>  -16.240</td> <td> 0.000</td> <td>   -0.490</td> <td>   -0.384</td>
</tr>
<tr>
  <th>state[T.VT]</th>                     <td>   -0.5315</td> <td>    0.030</td> <td>  -17.557</td> <td> 0.000</td> <td>   -0.591</td> <td>   -0.472</td>
</tr>
<tr>
  <th>state[T.WA]</th>                     <td>   -0.3058</td> <td>    0.030</td> <td>  -10.144</td> <td> 0.000</td> <td>   -0.365</td> <td>   -0.247</td>
</tr>
<tr>
  <th>state[T.WI]</th>                     <td>   -0.4736</td> <td>    0.026</td> <td>  -18.172</td> <td> 0.000</td> <td>   -0.525</td> <td>   -0.423</td>
</tr>
<tr>
  <th>state[T.WV]</th>                     <td>   -0.3404</td> <td>    0.048</td> <td>   -7.143</td> <td> 0.000</td> <td>   -0.434</td> <td>   -0.247</td>
</tr>
<tr>
  <th>state[T.WY]</th>                     <td>   -0.3941</td> <td>    0.058</td> <td>   -6.841</td> <td> 0.000</td> <td>   -0.507</td> <td>   -0.281</td>
</tr>
<tr>
  <th>condition[T.fair]</th>               <td>   -0.0706</td> <td>    0.015</td> <td>   -4.691</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.041</td>
</tr>
<tr>
  <th>condition[T.good]</th>               <td>    0.1512</td> <td>    0.005</td> <td>   31.817</td> <td> 0.000</td> <td>    0.142</td> <td>    0.161</td>
</tr>
<tr>
  <th>condition[T.like new]</th>           <td>    0.1415</td> <td>    0.007</td> <td>   20.266</td> <td> 0.000</td> <td>    0.128</td> <td>    0.155</td>
</tr>
<tr>
  <th>condition[T.new]</th>                <td>    0.2419</td> <td>    0.030</td> <td>    8.153</td> <td> 0.000</td> <td>    0.184</td> <td>    0.300</td>
</tr>
<tr>
  <th>condition[T.salvage]</th>            <td>   -0.2049</td> <td>    0.048</td> <td>   -4.288</td> <td> 0.000</td> <td>   -0.299</td> <td>   -0.111</td>
</tr>
<tr>
  <th>fuel[T.electric]</th>                <td>   -0.6633</td> <td>    0.075</td> <td>   -8.859</td> <td> 0.000</td> <td>   -0.810</td> <td>   -0.517</td>
</tr>
<tr>
  <th>fuel[T.gas]</th>                     <td>   -0.8173</td> <td>    0.010</td> <td>  -79.934</td> <td> 0.000</td> <td>   -0.837</td> <td>   -0.797</td>
</tr>
<tr>
  <th>fuel[T.hybrid]</th>                  <td>   -0.8506</td> <td>    0.022</td> <td>  -38.259</td> <td> 0.000</td> <td>   -0.894</td> <td>   -0.807</td>
</tr>
<tr>
  <th>fuel[T.other]</th>                   <td>   -0.6765</td> <td>    0.018</td> <td>  -37.006</td> <td> 0.000</td> <td>   -0.712</td> <td>   -0.641</td>
</tr>
<tr>
  <th>drive[T.fwd]</th>                    <td>   -0.2047</td> <td>    0.007</td> <td>  -28.085</td> <td> 0.000</td> <td>   -0.219</td> <td>   -0.190</td>
</tr>
<tr>
  <th>drive[T.rwd]</th>                    <td>   -0.0233</td> <td>    0.007</td> <td>   -3.340</td> <td> 0.001</td> <td>   -0.037</td> <td>   -0.010</td>
</tr>
<tr>
  <th>type[T.bus]</th>                     <td>   -0.4298</td> <td>    0.057</td> <td>   -7.526</td> <td> 0.000</td> <td>   -0.542</td> <td>   -0.318</td>
</tr>
<tr>
  <th>type[T.convertible]</th>             <td>    0.5819</td> <td>    0.016</td> <td>   36.026</td> <td> 0.000</td> <td>    0.550</td> <td>    0.614</td>
</tr>
<tr>
  <th>type[T.coupe]</th>                   <td>    0.4497</td> <td>    0.011</td> <td>   42.320</td> <td> 0.000</td> <td>    0.429</td> <td>    0.471</td>
</tr>
<tr>
  <th>type[T.hatchback]</th>               <td>   -0.0172</td> <td>    0.013</td> <td>   -1.369</td> <td> 0.171</td> <td>   -0.042</td> <td>    0.007</td>
</tr>
<tr>
  <th>type[T.mini-van]</th>                <td>   -0.0237</td> <td>    0.015</td> <td>   -1.562</td> <td> 0.118</td> <td>   -0.053</td> <td>    0.006</td>
</tr>
<tr>
  <th>type[T.offroad]</th>                 <td>    0.3700</td> <td>    0.041</td> <td>    9.032</td> <td> 0.000</td> <td>    0.290</td> <td>    0.450</td>
</tr>
<tr>
  <th>type[T.other]</th>                   <td>    0.4613</td> <td>    0.013</td> <td>   35.771</td> <td> 0.000</td> <td>    0.436</td> <td>    0.487</td>
</tr>
<tr>
  <th>type[T.pickup]</th>                  <td>    0.3509</td> <td>    0.009</td> <td>   39.562</td> <td> 0.000</td> <td>    0.334</td> <td>    0.368</td>
</tr>
<tr>
  <th>type[T.sedan]</th>                   <td>   -0.0576</td> <td>    0.007</td> <td>   -8.284</td> <td> 0.000</td> <td>   -0.071</td> <td>   -0.044</td>
</tr>
<tr>
  <th>type[T.truck]</th>                   <td>    0.2246</td> <td>    0.009</td> <td>   25.804</td> <td> 0.000</td> <td>    0.208</td> <td>    0.242</td>
</tr>
<tr>
  <th>type[T.van]</th>                     <td>    0.0404</td> <td>    0.014</td> <td>    2.911</td> <td> 0.004</td> <td>    0.013</td> <td>    0.068</td>
</tr>
<tr>
  <th>type[T.wagon]</th>                   <td>   -0.0903</td> <td>    0.014</td> <td>   -6.396</td> <td> 0.000</td> <td>   -0.118</td> <td>   -0.063</td>
</tr>
<tr>
  <th>year</th>                            <td>    0.5380</td> <td>    0.002</td> <td>  228.278</td> <td> 0.000</td> <td>    0.533</td> <td>    0.543</td>
</tr>
<tr>
  <th>odometer</th>                        <td>   -0.0952</td> <td>    0.002</td> <td>  -40.465</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.091</td>
</tr>
<tr>
  <th>cylinders</th>                       <td>    0.2304</td> <td>    0.003</td> <td>   73.514</td> <td> 0.000</td> <td>    0.224</td> <td>    0.236</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>24476.739</td> <th>  Durbin-Watson:     </th>  <td>   1.997</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>686367.240</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 0.676</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>16.284</td>   <th>  Cond. No.          </th>  <td>    240.</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>
</div>
<div class="cell markdown" id="-vE71Q6UGU7k">
<p>This has a low p-value for all of our predictors, except a vehicle
type of hatchback or mini-van and a handful of manufacturers. Let's see
if we can get more information from the MSE, RMSE, and <span
class="math inline"><em>R</em><sup>2</sup></span> statistics for this
model.</p>
</div>
<div class="cell code" data-execution_count="29" id="M-SdmFn44xuH">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, model.predict(X_train))</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, model.predict(X_test))</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, model.predict(X_train))</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, model.predict(X_test))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="OU4S4ornP4mL" data-outputId="0e15021c-6f04-4f32-b992-d21462b4809b">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of linear model on training data is:&quot;</span>, msetrain)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of linear model on test data is:&quot;</span>, msetest)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of linear model on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of linear model on test data is:&quot;</span>, rmsetest)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of linear model on training data is:&quot;</span>, r2train)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of linear model on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of linear model on training data is: 0.39402592697638344
MSE of linear model on test data is: 0.41404342973202746

RMSE of linear model on training data is: 0.6277148452732207
RMSE of linear model on test data is: 0.6434620654957272

R^2 score of linear model on training data is: 0.6027009671750873
R^2 score of linear model on test data is: 0.5991588069773714
</code></pre>
</div>
</div>
<div class="cell markdown" id="r6yVr1GXEDAI">
<p>The MSE for this model is fairly low. The <span
class="math inline"><em>R</em><sup>2</sup></span> value is good, but
leaves room for improvement. One possible way to change the model is
through feature selection since we know there are a few features that
are not significant to price. Let's try Lasso Regression.</p>
</div>
<section id="lasso-regression" class="cell markdown" id="24kWnrpy_05s">
<h2>Lasso Regression</h2>
</section>
<div class="cell markdown" id="jZtWcTCa_9oU">
<p>Perhaps we need to perform feature selection to better fit our data.
We will use Lasso Regression to perform feature selection. For more
detailed information on Lasso Regression, see this helpful <a
href="https://www.ibm.com/topics/lasso-regression">introduction to Lasso
Regression</a>.</p>
</div>
<div class="cell code" data-execution_count="31" id="6vEuY7yEBMs3">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.get_dummies(model_data.drop(<span class="st">&#39;price&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model_data[<span class="st">&#39;price&#39;</span>]</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ZYXYWtOg-VbP" data-outputId="3dcceda7-0a9e-4882-dd5f-ad00520cb512">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Lasso Regression</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>lasso_model <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.0005</span>, fit_intercept<span class="op">=</span><span class="va">True</span>, max_iter<span class="op">=</span><span class="dv">10000</span>).fit(X_train, y_train)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>lasso_model.coef_</span></code></pre></div>
<div class="output execute_result" data-execution_count="32">
<pre><code>array([ 0.00000000e+00,  5.36885806e-01, -9.63525894e-02,  2.38092734e-01,
        7.88910161e-02,  0.00000000e+00,  0.00000000e+00,  3.15289886e-02,
       -8.63965796e-03,  0.00000000e+00,  3.94710498e-02, -6.29542698e-02,
       -1.54108119e-01, -2.17832964e-01,  3.00119498e+00, -8.69706585e-02,
       -9.14256589e-02, -0.00000000e+00,  0.00000000e+00,  5.96846990e-02,
       -1.34568406e-01, -0.00000000e+00,  2.92715136e-02,  8.30896600e-02,
       -1.80470167e-01,  2.99074142e-01,  2.71258267e-01,  9.42816982e-02,
       -3.07673112e-03,  1.45225730e-01, -0.00000000e+00,  0.00000000e+00,
       -5.54843418e-02, -1.72863354e-01,  0.00000000e+00,  8.42200852e-01,
       -4.63843667e-02,  0.00000000e+00, -5.21466119e-03,  0.00000000e+00,
        1.75203248e-01, -9.18716077e-02,  0.00000000e+00,  4.30322684e-01,
        2.83972013e-02, -3.12908849e-01,  0.00000000e+00,  4.68994421e-02,
        2.69853354e-03, -6.92349900e-02, -0.00000000e+00,  0.00000000e+00,
       -1.25696694e-01,  4.15938867e-02,  5.97343534e-02, -0.00000000e+00,
       -0.00000000e+00, -6.72436076e-03,  0.00000000e+00, -1.03604458e-01,
        4.06396038e-02, -2.26187256e-01, -5.60136754e-02,  0.00000000e+00,
       -6.68843961e-02,  0.00000000e+00, -1.76869237e-02, -4.87505284e-02,
        0.00000000e+00,  8.03346992e-03,  7.13621745e-03, -0.00000000e+00,
        0.00000000e+00, -0.00000000e+00, -7.61188673e-03, -0.00000000e+00,
        1.13654483e-02, -3.32466902e-03, -1.04320144e-01, -4.52595150e-01,
        7.62616064e-02,  0.00000000e+00, -0.00000000e+00, -5.02478384e-03,
       -0.00000000e+00,  4.75843794e-02, -7.28844654e-02,  9.87796535e-03,
        2.78248523e-02, -5.18491023e-03,  1.46562901e-01,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -1.28631122e-01, -1.76634438e-01,
        2.33860015e-02,  1.02017870e-02,  0.00000000e+00, -6.67940680e-02,
        6.87163730e-01,  0.00000000e+00, -1.17917254e-01, -9.69884967e-02,
        0.00000000e+00,  2.54345792e-02, -1.89763514e-01,  0.00000000e+00,
       -3.41285545e-02, -8.09082767e-02,  5.40649696e-01,  4.02056908e-01,
       -5.24105215e-02, -4.11908828e-02,  1.47290417e-01,  4.10047671e-01,
        2.91378769e-01, -8.47404567e-02,  1.66644155e-01, -0.00000000e+00,
       -1.10700758e-01])</code></pre>
</div>
</div>
<div class="cell markdown" id="muPf3HAEU78V">
<p>We can see that not every feature has been selected (some features
have a coefficient of 0). Let's see if this improved the fit of our
model by looking at MSE, RMSE, and <span
class="math inline"><em>R</em><sup>2</sup></span> values.</p>
</div>
<div class="cell code" data-execution_count="33" id="htUjwlnZQLU2">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, lasso_model.predict(X_train))</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, lasso_model.predict(X_test))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, lasso_model.predict(X_train))</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, lasso_model.predict(X_test))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="34"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IIhYSwBHQW9w" data-outputId="59adc769-c4e4-486c-d656-d9f662a5a037">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on training data is:&quot;</span>, msetrain)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on test data is:&quot;</span>, msetest)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on test data is:&quot;</span>, rmsetest)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on training data is:&quot;</span>, r2train)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of lasso regression on training data is: 0.39795607172397357
MSE of lasso regression on test data is: 0.41736434003114725

RMSE of lasso regression on training data is: 0.6308375953634767
RMSE of lasso regression on test data is: 0.6460374138013582

R^2 score of lasso regression on training data is: 0.5987381753886141
R^2 score of lasso regression on test data is: 0.595943787608312
</code></pre>
</div>
</div>
<div class="cell markdown" id="4CfHTtmfDpPc">
<p>Our <span class="math inline"><em>R</em><sup>2</sup></span> test
score is not larger than for linear regression, so this model does not
explain the variability in our data better than linear regression. We
also see that the training and test MSEs and RMSEs are comparable to our
original linear model. Perhaps another modeling technique will better
improve our price prediction.</p>
</div>
<section id="knn" class="cell markdown" id="Kz9gENA14OEW">
<h2>KNN</h2>
</section>
<div class="cell markdown" id="N-iEZZF8B3tr">
<p><strong>What is K-Nearest Neighbors (KNN)?</strong></p>
<p>K-Nearest Neighbors (KNN) is a simple, yet powerful algorithm used in
both classification and regression tasks. It is a type of instance-based
or memory-based learning where the model does not explicitly learn a
model. Instead, it memorizes the training instances which are
subsequently used as "knowledge" for the prediction phase. Essentially,
KNN makes predictions for new data points by looking at the closest
labeled training data points — the "nearest neighbors". For more
detailed information on KNN, see this helpful [link.](<a
href="https://www.ibm.com/topics/knn#"
class="uri">https://www.ibm.com/topics/knn#</a>:~:text=The%20k%2Dnearest%20neighbors%20(KNN,of%20an%20individual%20data%20point.)</p>
</div>
<div class="cell markdown" id="wmOvPnoaB7Ef">
<p>We chose the KNN regressor from the scikit-learn library. We split
our data into training and testing sets to ensure that we could evaluate
our model's performance effectively. Then we trained our KNN model on
the training data. The key parameter in KNN is the number of neighbors
5. We experimented with different values to find the optimal number that
gives the best prediction accuracy.</p>
</div>
<div class="cell markdown" id="O7dDuL1RlW6j">
<p>We will now try K-Nearest Neighbors to model our data and predict
price.</p>
</div>
<div class="cell code" data-execution_count="35" id="OzeXr2pV4R1f">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> knn.predict(X_train)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="36" id="H6D15TVlr077">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>msetrain <span class="op">=</span> mean_squared_error(y_train, y_pred_train)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>msetest <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>rmsetrain <span class="op">=</span> np.sqrt(msetrain)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>rmsetest <span class="op">=</span> np.sqrt(msetest)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>r2train <span class="op">=</span> r2_score(y_train, y_pred_train)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>r2test <span class="op">=</span> r2_score(y_test, y_pred)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="37"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="E2aUWrBcr45R" data-outputId="310a82a3-6f67-4732-cd82-5783aa982f6b">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print MSE RMSE and R^2</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on training data is:&quot;</span>, msetrain)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE of lasso regression on test data is:&quot;</span>, msetest)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on training data is:&quot;</span>, rmsetrain)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE of lasso regression on test data is:&quot;</span>, rmsetest)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on training data is:&quot;</span>, r2train)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R^2 score of lasso regression on test data is:&quot;</span>, r2test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>MSE of lasso regression on training data is: 0.15073628600987088
MSE of lasso regression on test data is: 0.2480831524667121

RMSE of lasso regression on training data is: 0.3882477121759649
RMSE of lasso regression on test data is: 0.49807946400821634

R^2 score of lasso regression on training data is: 0.8480115734949325
R^2 score of lasso regression on test data is: 0.759827255638542
</code></pre>
</div>
</div>
<div class="cell markdown" id="Cc7kJbGZnB8x">
<p>We can see that KNN has a higher <span
class="math inline"><em>R</em><sup>2</sup></span> and lower MSE and RMSE
than our OLS and Lasso Regressors.</p>
</div>
<div class="cell markdown" id="hRZCxScMLxC3">
<p><img
src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExcjl2MWR6dWMwMHpuemdlenRoZG45bHlzMXBidHd4YmVrOGkya2dxeiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/Ur783X6ugp0ptW5li4/giphy.gif"
alt="Its getting better" /></p>
</div>
<section id="random-forest-decision-tree" class="cell markdown"
id="RWht73whUTKA">
<h3>Random Forest (Decision Tree)</h3>
</section>
<div class="cell markdown" id="bjt2qaP2lei7">
<p><strong>What is a Random Forest</strong></p>
<p>Random Forest is an ensemble learning method used for classification
and regression tasks. It operates by constructing multiple decision
trees during training and outputting the mean prediction (regression) or
majority vote (classification) of the individual trees. The key
advantages of Random Forest include its ability to handle large datasets
with higher dimensionality, its robustness to overfitting, and its
capability to capture complex interactions between features. For more
detailed information on Random Forest, see this helpful <a
href="https://www.ibm.com/topics/random-forest#:~:text=Random%20forest%20is%20a%20commonly,Decision%20trees">link</a></p>
</div>
<div class="cell markdown" id="pjA2F4Q7U0Xv">
<p>We use Random Forest to predict the prices of used cars based on
various features such as year, odometer reading, number of cylinders,
manufacturer, state, condition, fuel type, drive type, and vehicle
type.</p>
</div>
<div class="cell markdown" id="EvqcB41RU9ur">
<p>First we preprocess the data by standardizing numeric features and
encoding categorical variables. Then we split the data into training and
testing sets and train the Random Forest model on the training data.</p>
</div>
<div class="cell code" data-execution_count="38" id="C4kDVLHnIGRO">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>rf_data <span class="op">=</span> train_df</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> rf_data.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;object&#39;</span>]).columns</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> categorical_cols:</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    rf_data.loc[:, col] <span class="op">=</span> le.fit_transform(rf_data[col])</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>y_rf <span class="op">=</span> rf_data.pop(<span class="st">&#39;price&#39;</span>)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>X_rf <span class="op">=</span> rf_data</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>X_train_rf, X_test_rf, y_train_rf, y_test_rf <span class="op">=</span> split(X, y)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="EO1KskrgodJR" data-outputId="a9350548-55c3-4a09-8615-041461468844">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">50</span>],</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">40</span>],</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>]</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> parallel_backend(<span class="st">&#39;threading&#39;</span>, n_jobs<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    gc.collect()</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    grid_search.fit(X_train_rf, y_train_rf)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> grid_search.best_params_</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters:&quot;</span>, grid_search.best_params_)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best score:&quot;</span>, np.sqrt(<span class="op">-</span>grid_search.best_score_))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Best parameters: {&#39;max_depth&#39;: 30, &#39;min_samples_leaf&#39;: 10, &#39;n_estimators&#39;: 50}
Best score: 0.46800001486372106
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="47" id="fldg51j-omNE">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(<span class="op">**</span>best_params)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(X_train_rf, y_train_rf)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="41" id="Ik6mNvf0o46F">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>train_predictions <span class="op">=</span> model.predict(X_train_rf)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>r2_trainRF <span class="op">=</span> r2_score(y_train_rf, train_predictions)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(X_test_rf)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>r2_testRF <span class="op">=</span> r2_score(y_test_rf, predictions)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>mse_trainRF <span class="op">=</span> mean_squared_error(y_train_rf, train_predictions)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>mse_testRF <span class="op">=</span> mean_squared_error(y_test_rf, predictions)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="B3M_CS4Aq07T" data-outputId="bff9f05e-8b38-4197-b163-73b50f4a93d3">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;r2 score of Random Forest Regressor model on training data is:&quot;</span>, r2_trainRF)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;r2 score of Random Forest Regressor model on test data is:&quot;</span>, r2_trainRF)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE for the training data: </span><span class="sc">{</span>mse_trainRF<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MSE for the testing data: </span><span class="sc">{</span>mse_testRF<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>r2 score of Random Forest Regressor model on training data is: 0.8387894131137202
r2 score of Random Forest Regressor model on test data is: 0.8387894131137202
MSE for the training data: 0.1598824706031101
MSE for the testing data: 0.20850013205577658
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="1HnB6H1Krv8F" data-outputId="4dd02c8e-e093-4b32-e079-eaa3aff63765">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>rmse_trainRF <span class="op">=</span> np.sqrt(mse_trainRF)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>rmse_testRF <span class="op">=</span> np.sqrt(mse_testRF)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE for the training data: </span><span class="sc">{</span>rmse_trainRF<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE for the testing data: </span><span class="sc">{</span>rmse_testRF<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE for the training data: 0.39985306126514786
RMSE for the testing data: 0.45661814687523816
</code></pre>
</div>
</div>
<div class="cell markdown" id="-GEVZyYRG7_Y">
<p>We can see that Random Forest has a higher <span
class="math inline"><em>R</em><sup>2</sup></span> and lower MSE and RMSE
than our previous models.</p>
</div>
<section id="neural-network" class="cell markdown" id="xFlNaLvQzz43">
<h2>Neural Network</h2>
</section>
<div class="cell markdown" id="OlulrIqNllVU">
<p>We will now create a Neural Network to model our data and predict
price. The activation used for this neural network is <a
href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/">ReLu</a>
(Rectified Linear Unit) because of its computational efficiency.
Moreover, using a ReLu function also leads to a faster convergence. In
order to improve our model efficiency, we set some considerably high
batch size and number of epochs, this helped us be more computationally
efficient and keep the gradient constant. Furthermore, the more epochs
we set the better we can monitor how the NN is performing and compare
their results.</p>
</div>
<div class="cell code" data-execution_count="49"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="Y4-0UDT4-XWi" data-outputId="599c3519-9b90-48b1-829a-711a2bae3e15">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model_data</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling the features since they have different magnitudes</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural network model, activation used is relu (most common)</span></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>[X_train.shape[<span class="dv">1</span>]]),</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.3</span>),</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.3</span>),</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">1</span>)</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;mean_squared_error&#39;</span>)</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model and save the training history</span></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train_scaled, y_train, epochs<span class="op">=</span><span class="dv">400</span>, batch_size<span class="op">=</span><span class="dv">256</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Model evaluation</span></span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> model.evaluate(X_test_scaled, y_test)</span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for the test: </span><span class="sc">{</span>test_loss<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the loss over epochs</span></span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epochs&#39;</span>)</span>
<span id="cb54-35"><a href="#cb54-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb54-36"><a href="#cb54-36" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loss Over Epochs&#39;</span>)</span>
<span id="cb54-37"><a href="#cb54-37" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb54-38"><a href="#cb54-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/400
289/289 [==============================] - 4s 9ms/step - loss: 0.4313 - val_loss: 0.3373
Epoch 2/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3749 - val_loss: 0.3338
Epoch 3/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3647 - val_loss: 0.3257
Epoch 4/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3581 - val_loss: 0.3231
Epoch 5/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3529 - val_loss: 0.3160
Epoch 6/400
289/289 [==============================] - 3s 10ms/step - loss: 0.3490 - val_loss: 0.3197
Epoch 7/400
289/289 [==============================] - 4s 15ms/step - loss: 0.3456 - val_loss: 0.3116
Epoch 8/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3414 - val_loss: 0.3071
Epoch 9/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3382 - val_loss: 0.3041
Epoch 10/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3369 - val_loss: 0.3053
Epoch 11/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3345 - val_loss: 0.3053
Epoch 12/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3320 - val_loss: 0.3025
Epoch 13/400
289/289 [==============================] - 3s 11ms/step - loss: 0.3286 - val_loss: 0.3019
Epoch 14/400
289/289 [==============================] - 2s 8ms/step - loss: 0.3274 - val_loss: 0.2968
Epoch 15/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3252 - val_loss: 0.2936
Epoch 16/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3217 - val_loss: 0.2946
Epoch 17/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3187 - val_loss: 0.2913
Epoch 18/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3194 - val_loss: 0.2893
Epoch 19/400
289/289 [==============================] - 2s 8ms/step - loss: 0.3164 - val_loss: 0.2969
Epoch 20/400
289/289 [==============================] - 3s 11ms/step - loss: 0.3163 - val_loss: 0.2898
Epoch 21/400
289/289 [==============================] - 2s 8ms/step - loss: 0.3156 - val_loss: 0.2861
Epoch 22/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3128 - val_loss: 0.2874
Epoch 23/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3102 - val_loss: 0.2831
Epoch 24/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3103 - val_loss: 0.2817
Epoch 25/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3104 - val_loss: 0.2787
Epoch 26/400
289/289 [==============================] - 3s 9ms/step - loss: 0.3079 - val_loss: 0.2813
Epoch 27/400
289/289 [==============================] - 3s 11ms/step - loss: 0.3069 - val_loss: 0.2763
Epoch 28/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3056 - val_loss: 0.2785
Epoch 29/400
289/289 [==============================] - 2s 7ms/step - loss: 0.3050 - val_loss: 0.2756
Epoch 30/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3014 - val_loss: 0.2737
Epoch 31/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3025 - val_loss: 0.2751
Epoch 32/400
289/289 [==============================] - 2s 6ms/step - loss: 0.3021 - val_loss: 0.2813
Epoch 33/400
289/289 [==============================] - 3s 10ms/step - loss: 0.3007 - val_loss: 0.2768
Epoch 34/400
289/289 [==============================] - 3s 11ms/step - loss: 0.3017 - val_loss: 0.2715
Epoch 35/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2962 - val_loss: 0.2725
Epoch 36/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2980 - val_loss: 0.2762
Epoch 37/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2963 - val_loss: 0.2735
Epoch 38/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2959 - val_loss: 0.2696
Epoch 39/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2964 - val_loss: 0.2675
Epoch 40/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2944 - val_loss: 0.2710
Epoch 41/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2923 - val_loss: 0.2690
Epoch 42/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2927 - val_loss: 0.2663
Epoch 43/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2893 - val_loss: 0.2696
Epoch 44/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2921 - val_loss: 0.2704
Epoch 45/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2911 - val_loss: 0.2666
Epoch 46/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2894 - val_loss: 0.2659
Epoch 47/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2915 - val_loss: 0.2691
Epoch 48/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2871 - val_loss: 0.2653
Epoch 49/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2861 - val_loss: 0.2662
Epoch 50/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2879 - val_loss: 0.2649
Epoch 51/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2888 - val_loss: 0.2647
Epoch 52/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2854 - val_loss: 0.2667
Epoch 53/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2842 - val_loss: 0.2634
Epoch 54/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2846 - val_loss: 0.2638
Epoch 55/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2836 - val_loss: 0.2594
Epoch 56/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2834 - val_loss: 0.2642
Epoch 57/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2835 - val_loss: 0.2667
Epoch 58/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2829 - val_loss: 0.2634
Epoch 59/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2806 - val_loss: 0.2602
Epoch 60/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2800 - val_loss: 0.2613
Epoch 61/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2802 - val_loss: 0.2611
Epoch 62/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2810 - val_loss: 0.2647
Epoch 63/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2809 - val_loss: 0.2615
Epoch 64/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2799 - val_loss: 0.2603
Epoch 65/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2803 - val_loss: 0.2612
Epoch 66/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2789 - val_loss: 0.2605
Epoch 67/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2800 - val_loss: 0.2579
Epoch 68/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2749 - val_loss: 0.2602
Epoch 69/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2768 - val_loss: 0.2582
Epoch 70/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2765 - val_loss: 0.2552
Epoch 71/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2765 - val_loss: 0.2582
Epoch 72/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2755 - val_loss: 0.2560
Epoch 73/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2748 - val_loss: 0.2557
Epoch 74/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2763 - val_loss: 0.2572
Epoch 75/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2741 - val_loss: 0.2547
Epoch 76/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2747 - val_loss: 0.2547
Epoch 77/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2768 - val_loss: 0.2576
Epoch 78/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2730 - val_loss: 0.2545
Epoch 79/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2755 - val_loss: 0.2572
Epoch 80/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2733 - val_loss: 0.2545
Epoch 81/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2751 - val_loss: 0.2537
Epoch 82/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2737 - val_loss: 0.2542
Epoch 83/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2721 - val_loss: 0.2540
Epoch 84/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2707 - val_loss: 0.2528
Epoch 85/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2719 - val_loss: 0.2512
Epoch 86/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2713 - val_loss: 0.2494
Epoch 87/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2715 - val_loss: 0.2527
Epoch 88/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2694 - val_loss: 0.2505
Epoch 89/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2693 - val_loss: 0.2533
Epoch 90/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2716 - val_loss: 0.2515
Epoch 91/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2707 - val_loss: 0.2591
Epoch 92/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2700 - val_loss: 0.2489
Epoch 93/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2693 - val_loss: 0.2555
Epoch 94/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2704 - val_loss: 0.2537
Epoch 95/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2698 - val_loss: 0.2488
Epoch 96/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2675 - val_loss: 0.2515
Epoch 97/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2688 - val_loss: 0.2522
Epoch 98/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2664 - val_loss: 0.2479
Epoch 99/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2686 - val_loss: 0.2532
Epoch 100/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2646 - val_loss: 0.2509
Epoch 101/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2667 - val_loss: 0.2543
Epoch 102/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2634 - val_loss: 0.2497
Epoch 103/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2662 - val_loss: 0.2495
Epoch 104/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2670 - val_loss: 0.2473
Epoch 105/400
289/289 [==============================] - 2s 9ms/step - loss: 0.2675 - val_loss: 0.2517
Epoch 106/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2661 - val_loss: 0.2473
Epoch 107/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2668 - val_loss: 0.2504
Epoch 108/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2617 - val_loss: 0.2512
Epoch 109/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2658 - val_loss: 0.2494
Epoch 110/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2640 - val_loss: 0.2496
Epoch 111/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2633 - val_loss: 0.2447
Epoch 112/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2660 - val_loss: 0.2483
Epoch 113/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2647 - val_loss: 0.2493
Epoch 114/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2606 - val_loss: 0.2462
Epoch 115/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2644 - val_loss: 0.2452
Epoch 116/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2643 - val_loss: 0.2484
Epoch 117/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2613 - val_loss: 0.2458
Epoch 118/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2610 - val_loss: 0.2457
Epoch 119/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2616 - val_loss: 0.2467
Epoch 120/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2636 - val_loss: 0.2474
Epoch 121/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2625 - val_loss: 0.2455
Epoch 122/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2608 - val_loss: 0.2423
Epoch 123/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2614 - val_loss: 0.2457
Epoch 124/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2620 - val_loss: 0.2473
Epoch 125/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2596 - val_loss: 0.2423
Epoch 126/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2620 - val_loss: 0.2485
Epoch 127/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2617 - val_loss: 0.2442
Epoch 128/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2608 - val_loss: 0.2447
Epoch 129/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2623 - val_loss: 0.2459
Epoch 130/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2607 - val_loss: 0.2430
Epoch 131/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2605 - val_loss: 0.2448
Epoch 132/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2596 - val_loss: 0.2425
Epoch 133/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2587 - val_loss: 0.2434
Epoch 134/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2575 - val_loss: 0.2439
Epoch 135/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2582 - val_loss: 0.2455
Epoch 136/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2580 - val_loss: 0.2422
Epoch 137/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2566 - val_loss: 0.2423
Epoch 138/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2590 - val_loss: 0.2415
Epoch 139/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2596 - val_loss: 0.2435
Epoch 140/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2587 - val_loss: 0.2425
Epoch 141/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2618 - val_loss: 0.2431
Epoch 142/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2559 - val_loss: 0.2405
Epoch 143/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2588 - val_loss: 0.2437
Epoch 144/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2546 - val_loss: 0.2398
Epoch 145/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2556 - val_loss: 0.2434
Epoch 146/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2552 - val_loss: 0.2413
Epoch 147/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2559 - val_loss: 0.2432
Epoch 148/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2561 - val_loss: 0.2444
Epoch 149/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2565 - val_loss: 0.2443
Epoch 150/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2551 - val_loss: 0.2412
Epoch 151/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2554 - val_loss: 0.2427
Epoch 152/400
289/289 [==============================] - 2s 9ms/step - loss: 0.2568 - val_loss: 0.2433
Epoch 153/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2599 - val_loss: 0.2427
Epoch 154/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2536 - val_loss: 0.2455
Epoch 155/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2554 - val_loss: 0.2405
Epoch 156/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2543 - val_loss: 0.2401
Epoch 157/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2582 - val_loss: 0.2415
Epoch 158/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2555 - val_loss: 0.2412
Epoch 159/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2550 - val_loss: 0.2422
Epoch 160/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2535 - val_loss: 0.2411
Epoch 161/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2544 - val_loss: 0.2401
Epoch 162/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2543 - val_loss: 0.2402
Epoch 163/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2534 - val_loss: 0.2393
Epoch 164/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2548 - val_loss: 0.2404
Epoch 165/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2527 - val_loss: 0.2381
Epoch 166/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2542 - val_loss: 0.2392
Epoch 167/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2521 - val_loss: 0.2393
Epoch 168/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2539 - val_loss: 0.2398
Epoch 169/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2509 - val_loss: 0.2406
Epoch 170/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2553 - val_loss: 0.2406
Epoch 171/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2512 - val_loss: 0.2373
Epoch 172/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2537 - val_loss: 0.2361
Epoch 173/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2505 - val_loss: 0.2375
Epoch 174/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2508 - val_loss: 0.2379
Epoch 175/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2527 - val_loss: 0.2412
Epoch 176/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2521 - val_loss: 0.2378
Epoch 177/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2515 - val_loss: 0.2356
Epoch 178/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2501 - val_loss: 0.2369
Epoch 179/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2500 - val_loss: 0.2390
Epoch 180/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2517 - val_loss: 0.2382
Epoch 181/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2514 - val_loss: 0.2415
Epoch 182/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2516 - val_loss: 0.2373
Epoch 183/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2516 - val_loss: 0.2404
Epoch 184/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2501 - val_loss: 0.2373
Epoch 185/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2506 - val_loss: 0.2366
Epoch 186/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2506 - val_loss: 0.2376
Epoch 187/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2491 - val_loss: 0.2356
Epoch 188/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2487 - val_loss: 0.2363
Epoch 189/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2498 - val_loss: 0.2365
Epoch 190/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2466 - val_loss: 0.2380
Epoch 191/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2502 - val_loss: 0.2370
Epoch 192/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2485 - val_loss: 0.2357
Epoch 193/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2479 - val_loss: 0.2353
Epoch 194/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2490 - val_loss: 0.2370
Epoch 195/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2489 - val_loss: 0.2352
Epoch 196/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2476 - val_loss: 0.2406
Epoch 197/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2491 - val_loss: 0.2354
Epoch 198/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2482 - val_loss: 0.2364
Epoch 199/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2493 - val_loss: 0.2385
Epoch 200/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2467 - val_loss: 0.2345
Epoch 201/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2455 - val_loss: 0.2389
Epoch 202/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2490 - val_loss: 0.2338
Epoch 203/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2467 - val_loss: 0.2383
Epoch 204/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2476 - val_loss: 0.2358
Epoch 205/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2464 - val_loss: 0.2341
Epoch 206/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2480 - val_loss: 0.2365
Epoch 207/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2491 - val_loss: 0.2374
Epoch 208/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2476 - val_loss: 0.2345
Epoch 209/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2498 - val_loss: 0.2334
Epoch 210/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2468 - val_loss: 0.2368
Epoch 211/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2529 - val_loss: 0.2348
Epoch 212/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2475 - val_loss: 0.2373
Epoch 213/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2457 - val_loss: 0.2345
Epoch 214/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2502 - val_loss: 0.2365
Epoch 215/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2490 - val_loss: 0.2375
Epoch 216/400
289/289 [==============================] - 2s 6ms/step - loss: 0.2459 - val_loss: 0.2359
Epoch 217/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2467 - val_loss: 0.2347
Epoch 218/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2447 - val_loss: 0.2360
Epoch 219/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2476 - val_loss: 0.2367
Epoch 220/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2435 - val_loss: 0.2338
Epoch 221/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2449 - val_loss: 0.2367
Epoch 222/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2485 - val_loss: 0.2372
Epoch 223/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2473 - val_loss: 0.2355
Epoch 224/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2453 - val_loss: 0.2331
Epoch 225/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2459 - val_loss: 0.2363
Epoch 226/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2438 - val_loss: 0.2326
Epoch 227/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2463 - val_loss: 0.2358
Epoch 228/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2456 - val_loss: 0.2351
Epoch 229/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2455 - val_loss: 0.2346
Epoch 230/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2432 - val_loss: 0.2348
Epoch 231/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2456 - val_loss: 0.2328
Epoch 232/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2475 - val_loss: 0.2333
Epoch 233/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2434 - val_loss: 0.2354
Epoch 234/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2459 - val_loss: 0.2356
Epoch 235/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2444 - val_loss: 0.2321
Epoch 236/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2445 - val_loss: 0.2349
Epoch 237/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2441 - val_loss: 0.2338
Epoch 238/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2426 - val_loss: 0.2350
Epoch 239/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2418 - val_loss: 0.2346
Epoch 240/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2413 - val_loss: 0.2341
Epoch 241/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2414 - val_loss: 0.2378
Epoch 242/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2422 - val_loss: 0.2351
Epoch 243/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2442 - val_loss: 0.2330
Epoch 244/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2407 - val_loss: 0.2321
Epoch 245/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2427 - val_loss: 0.2329
Epoch 246/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2425 - val_loss: 0.2319
Epoch 247/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2445 - val_loss: 0.2336
Epoch 248/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2441 - val_loss: 0.2319
Epoch 249/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2414 - val_loss: 0.2316
Epoch 250/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2394 - val_loss: 0.2326
Epoch 251/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2446 - val_loss: 0.2332
Epoch 252/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2411 - val_loss: 0.2343
Epoch 253/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2393 - val_loss: 0.2306
Epoch 254/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2400 - val_loss: 0.2301
Epoch 255/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2433 - val_loss: 0.2322
Epoch 256/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2423 - val_loss: 0.2298
Epoch 257/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2410 - val_loss: 0.2311
Epoch 258/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2418 - val_loss: 0.2343
Epoch 259/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2430 - val_loss: 0.2284
Epoch 260/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2442 - val_loss: 0.2301
Epoch 261/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2407 - val_loss: 0.2323
Epoch 262/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2392 - val_loss: 0.2328
Epoch 263/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2382 - val_loss: 0.2327
Epoch 264/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2429 - val_loss: 0.2343
Epoch 265/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2402 - val_loss: 0.2309
Epoch 266/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2440 - val_loss: 0.2314
Epoch 267/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2408 - val_loss: 0.2298
Epoch 268/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2400 - val_loss: 0.2315
Epoch 269/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2431 - val_loss: 0.2285
Epoch 270/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2406 - val_loss: 0.2305
Epoch 271/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2396 - val_loss: 0.2318
Epoch 272/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2427 - val_loss: 0.2317
Epoch 273/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2392 - val_loss: 0.2313
Epoch 274/400
289/289 [==============================] - 4s 15ms/step - loss: 0.2401 - val_loss: 0.2341
Epoch 275/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2393 - val_loss: 0.2344
Epoch 276/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2423 - val_loss: 0.2303
Epoch 277/400
289/289 [==============================] - 5s 18ms/step - loss: 0.2416 - val_loss: 0.2295
Epoch 278/400
289/289 [==============================] - 4s 15ms/step - loss: 0.2385 - val_loss: 0.2294
Epoch 279/400
289/289 [==============================] - 4s 12ms/step - loss: 0.2389 - val_loss: 0.2321
Epoch 280/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2413 - val_loss: 0.2315
Epoch 281/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2391 - val_loss: 0.2320
Epoch 282/400
289/289 [==============================] - 5s 17ms/step - loss: 0.2415 - val_loss: 0.2303
Epoch 283/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2394 - val_loss: 0.2289
Epoch 284/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2409 - val_loss: 0.2321
Epoch 285/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2423 - val_loss: 0.2283
Epoch 286/400
289/289 [==============================] - 5s 16ms/step - loss: 0.2442 - val_loss: 0.2321
Epoch 287/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2394 - val_loss: 0.2320
Epoch 288/400
289/289 [==============================] - 4s 12ms/step - loss: 0.2402 - val_loss: 0.2306
Epoch 289/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2377 - val_loss: 0.2317
Epoch 290/400
289/289 [==============================] - 4s 15ms/step - loss: 0.2360 - val_loss: 0.2314
Epoch 291/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2402 - val_loss: 0.2334
Epoch 292/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2403 - val_loss: 0.2291
Epoch 293/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2398 - val_loss: 0.2296
Epoch 294/400
289/289 [==============================] - 5s 18ms/step - loss: 0.2403 - val_loss: 0.2272
Epoch 295/400
289/289 [==============================] - 4s 15ms/step - loss: 0.2370 - val_loss: 0.2308
Epoch 296/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2403 - val_loss: 0.2322
Epoch 297/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2382 - val_loss: 0.2309
Epoch 298/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2371 - val_loss: 0.2308
Epoch 299/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2375 - val_loss: 0.2286
Epoch 300/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2428 - val_loss: 0.2293
Epoch 301/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2434 - val_loss: 0.2307
Epoch 302/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2384 - val_loss: 0.2303
Epoch 303/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2406 - val_loss: 0.2304
Epoch 304/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2368 - val_loss: 0.2290
Epoch 305/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2386 - val_loss: 0.2304
Epoch 306/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2377 - val_loss: 0.2293
Epoch 307/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2386 - val_loss: 0.2293
Epoch 308/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2375 - val_loss: 0.2332
Epoch 309/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2389 - val_loss: 0.2308
Epoch 310/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2357 - val_loss: 0.2297
Epoch 311/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2371 - val_loss: 0.2288
Epoch 312/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2361 - val_loss: 0.2300
Epoch 313/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2368 - val_loss: 0.2310
Epoch 314/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2364 - val_loss: 0.2325
Epoch 315/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2372 - val_loss: 0.2289
Epoch 316/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2357 - val_loss: 0.2296
Epoch 317/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2374 - val_loss: 0.2269
Epoch 318/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2378 - val_loss: 0.2346
Epoch 319/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2382 - val_loss: 0.2311
Epoch 320/400
289/289 [==============================] - 5s 16ms/step - loss: 0.2344 - val_loss: 0.2300
Epoch 321/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2368 - val_loss: 0.2285
Epoch 322/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2350 - val_loss: 0.2282
Epoch 323/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2378 - val_loss: 0.2293
Epoch 324/400
289/289 [==============================] - 4s 15ms/step - loss: 0.2366 - val_loss: 0.2288
Epoch 325/400
289/289 [==============================] - 4s 12ms/step - loss: 0.2388 - val_loss: 0.2305
Epoch 326/400
289/289 [==============================] - 4s 13ms/step - loss: 0.2391 - val_loss: 0.2308
Epoch 327/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2365 - val_loss: 0.2289
Epoch 328/400
289/289 [==============================] - 5s 16ms/step - loss: 0.2351 - val_loss: 0.2284
Epoch 329/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2377 - val_loss: 0.2290
Epoch 330/400
289/289 [==============================] - 4s 12ms/step - loss: 0.2354 - val_loss: 0.2297
Epoch 331/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2396 - val_loss: 0.2317
Epoch 332/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2341 - val_loss: 0.2284
Epoch 333/400
289/289 [==============================] - 3s 12ms/step - loss: 0.2354 - val_loss: 0.2260
Epoch 334/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2376 - val_loss: 0.2296
Epoch 335/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2357 - val_loss: 0.2279
Epoch 336/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2342 - val_loss: 0.2291
Epoch 337/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2367 - val_loss: 0.2268
Epoch 338/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2371 - val_loss: 0.2291
Epoch 339/400
289/289 [==============================] - 5s 17ms/step - loss: 0.2353 - val_loss: 0.2299
Epoch 340/400
289/289 [==============================] - 5s 16ms/step - loss: 0.2372 - val_loss: 0.2284
Epoch 341/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2345 - val_loss: 0.2284
Epoch 342/400
289/289 [==============================] - 5s 18ms/step - loss: 0.2324 - val_loss: 0.2283
Epoch 343/400
289/289 [==============================] - 5s 19ms/step - loss: 0.2355 - val_loss: 0.2286
Epoch 344/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2374 - val_loss: 0.2278
Epoch 345/400
289/289 [==============================] - 4s 14ms/step - loss: 0.2376 - val_loss: 0.2325
Epoch 346/400
289/289 [==============================] - 5s 17ms/step - loss: 0.2336 - val_loss: 0.2301
Epoch 347/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2346 - val_loss: 0.2276
Epoch 348/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2339 - val_loss: 0.2283
Epoch 349/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2357 - val_loss: 0.2353
Epoch 350/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2350 - val_loss: 0.2312
Epoch 351/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2381 - val_loss: 0.2298
Epoch 352/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2362 - val_loss: 0.2319
Epoch 353/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2364 - val_loss: 0.2316
Epoch 354/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2334 - val_loss: 0.2276
Epoch 355/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2354 - val_loss: 0.2284
Epoch 356/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2385 - val_loss: 0.2274
Epoch 357/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2345 - val_loss: 0.2293
Epoch 358/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2313 - val_loss: 0.2284
Epoch 359/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2338 - val_loss: 0.2286
Epoch 360/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2358 - val_loss: 0.2293
Epoch 361/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2335 - val_loss: 0.2296
Epoch 362/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2325 - val_loss: 0.2306
Epoch 363/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2381 - val_loss: 0.2314
Epoch 364/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2364 - val_loss: 0.2304
Epoch 365/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2345 - val_loss: 0.2310
Epoch 366/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2343 - val_loss: 0.2320
Epoch 367/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2344 - val_loss: 0.2311
Epoch 368/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2356 - val_loss: 0.2283
Epoch 369/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2348 - val_loss: 0.2339
Epoch 370/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2353 - val_loss: 0.2287
Epoch 371/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2346 - val_loss: 0.2289
Epoch 372/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2336 - val_loss: 0.2263
Epoch 373/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2339 - val_loss: 0.2288
Epoch 374/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2343 - val_loss: 0.2311
Epoch 375/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2319 - val_loss: 0.2268
Epoch 376/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2283 - val_loss: 0.2284
Epoch 377/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2320 - val_loss: 0.2265
Epoch 378/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2329 - val_loss: 0.2307
Epoch 379/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2346 - val_loss: 0.2287
Epoch 380/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2315 - val_loss: 0.2284
Epoch 381/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2368 - val_loss: 0.2315
Epoch 382/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2322 - val_loss: 0.2272
Epoch 383/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2350 - val_loss: 0.2308
Epoch 384/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2345 - val_loss: 0.2308
Epoch 385/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2311 - val_loss: 0.2299
Epoch 386/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2356 - val_loss: 0.2281
Epoch 387/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2315 - val_loss: 0.2273
Epoch 388/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2313 - val_loss: 0.2269
Epoch 389/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2355 - val_loss: 0.2265
Epoch 390/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2313 - val_loss: 0.2281
Epoch 391/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2323 - val_loss: 0.2276
Epoch 392/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2325 - val_loss: 0.2252
Epoch 393/400
289/289 [==============================] - 3s 9ms/step - loss: 0.2327 - val_loss: 0.2275
Epoch 394/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2345 - val_loss: 0.2307
Epoch 395/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2317 - val_loss: 0.2303
Epoch 396/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2330 - val_loss: 0.2270
Epoch 397/400
289/289 [==============================] - 2s 8ms/step - loss: 0.2322 - val_loss: 0.2256
Epoch 398/400
289/289 [==============================] - 3s 11ms/step - loss: 0.2314 - val_loss: 0.2280
Epoch 399/400
289/289 [==============================] - 3s 10ms/step - loss: 0.2313 - val_loss: 0.2265
Epoch 400/400
289/289 [==============================] - 2s 7ms/step - loss: 0.2272 - val_loss: 0.2299
722/722 [==============================] - 2s 2ms/step - loss: 0.2327
MSE for the test: 0.23270732164382935
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_0bd9f42f56ed4292b318f805e6ce5fe7/335ac3d312cc18c77b78d447264be99b711929a4.png" /></p>
</div>
</div>
<div class="cell markdown" id="ojbKeEuLk0jt">
<p>If we observe the plot for the loss over epochs, it is clear to see
that, at first, the loss decreases drastically. Later, it will converge
to the loss value and stay constant throughout all the other epochs
left. The result we get in this plot is the result we expected since the
loss was expected to decrease at first and then converge.</p>
</div>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="82Cp5R_G5fRY" data-outputId="fd99366f-432a-412c-efc4-c7dce3285a26">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> model.predict(X_train_scaled)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test_scaled)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>train_mse <span class="op">=</span> mean_squared_error(y_train, y_train_pred)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>train_rmse <span class="op">=</span> train_mse <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>train_r2 <span class="op">=</span> r2_score(y_train, y_train_pred)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating  Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R2</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>test_mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> test_mse <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>test_r2 <span class="op">=</span> r2_score(y_test, y_test_pred)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Printing out the results</span></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for train: </span><span class="sc">{</span>train_mse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE for train: </span><span class="sc">{</span>train_rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;R2 for train: </span><span class="sc">{</span>train_r2<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MSE for test: </span><span class="sc">{</span>test_mse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE for test: </span><span class="sc">{</span>test_rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;R2 for test: </span><span class="sc">{</span>test_r2<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>2888/2888 [==============================] - 6s 2ms/step
722/722 [==============================] - 2s 2ms/step
MSE for train: 0.20037733570331592
RMSE for train: 0.44763527084370364
R2 for train: 0.7992521122431385
MSE for test: 0.2327073383934005
RMSE for test: 0.4823974900363812
R2 for test: 0.7689981368056281
</code></pre>
</div>
</div>
<div class="cell markdown" id="iUTawOyzHx2O">
<p>We can see that Neural Network has a pretty good <span
class="math inline"><em>R</em><sup>2</sup></span> and low MSE and RMSE
but Random Forset gave us best results.</p>
</div>
<div class="cell markdown" id="4vBKa-l2HaDF">

</div>
<section id="interpretation" class="cell markdown" id="ePHtO8Rlv8E0">
<h1><strong>Interpretation</strong></h1>
<p><strong><h3>Statistical Conclusions</h3></strong></p>
<p>When testing against test data, we found that our models had the
following MSE, RMSE and R2 scores:</p>
<table >
<tr>
<th>
<p>Model<th><th>MSE<th><th>RMSE<th><th>R2<th><tr> <tr> <td>Linear
Regression<td><td>0.414<td><td>0.634<td><td>0.599<td> <tr> <tr>
<td>Lasso Regression<td><td>0.417<td><td>0.646<td><td>0.596<td> <tr>
<tr> <td>KNN<td><td>0.248<td><td>0.498<td><td>0.760<td> <tr> <tr>
<td>Random Forest Tree<td><td>0.208<td><td>0.456<td><td>0.839<td> <tr>
<tr> <td>Neural Network<td><td>0.232<td><td>0.482<td><td>0.769<td> <tr>
<table></p>
<p>Based on these statistics, the <strong>Random Forest model</strong>
emerged as the best model for predicting a used vehicle's price, with a
Mean Squared Error of 0.208, a Root Mean Squared Error of 0.456, and an
R² Score of 0.839. This model not only provided the lowest error metrics
but also the highest explanatory power regarding the variance in vehicle
prices.</p>
<p><strong><h3>Importance</h3></strong></p>
<p>In summary, the significant and growing reliance on used vehicles in
American daily life, coupled with rising vehicle prices, underscores the
importance of effectively navigating the automotive market. Our project
aimed to meet this need by developing a reliable price predictor for
used cars, ensuring that individuals receive a fair price on their used
vehicles. Ultimately, this project seeks to empower individuals with the
knowledge needed to make informed decisions when purchasing or selling a
car.</p>
</section>
<div class="cell markdown" id="harH9DoZMgpw">
<p>As we conclude our exploration of various predictive models for used
car prices, we have traversed a comprehensive journey from data
preparation to advanced modeling techniques. Our project has
demonstrated the effectiveness of multiple algorithms, each with its
strengths and nuances, in the context of a real-world application that
impacts everyday financial decisions.</p>
<p><strong>Closing Thoughts</strong></p>
<p>This project underscores the power of data science and machine
learning in transforming raw data into actionable insights. By carefully
tuning our models and selecting the right tool for the job, we have
developed a system that not only predicts with accuracy but also
enhances our understanding of the used car market.</p>
<p>We hope this project serves as a valuable resource for those looking
to navigate the complexities of used vehicle pricing and as a stepping
stone for further research and development in predictive modeling.</p>
<p>Thank you for joining us on this analytical journey. We look forward
to future opportunities to explore and innovate together in the realm of
data science.</p>
</div>
<div class="cell markdown" id="vjlFAQwLPwsS">
<p><img
src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExaTNlYTFrZWxqNWc1M3FzZzNrcjNxN3B2Mm52a2tkMmY3N3F2bmRkcSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3oz8xIsloV7zOmt81G/giphy.gif"
alt="Thank You" /></p>
</div>
<div class="cell markdown" id="gQpkIy6tP7xH">

</div>
</body>
</html>
